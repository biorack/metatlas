{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0,'/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages' )\n",
    "from molvs.standardize import enumerate_tautomers_smiles\n",
    "from rdkit import Chem\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "ref_df = pd.read_pickle('/project/projectdirs/openmsi/projects/ben_run_pactolus/unique_compounds.pkl')\n",
    "inchis = ref_df.head(100).inchi.tolist()\n",
    "\n",
    "def process_apply(x):\n",
    "    return enumerate_tautomers_smiles(Chem.MolToSmiles(Chem.MolFromInchi(str(x))))\n",
    "\n",
    "\n",
    "num_procs = 100\n",
    "p = mp.Pool(processes=num_procs)\n",
    "t0 = time.time()\n",
    "\n",
    "pool_results = p.map(process_apply, inchis)\n",
    "print time.time() - t0\n",
    "p.close()\n",
    "p.terminate()\n",
    "df = pd.DataFrame(pd.Series(pool_results),columns = ['tautomers'])\n",
    "df.to_pickle('/project/projectdirs/openmsi/projects/chemical_networks/tautomers.pkl')\n",
    "print time.time() - t0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named molvs.standardize",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b133013a8c84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmolvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menumerate_tautomers_smiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menumerate_tautomers_smiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CCC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named molvs.standardize"
     ]
    }
   ],
   "source": [
    "from molvs.standardize import enumerate_tautomers_smiles\n",
    "from rdkit import Chem\n",
    "enumerate_tautomers_smiles('CCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0,'/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages' )\n",
    "from molvs.standardize import enumerate_tautomers_smiles\n",
    "from rdkit import Chem\n",
    "\n",
    "ref_df = pd.read_pickle('/project/projectdirs/openmsi/projects/ben_run_pactolus/unique_compounds.pkl')\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "def process_apply(x):\n",
    "    return enumerate_tautomers_smiles(Chem.MolToSmiles(Chem.MolFromInchi(str(x))))\n",
    "\n",
    "def process(df):\n",
    "    res = df.apply(process_apply)\n",
    "    return res\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "num_procs = 272\n",
    "p = mp.Pool(processes=num_procs)\n",
    "split_dfs = np.array_split(ref_df.head(1000).inchi,num_procs)\n",
    "pool_results = p.map(process, split_dfs)\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "# merging parts processed by different processes\n",
    "parts = pd.concat(pool_results, axis=0)\n",
    "parts.to_pickle('/project/projectdirs/openmsi/projects/chemical_networks/tautomers.pkl')\n",
    "print time.time() - t0\n",
    "# # merging newly calculated parts to big_df\n",
    "# big_df = pd.concat([big_df, parts], axis=1)\n",
    "\n",
    "# # checking if the dfs were merged correctly\n",
    "# pdt.assert_series_equal(parts['id'], big_df['id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# tautomers = ref_df.head(100).inchi.apply(lambda x: enumerate_tautomers_smiles(Chem.MolToSmiles(Chem.MolFromInchi(str(x)))))\n",
    "# smiles = rdkit_mols.apply(lambda x: (x,isomericSmiles=True))\n",
    "# tautomers = smiles.apply(enumerate_tautomers_smiles)\n",
    "# tautomers.to_pickle('/project/projectdirs/openmsi/projects/chemical_networks/tautomer_pandas_series.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "len(np.array_split(ref_df.head(120).inchi,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "p.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "d = [(20,26.8),(10,29.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "down vote\n",
    "accepted\n",
    "You can parallelize this with Dask.dataframe. This will work almost the same except that you can't use column assignment and will instead need to use the assign method\n",
    "```\n",
    ">>> dmaster = dd.from_pandas(master, npartitions=4)\n",
    ">>> dmaster = dmaster.assign(my_value=dmaster.original.apply(lambda x: helper(x, slave), name='my_value'))\n",
    ">>> dmaster.compute()\n",
    "```\n",
    "original  my_value\n",
    "\n",
    "0  this is a nice sentence         2\n",
    "\n",
    "1      this is another one         3\n",
    "\n",
    "2    stackoverflow is nice         1\n",
    "\n",
    "\n",
    "Additionally, you should think about the tradeoffs between using threads vs processes here. Your fuzzy string matching almost certainly doesn't release the GIL, so you won't get any benefit from using multiple threads. However, using processes will cause data to serialize and move around your machine, which might slow things down a bit.\n",
    "\n",
    "You can experiment between using threads and processes or a distributed system by managing the  get= keyword argument to the compute() method.\n",
    "```\n",
    "import dask.multiprocessing\n",
    "import dask.threaded\n",
    "\n",
    ">>> dmaster.compute(get=dask.threaded.get)  # this is default for dask.dataframe\n",
    ">>> dmaster.compute(get=dask.multiprocessing.get)  # try processes instead\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dmaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import dask.dataframe as dd\n",
    "import dask.multiprocessing\n",
    "import dask.threaded\n",
    "dmaster = dd.from_pandas(ref_df.head(120), npartitions=20)\n",
    "dmaster = dmaster.assign(my_value=dmaster.inchi.apply(lambda x: enumerate_tautomers_smiles(Chem.MolToSmiles(Chem.MolFromInchi(str(x))))), name='my_value')\n",
    "out_df = dmaster.compute(get=dask.threaded.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mols = []\n",
    "fmt = '%(asctime)s - %(levelname)s - %(validation)s - %(message)s'\n",
    "validator = Validator(log_format=fmt)\n",
    "\n",
    "from molvs import Standardizer\n",
    "s = Standardizer()\n",
    "\n",
    "smols = []\n",
    "for m in enumerate_tautomers_smiles('C[C@H]1CCC[C@@]2([C@@]1(CCCC2)O)C'):\n",
    "    mol = Chem.MolFromSmiles(m)\n",
    "    mols.append(mol)\n",
    "    validator.validate(mol)\n",
    "    smols.append(s.tautomer_parent(mol))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MolsToGridImage(mols, molsPerRow=4, subImgSize=(300, 200), legends=None, highlightAtomLists=None, useSVG=False)#, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
