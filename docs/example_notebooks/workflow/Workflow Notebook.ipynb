{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Python Packages\n",
    "\n",
    "To install the kernel used by NERSC-metatlas users, copy the following text to $HOME/.ipython/kernels/mass_spec_cori/kernel.json\n",
    "\n",
    "```\n",
    "{\n",
    " \"argv\": [\n",
    "  \"/global/common/software/m2650/python-cori/bin/python\",\n",
    "  \"-m\",\n",
    "  \"IPython.kernel\",\n",
    "  \"-f\",\n",
    "  \"{connection_file}\"\n",
    " ],\n",
    " \"env\": {\n",
    "    \"PATH\": \"/global/common/software/m2650/python-cori/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\"\n",
    " },\n",
    " \"display_name\": \"mass_spec_cori\",\n",
    " \"language\": \"python\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NERSC=', True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import sys, os\n",
    "\n",
    "#### add a path to your private code if not using production code ####\n",
    "sys.path.insert(0,\"/global/homes/b/bpb/repos/metatlas/\") #where your private code is\n",
    "######################################################################\n",
    "\n",
    "from metatlas.helpers import dill2plots as dp\n",
    "from metatlas.helpers import metatlas_get_data_helper_fun as ma_data\n",
    "# from metatlas.helpers import chromatograms_mp_plots as cp\n",
    "# from metatlas.helpers import chromplotplus as cpp\n",
    "import metatlas.metatlas_objects as metob\n",
    "# from metatlas.helpers import mzmine_helpers as mzm\n",
    "from metatlas.helpers import fastanalysis as fa\n",
    "# import qgrid\n",
    "\n",
    "# from ipywidgets import interact, interactive, fixed\n",
    "# import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import time\n",
    "import dill\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = dp.get_metatlas_files(experiment = '20180712_KBL_HILICZ_DCDerr_RSZ',name = '%',most_recent = True)\n",
    "df = metob.to_dataframe(files)\n",
    "# df = df[df.username=='pasteur']\n",
    "# my_grid = qgrid.QGridWidget(df=df[['experiment','name','username','acquisition_time']])\n",
    "# my_grid.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_groups = {}\n",
    "for f in files:\n",
    "    if not 'FPS' in f.name:\n",
    "        pieces = f.name.split('_')[:11] #skipping the user supplied identifier\n",
    "        pieces.append(f.name.split('_')[12])\n",
    "        group_name = '_'.join(pieces)\n",
    "        if group_name in my_groups.keys():\n",
    "            my_groups[group_name].append(f)\n",
    "        else:\n",
    "            my_groups[group_name] = [f]\n",
    "\n",
    "new_groups = []\n",
    "for k,v in my_groups.items():\n",
    "    new_groups.append(metob.Group(name=k,items=v))\n",
    "# metob.store(new_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in new_groups:\n",
    "    print(n.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Register LCMS Runs into categorical groups.\n",
    "\n",
    "* ### Select MetAtlas LCMS Runs by experiment and filename.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Create a \"File-Info\" sheet from the selected files.  \n",
    "This sheet needs to be downloaded and filled in.  The \"File-Info\" sheet is the exchange format we use to define the grouping membership for LCMS runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.make_empty_fileinfo_sheet('/global/homes/b/bpb/Downloads/empty_fileinfo.tab',files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Create metatlas groups from filled in file-info sheet\n",
    "Defining groups of files allows for the selection of sets of LCMS runs by specifying the group names.  In addition,  the group membership is preserved in the exported metatlas datasets; so the application of statistical methods based on grouped data is straightforward.\n",
    "\n",
    "Your filled in sheet will look something like this:\n",
    "<style type=\"text/css\">\n",
    "\ttable.tableizer-table {\n",
    "\t\tfont-size: 12px;\n",
    "\t\tborder: 1px solid #CCC; \n",
    "\t\tfont-family: Arial, Helvetica, sans-serif;\n",
    "\t} \n",
    "\t.tableizer-table td {\n",
    "\t\tpadding: 4px;\n",
    "\t\tmargin: 3px;\n",
    "\t\tborder: 1px solid #CCC;\n",
    "\t}\n",
    "\t.tableizer-table th {\n",
    "\t\tbackground-color: #104E8B; \n",
    "\t\tcolor: #FFF;\n",
    "\t\tfont-weight: bold;\n",
    "\t}\n",
    "</style>\n",
    "<table class=\"tableizer-table\">\n",
    "<thead><tr class=\"tableizer-firstrow\"><th>mzml_file</th><th>group</th><th>description</th></tr></thead><tbody>\n",
    " <tr><td>.../20160531_KBL_violacein_cells_384_final/20160531_C18_ACN_POS_MSMS_KBL_Qex_A_10_Run413.mzML</td><td>20160531_KBL_C18_Vio_cells_384_Quad_1</td><td>&nbsp;</td></tr>\n",
    " <tr><td>.../20160531_KBL_violacein_cells_384_final/20160531_C18_ACN_POS_MSMS_KBL_Qex_A_11_Run415.mzML</td><td>20160531_KBL_C18_Vio_cells_384_Quad_1</td><td>&nbsp;</td></tr>\n",
    " <tr><td>.../20160531_KBL_violacein_cells_384_final/20160531_C18_ACN_POS_MSMS_KBL_Qex_A_12_Run417.mzML</td><td>20160531_KBL_C18_Vio_cells_384_Quad_1</td><td>&nbsp;</td></tr>\n",
    " <tr><td>.../20160531_KBL_violacein_cells_384_final/20160531_C18_ACN_POS_MSMS_KBL_Qex_A_1_Run395.mzML</td><td>20160531_KBL_C18_Vio_cells_384_Quad_2</td><td>&nbsp;</td></tr>\n",
    " <tr><td>.../20160531_KBL_violacein_cells_384_final/20160531_C18_ACN_POS_MSMS_KBL_Qex_A_2_Run397.mzML</td><td>20160531_KBL_C18_Vio_cells_384_Quad_2</td><td>&nbsp;</td></tr>\n",
    " <tr><td>.../20160531_KBL_violacein_cells_384_final/20160531_C18_ACN_POS_MSMS_KBL_Qex_A_3_Run399.mzML</td><td>20160531_KBL_C18_Vio_cells_384_Quad_2</td><td></td></tr>\n",
    "</tbody></table>\n",
    "\n",
    "A text description of each group is an optional field.  These can be a few, short sentences that describe each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dp.make_groups_from_fileinfo_sheet('/global/homes/b/bpb/Downloads/test_make_groups.txt',\n",
    "                                       filetype='tab',\n",
    "                                       store=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the list of metatlas objects using \"to_dataframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metob.to_dataframe(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create a new Atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### From a spreadsheet\n",
    "This is by far the most common way to create a new Atlas in Metabolite Atlas.  The columns the sheet must be exactly as what is seen here.  In cases where there isn't a compound in the database, the \"label\" field below is used.  Here is an example of what a sheet could look like.\n",
    "\n",
    "<style type=\"text/css\">\n",
    "\ttable.tableizer-table {\n",
    "\t\tfont-size: 12px;\n",
    "\t\tborder: 1px solid #CCC; \n",
    "\t\tfont-family: Arial, Helvetica, sans-serif;\n",
    "\t} \n",
    "\t.tableizer-table td {\n",
    "\t\tpadding: 4px;\n",
    "\t\tmargin: 3px;\n",
    "\t\tborder: 1px solid #CCC;\n",
    "\t}\n",
    "\t.tableizer-table th {\n",
    "\t\tbackground-color: #104E8B; \n",
    "\t\tcolor: #FFF;\n",
    "\t\tfont-weight: bold;\n",
    "\t}\n",
    "</style>\n",
    "<table class=\"tableizer-table\">\n",
    "<thead><tr class=\"tableizer-firstrow\"><th>label</th><th>rt_min</th><th>rt_max</th><th>rt_peak</th><th>mz</th><th>mz_tolerance</th><th>inchi_key</th></tr></thead><tbody>\n",
    " <tr><td>violacein </td><td>4.2</td><td>4.4</td><td>4.3</td><td>344.1036913</td><td>5</td><td>XAPNKXIRQFHCHN-QGOAFFKASA-N</td></tr>\n",
    " <tr><td>deoxyviolacein (iso1 - main)</td><td>4.75</td><td>4.9</td><td>4.8</td><td>328.1087767</td><td>5</td><td>OJUJNNKCVPCATE-QGOAFFKASA-N</td></tr>\n",
    " <tr><td>tryptophan</td><td>2.3</td><td>2.45</td><td>2.36</td><td>205.0978776</td><td>5</td><td>QIVBCDIJIAJPQS-VIFPVBQESA-N</td></tr>\n",
    " <tr><td>deoxychromoviridans</td><td>5.4</td><td>6</td><td>5.75</td><td>605.244821</td><td>5</td><td>&nbsp;</td></tr>\n",
    " <tr><td>chromoviridans</td><td>5.15</td><td>5.5</td><td>5.3</td><td>621.239736</td><td>5</td><td>&nbsp;</td></tr>\n",
    " <tr><td>ABMBA</td><td>4.72</td><td>4.88</td><td>4.8</td><td>229.9811</td><td>5</td><td>LCMZECCEEOQWLQ-UHFFFAOYSA-N</td></tr>\n",
    "</tbody></table>\n",
    "\n",
    "These tables can be csv or tab delimited text or excel spreadsheets.\n",
    "\n",
    "There is a <a href = 'https://drive.google.com/open?id=0BweRoDuGcsLBNkYtQUpjQ0ktZDg'> lookup table here </a> of all compounds to get the inchi_key.\n",
    "\n",
    "For old MetAtlas atlases, you can use Excel's \"vlookup\" function along with <a href = 'https://drive.google.com/open?id=0BweRoDuGcsLBQUxrRjgtbjhnSDg'> this lookup table </a> to map the old names to valid inchi keys.\n",
    "\n",
    "```\n",
    "=VLOOKUP(H2,$A:$B,2,0) where $A:$B are columns containing name and inchi-key\n",
    "```\n",
    "\n",
    "This is a <a href = 'https://drive.google.com/open?id=0BweRoDuGcsLBaThjcEZuSjh2dXM'> link </a> to all the old compound identifications that were in the database prior to the refactoring in Mid June, 2016.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/global/homes/b/bpb/Downloads/20191018_POS_TG_FINALFINALnorm2_BIG_algae_BETO_IG_Mono.csv')\n",
    "df.fillna('',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "myAtlas = dp.make_atlas_from_spreadsheet('ISTD and QC Atlases - QC SOP v3.tsv',\n",
    "                                       '20191001_BPB_QC_HILICZ_POS_Training3',\n",
    "                                       filetype='tab',\n",
    "                                       sheetname='',\n",
    "                                       polarity = 'positive',\n",
    "                                       store=True,\n",
    "                                      mz_tolerance = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "myAtlas = dp.make_atlas_from_spreadsheet(df,\n",
    "                                       '20191112_bpb_normalization_atlas_pos_lipid',\n",
    "                                       filetype='dataframe',\n",
    "                                       sheetname='',\n",
    "                                       polarity = 'positive',\n",
    "                                       store=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Select groups of files to operate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = dp.select_groups_for_analysis(name = '%20190308_KBL_IG-SS_BETO_Algae_Mono26B_HF_LipV7_47560%',\n",
    "                                       most_recent = True,\n",
    "                                       remove_empty = True,\n",
    "                                       include_list = [], exclude_list = ['NEG','QC','InjBl'])#['QC','Blank'])\n",
    "\n",
    "# dp = reload(dp)\n",
    "# groups = dp.select_groups_for_analysis(name = '%DCD%QE-139_HILICZ%POS%',\n",
    "#                                        most_recent = True,\n",
    "#                                        remove_empty = True,\n",
    "#                                        include_list = [], exclude_list = [])#['QC','Blank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in groups:\n",
    "    for f in g.items:\n",
    "        print f.mzml_file\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Select Atlas to use\n",
    "* ### Select by Atlas name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#default ema atlas: EMA_pos%50447%\n",
    "atlases = metob.retrieve('Atlas',name='20191112_bpb_normalization_atlas_pos_lipid',username='bpb')\n",
    "names = []\n",
    "for i,a in enumerate(atlases):\n",
    "    print(i,a.name,pd.to_datetime(a.last_modified,unit='s'),len(a.compound_identifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Alternative way to get atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "atlases = dp.get_metatlas_atlas(name='coelicolor_features_20170620',do_print = True,most_recent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### A list of atlases is returned by the cell above.  \n",
    "\n",
    "* You must run the following cell to specify which Atlas you want to continue your analysis with (Even if only a single atlas is returned).\n",
    "\n",
    "* Make a dataframe from your atlas.  Required for the new, faster data slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAtlas = atlases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "atlas_df['label'] = ['%s___%s'%(cid.name,cid.mz_references[0].adduct) for cid in myAtlas.compound_identifications]\n",
    "print myAtlas.name\n",
    "print myAtlas.username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the atlases name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAtlas.name = 'SK-ZZ-MAIZE-HILIC-NEG-EMA50447'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove flagged compounds from your atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(myAtlas.compound_identifications))\n",
    "myAtlas.compound_identifications = [atlas_id for atlas_id in myAtlas.compound_identifications if atlas_id.description != 'remove']\n",
    "print(len(myAtlas.compound_identifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust RT using y = m x + b approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0.99\n",
    "b = 0.346\n",
    "extra_rt = 0.2\n",
    "for i,cpd_id in enumerate(myAtlas.compound_identifications):\n",
    "    rt_min = myAtlas.compound_identifications[i].rt_references[0].rt_min\n",
    "    rt_max = myAtlas.compound_identifications[i].rt_references[0].rt_max\n",
    "    rt_peak = myAtlas.compound_identifications[i].rt_references[0].rt_peak\n",
    "    myAtlas.compound_identifications[i].rt_references[0].rt_min = m * rt_min + b - extra_rt\n",
    "    myAtlas.compound_identifications[i].rt_references[0].rt_peak = m * rt_peak + b\n",
    "    myAtlas.compound_identifications[i].rt_references[0].rt_max = m * rt_max + b + extra_rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the updated Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metob.store([myAtlas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the selected atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View only the first few lines\n",
    "* Remove the \".head()\" to show the whole thing\n",
    "* Put a number in the \".head()\" to show number of rows\n",
    "* Edit set_option to configure display:\n",
    "* More options available here:\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.set_option.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the atlas as a qgrid widget (good for widescreen displays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the atlas as a pandas dataframe (tweak the pandas display options to fit)\n",
    "* More options available here:\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.set_option.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "atlas_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for my_group in groups:\n",
    "    for my_file in my_group.items:\n",
    "        all_files.append((my_file,my_group,atlas_df,myAtlas))\n",
    "        \n",
    "pool = mp.Pool(processes=min(4, len(all_files)))\n",
    "t0 = time.time()\n",
    "metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "#If you're code crashes here, make sure to terminate any processes left open.\n",
    "print time.time() - t0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select parameters to split atlas_df and metatlas_dataset by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = dp.get_msms_hits(metatlas_dataset,extra_time=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_me_red='cooked', \n",
    "a = dp.adjust_rt_for_selected_compound(metatlas_dataset, msms_hits=hits,compound_idx=0,include_lcmsruns = [],alpha=0.75,width=12,height=4.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz = metob.MzReference(mz=1234.1234,adduct='[M+H]+')\n",
    "mz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd = metob.retrieve('Compounds',inchi_key='ALRHLSYJTWAHJZ-UHFFFAOYSA-N',username='*')[-1]\n",
    "cpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metob.CompoundIdentification(mz_references=[mz],rt_refereces=[metob.RtReference(rt_min=123.123)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metatlas_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metatlas_dataset[3][-1]['data']['ms1_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metatlas_dataset[3][3]['data']['ms1_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = dp.normalize_peaks_by_internal_standard(metatlas_dataset,myAtlas,exclude_groups=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[3][3]['data']['ms1_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Parameter meanings:\n",
    "# each parameter is compared to best scoring metric for each compound\n",
    "# across all files\n",
    "###\n",
    "# 'min_intensity' <= highest intensity across all files for given compound\n",
    "# 'rt_tolerance' >= shift of median RT across all files for given compound to reference\n",
    "# 'mz_tolerance' >= ppm of median mz across all files for given compound relative to reference\n",
    "# 'min_msms_score' <= highest compound dot-product score across all files for given compound relative to reference\n",
    "# 'min_num_frag_matches' <= number of matching mzs when calculating max_msms_score\n",
    "# 'min_relative_frag_intensity' <= ratio of second highest to first highest intensity of matching sample mzs\n",
    "\n",
    "\n",
    "###\n",
    "# Custom\n",
    "###\n",
    "# kwargs = {'min_intensity': ,\n",
    "#           'rt_tolerance': ,\n",
    "#           'mz_tolerance': ,\n",
    "#           'min_msms_score': ,\n",
    "#           'allow_no_msms': ,\n",
    "#           'min_num_frag_matches': ,\n",
    "#           'min_relative_frag_intensity': }\n",
    "\n",
    "\n",
    "###\n",
    "# Loose\n",
    "###\n",
    "kwargs = {'min_intensity': 1e3,\n",
    "          'rt_tolerance': .25,\n",
    "          'mz_tolerance': 25,\n",
    "          'min_msms_score': 0.0, 'allow_no_msms': True,\n",
    "          'min_num_frag_matches': 1,  'min_relative_frag_intensity': .01}\n",
    "\n",
    "\n",
    "###\n",
    "# Strict\n",
    "###\n",
    "# kwargs = {'min_intensity': 1e5,\n",
    "#           'rt_tolerance': .25,\n",
    "#           'mz_tolerance': 5,\n",
    "#           'min_msms_score': .6, 'allow_no_msms': False,\n",
    "#           'min_num_frag_matches': 3, 'min_relative_frag_intensity': .1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scores_df, and split atlas and metatlas_dataset according to previously selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = reload(fa)\n",
    "scores_df = fa.make_scores_df(metatlas_dataset)\n",
    "scores_df['passing'] = fa.test_scores_df(scores_df, **kwargs)\n",
    "\n",
    "pass_atlas_df, fail_atlas_df, pass_dataset, fail_dataset = fa.filter_atlas_and_dataset(scores_df, atlas_df, metatlas_dataset,\n",
    "                                                                                    column='passing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output scores_df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv(os.path.join(output_dir, 'compound_scores.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save new filtered atlas(es) to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_atlas = dp.make_atlas_from_spreadsheet(pass_atlas_df,\n",
    "                                                atlas_name='positve_filtered_atlas_name'\n",
    "                                                filetype='dataframe',\n",
    "                                                polarity='positive', #Fill in the polarity here ('positive' or 'negative')\n",
    "                                                store=False,\n",
    "                                                mz_tolerance = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7a. Adjust Retention Times.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = dp.adjust_rt_for_selected_compound(metatlas_dataset,compound_idx=0,include_lcmsruns = [],alpha=0.75,width=10,height=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7b. Normalize by internal standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "metatlas_dataset = dp.normalize_peaks_by_internal_standard(metatlas_dataset,myAtlas,exclude_groups=['ExCtrl','FPS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Make Supplementary Tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify a directory to put all the figures into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/global/homes/b/bpb/Downloads/tag_norm_4/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Export Atlas to a Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_identifications = dp.export_atlas_to_spreadsheet(myAtlas,os.path.join(output_dir,'atlas_export.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Dataframes and spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "peak_height = dp.make_output_dataframe(input_fname = '',input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_height' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "peak_area = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_area' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "mz_peak = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='mz_peak' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "rt_peak = dp.make_output_dataframe(input_fname = my_file, input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [],fieldname='rt_peak' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "mz_centroid = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='mz_centroid' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "rt_centroid = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='rt_centroid' , output_loc=os.path.join(output_dir,'sheets'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas to help with downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = peak_height.copy()\n",
    "df.columns = df.columns.droplevel(1)\n",
    "df.fillna(0,inplace=True)\n",
    "groups = df.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = peak_height.copy()\n",
    "df.columns = df.columns.droplevel(1)\n",
    "#filter numbers less than threshold with zero\n",
    "df.fillna(0,inplace=True)\n",
    "#only do calculation for non-zero values\n",
    "df_stats = df.transpose().groupby('group').mean().transpose()\n",
    "# df_stats = df.transpose().groupby('group').std().transpose()\n",
    "# df_stats = df.transpose().groupby('group').count().transpose()\n",
    "\n",
    "df_stats.reset_index(drop=True,inplace=True)\n",
    "df_stats['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "df_stats.to_csv('stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df.transpose().groupby('group').mean().transpose()\n",
    "df_stats.reset_index(drop=True,inplace=True)\n",
    "df_stats['fold_change'] = np.log2(np.divide(df_stats[groups[1]],df_stats[groups[0]]))\n",
    "# print df_stats[df_stats.fold_change>-2].index.tolist()\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "cat1 = df[[c for c in df.columns if c == groups[0]]]\n",
    "cat2 = df[[c for c in df.columns if c == groups[1]]]\n",
    "\n",
    "\n",
    "df_stats['t-score'],df_stats['p-value'] = ttest_ind(cat1,cat2,axis=1)\n",
    "df_stats['label'] = [cid.name for cid in myAtlas.compound_identifications]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv('/global/homes/b/bpb/Downloads/magi_coelicolor_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_stats[df_stats.fold_change<-1].index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Error bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "dp.plot_errorbar_plots(peak_height, output_loc=os.path.join(output_dir,'error_bar_peak_height'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.plot_errorbar_plots(rt_peak, output_loc=os.path.join(output_dir,'error_bar_rt_peak'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Chromatograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster Chromatogram plots (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## THINGS YOU MIGHT WANT TO CHANGE\n",
    "group = None # 'page' or 'index' or None\n",
    "save = True\n",
    "share_y = True\n",
    "\n",
    "## THINGS YOU PROBABLY DON'T WANT TO CHANGE\n",
    "file_names = ma_data.get_file_names(metatlas_dataset)\n",
    "compound_names = ma_data.get_compound_names(metatlas_dataset)[0]\n",
    "args_list = []\n",
    "\n",
    "chromatogram_str = 'compound_chromatograms'\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir,chromatogram_str)):\n",
    "    os.makedirs(os.path.join(output_dir,chromatogram_str))\n",
    "\n",
    "for compound_idx, my_compound in enumerate(compound_names):\n",
    "    my_data = list()\n",
    "    for file_idx, my_file in enumerate(file_names):\n",
    "        my_data.append(metatlas_dataset[file_idx][compound_idx])\n",
    "    kwargs = {'data': my_data,\n",
    "             'file_name': os.path.join(output_dir, chromatogram_str, my_compound+'.pdf'),\n",
    "             'group': group,\n",
    "             'save': save,\n",
    "             'share_y': share_y,\n",
    "             'names': file_names}\n",
    "    args_list.append(kwargs)\n",
    "max_processes = 4\n",
    "pool = mp.Pool(processes=min(max_processes, len(metatlas_dataset[0])))\n",
    "pool.map(cpp.chromplotplus, args_list)\n",
    "pool.close()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a plot for each compound:\n",
    "* Each lcmsrun will be a subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THINGS YOU MIGHT WANT TO CHANGE\n",
    "nCols = 8\n",
    "share_y = True\n",
    "## THINGS YOU PROBABLY DON'T WANT TO CHANGE\n",
    "file_names = ma_data.get_file_names(metatlas_dataset)\n",
    "compound_names = ma_data.get_compound_names(metatlas_dataset)[0]\n",
    "nRows = int(np.ceil(len(file_names)/float(nCols)))\n",
    "args_list = []\n",
    "\n",
    "chromatogram_str = 'compound_chromatograms'\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir,chromatogram_str)):\n",
    "    os.makedirs(os.path.join(output_dir,chromatogram_str))\n",
    "\n",
    "for compound_idx, my_compound in enumerate(compound_names):\n",
    "    my_data = list()\n",
    "    for file_idx, my_file in enumerate(file_names):\n",
    "        my_data.append(metatlas_dataset[file_idx][compound_idx])\n",
    "    kwargs = {'data': my_data,\n",
    "              'file_name': os.path.join(output_dir, chromatogram_str, my_compound+'.pdf'),\n",
    "              'rowscols': (nRows, nCols),\n",
    "              'share_y': share_y,\n",
    "              'names': file_names}\n",
    "    args_list.append(kwargs)\n",
    "    cp.plot_compounds_and_files_mp(kwargs)\n",
    "# max_processes = 4\n",
    "# pool = mp.Pool(processes=min(max_processes, len(metatlas_dataset[0])))\n",
    "\n",
    "# pool.map(cp.plot_compounds_and_files_mp, args_list)\n",
    "# pool.close()\n",
    "# pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a plot for each lcmsrun\n",
    "* Each compound will be a subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## THINGS YOU MIGHT WANT TO CHANGE\n",
    "nCols = 8\n",
    "share_y = False\n",
    "\n",
    "chromatogram_str = 'lcmsrun_chromatograms'\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir,chromatogram_str)):\n",
    "    os.makedirs(os.path.join(output_dir,chromatogram_str))\n",
    "\n",
    "## THINGS YOU PROBABLY DON'T WANT TO CHANGE\n",
    "file_names = ma_data.get_file_names(metatlas_dataset)\n",
    "compound_names = ma_data.get_compound_names(metatlas_dataset)[0]\n",
    "nRows = int(np.ceil(len(compound_names)/float(nCols)))\n",
    "args_list = []\n",
    "for file_idx, my_file in enumerate(file_names):\n",
    "    kwargs = {'data': metatlas_dataset[file_idx],\n",
    "              'file_name': os.path.join(output_dir, chromatogram_str, my_compound+'.pdf'),\n",
    "              'rowscols': (nRows, nCols),\n",
    "              'share_y': share_y,\n",
    "              'names': compound_names}\n",
    "    args_list.append(kwargs)\n",
    "\n",
    "max_processes = 4\n",
    "pool = mp.Pool(processes=min(max_processes, len(metatlas_dataset)))\n",
    "pool.map(cp.plot_compounds_and_files_mp, args_list)\n",
    "pool.close()\n",
    "pool.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Identification Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "dp.make_identification_figure(input_dataset = metatlas_dataset, input_fname = my_file, include_lcmsruns = [],exclude_lcmsruns = ['InjBl','QC','Blank','blank'], output_loc=os.path.join(output_dir,'identification'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a single tar file of your output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "tarball_name = timestr + '_' + os.path.basename(os.path.normpath(output_dir)) + '.tar.gz'\n",
    "%system tar -zcf $tarball_name -C $output_dir .\n",
    "print 'done'\n",
    "from IPython.core.display import display, HTML\n",
    "f1 = '/user/bpb/files'+os.path.join(os.getcwd().replace('/global/u2/b/bpb',''), tarball_name)\n",
    "f2 = tarball_name\n",
    "display(HTML('<a href=\"%s\" download=\"%s\">Start automatic download!</a>'%(f1,f2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tarball will be stored in your current directory.  Run this to see current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%system pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Compare feature EICs to BPC of each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "files = groups[0].items\n",
    "ma_data = reload(ma_data)\n",
    "for f in files:\n",
    "    bpc = ma_data.get_bpc(f.hdf5_file,dataset='ms1_neg')\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    plt.plot(bpc.rt,bpc.i,'k-')\n",
    "#     for d in metatlas_dataset[file_index]:\n",
    "#         plt.plot(d['data']['eic']['rt'],d['data']['eic']['intensity'],c=np.random.rand(3,1),alpha=0.9)\n",
    "    ax = plt.gca()\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title('\\n'.join(wrap(base_file_names[file_index],50)))\n",
    "    ax.set_xlabel('Retention Time (min)')\n",
    "    ax.set_ylabel('Intensity')\n",
    "    plt.xlim(0,23)\n",
    "    plt.ylim(1e5,1e10)\n",
    "#     fig.savefig('/global/homes/b/bpb/trent/' + base_file_names[file_index].split('.')[0] + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "\n",
    "file_index = 0\n",
    "yscale = 'log'\n",
    "\n",
    "\n",
    "full_file_names = ma_data.get_file_names(metatlas_dataset,full_path=True)\n",
    "base_file_names = ma_data.get_file_names(metatlas_dataset,full_path=False)\n",
    "\n",
    "for file_index in range(len(full_file_names)):\n",
    "\n",
    "    bpc = ma_data.get_bpc(full_file_names[file_index],dataset='ms1_neg')\n",
    "    if not os.path.exists(os.path.join(output_dir,'bpc_eic' )):\n",
    "        os.makedirs(os.path.join(output_dir,'bpc_eic'))\n",
    "    fig = plt.figure(figsize=(20,6))\n",
    "    plt.plot(bpc.rt,bpc.i,'k-')\n",
    "    for d in metatlas_dataset[file_index]:\n",
    "        plt.plot(d['data']['eic']['rt'],d['data']['eic']['intensity'],c=np.random.rand(3,1),alpha=0.9)\n",
    "    ax = plt.gca()\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_title('\\n'.join(wrap(base_file_names[file_index],50)))\n",
    "    ax.set_xlabel('Retention Time (min)')\n",
    "    ax.set_ylabel('Intensity')\n",
    "    plt.xlim(0,23)\n",
    "    plt.ylim(1e5,1e10)\n",
    "    fig.savefig(os.path.join(output_dir,'bpc_eic', base_file_names[file_index].split('.')[0] + '.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_data = reload(ma_data)\n",
    "f_list = [ma_data.compare_EIC_to_BPC_for_file(metatlas_dataset,idx,yscale ='log') for idx in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_file_names = ma_data.get_file_names(metatlas_dataset,full_path=True)\n",
    "base_file_names = ma_data.get_file_names(metatlas_dataset,full_path=False)\n",
    "bpc = ma_data.get_bpc(full_file_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = bpc.mz.round(4).value_counts(normalize=False, sort=True, ascending=False, bins=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "f = bpc.mz.hist(bins=1000)\n",
    "plt.show(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Clean up Zombie Processes\n",
    "\n",
    "* ### These are not meant to be used as part of normal work\n",
    "\n",
    "* ### If code crashes, we will have to use these tools to clean things up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try simply closing the pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a DataFrame of user's processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import getpass\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "pids = [int(pid) for pid in os.listdir('/proc') if pid.isdigit()]\n",
    "proc_df = []\n",
    "for pid in pids:\n",
    "    try:\n",
    "        process = psutil.Process(pid)\n",
    "        if process.username() == getpass.getuser():\n",
    "            temp = {'pid': process.pid,\n",
    "                    'name': process.name(),\n",
    "                    'user': process.username(),\n",
    "                    'created_timestamp': int(process.create_time()*100),\n",
    "                    'created_datestr': str(datetime.fromtimestamp(process.create_time()))}\n",
    "            proc_df.append(temp)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "df = pd.DataFrame(proc_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kill process by process id (pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in df[df.created_timestamp > 147939907007].pid:\n",
    "    p = psutil.Process(pid)\n",
    "    p.terminate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = psutil.Process(43671)\n",
    "p.terminate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Run an MZMine Batch Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = metob.retrieve('lcmsruns',experiment='%jd_of%',name='%_pos_%',username='*')\n",
    "mzml_files = []\n",
    "print(len(files))\n",
    "for f in files:\n",
    "    mzml_files.append(f.mzml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob('/project/projectdirs/metatlas/raw_data/smkosina/20170317_SK_Arkin_PseudoAbxCsource/*.mzML')\n",
    "mzml_files = []\n",
    "for f in files:\n",
    "\n",
    "    if not '_InjBl' in f:\n",
    "        if ('_' in f) or ('Sterile' in f):\n",
    "            if 'NEG_' in f:\n",
    "                mzml_files.append(f)#f.replace('20170317_SK-MdR_Arkin_PseudoAbxCsource_QE144_EPC18-USDAY26531_MSMS_','')))\n",
    "# files\n",
    "\n",
    "\n",
    "\n",
    "mzml_files = sorted(mzml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mzml_files = []\n",
    "for g in groups:\n",
    "    for f in g.items:\n",
    "        mzml_files.append(f.mzml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mzml_files = ['/project/projectdirs/metatlas/raw_data/kblouie/20150914_actinorhodin_finalset_50mm/20150910_C18_MeOH_NEG_MSMS_Scoelicolor_media_WT_M145_Day6_3of4___Run61.mzML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_str = 'PseudoC_C18_NEG'\n",
    "# C18_MSMS_NEG_Secondary_Metabolite_Parameters\n",
    "mzm.make_mzmine_scripts(mzml_files, \n",
    "                        outfile='/project/projectdirs/metatlas/projects/mzmine_parameters/%s_mzmine_output.csv'%new_str,\n",
    "                        new_batch_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/%s_job_script_parameters.xml'%new_str,\n",
    "                        new_sbatch_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/%s_mzmine_job.sbatch'%new_str,\n",
    "                        new_qsub_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/%s_mzmine_job.qsub'%new_str,\n",
    "                        base_batch_file='/project/projectdirs/metatlas/projects/mzmine_parameters/C18_MSMS_NEG_Secondary_Metabolite_Parameters.xml',\n",
    "                        base_sbatch_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/mzmine_job.sbatch',\n",
    "                        base_qsub_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/mzmine_job.qsub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatlas.helpers import mzmine_helpers as mzm\n",
    "# mollaretii_P10_vs_0_output.csv\n",
    "# mzmine_out  = '/project/projectdirs/metatlas/projects/mzmine_parameters/pathway_1_mzmine_output.csv'\n",
    "mzmine_out = '/global/project/projectdirs/metatlas/projects/mzmine_parameters/dangl_exudate_C18_pos_mzmine_output.csv'\n",
    "# mzmine_out = '/global/project/projectdirs/metatlas/projects/mzmine_parameters/RootExu_C18_neg_mzmine_output.csv'\n",
    "atlas_df,myAtlas = mzm.metatlas_formatted_atlas_from_mzmine_output(mzmine_out,\n",
    "                                                               'positive',\n",
    "                                                               make_atlas=False,\n",
    "                                                               atlas_name='20161117_test_mzmine_atlas_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = atlas_df.copy()\n",
    "df = df.fillna(0)\n",
    "df.set_index(['label','mz','mz_tolerance','rt_peak','rt_min','rt_max','inchi_key','detected_polarity','max_intensity'],inplace=True,)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#add group info\n",
    "group_level = []\n",
    "for c in df.columns:\n",
    "    temp = ''\n",
    "    for g in groups:\n",
    "        for item in g.items:\n",
    "            if c.replace(' Peak height','') in item.name:\n",
    "                temp = g.name\n",
    "#     split_name = temp.split('_')\n",
    "#     split_name.extend([''] * (4 - len(split_name)))\n",
    "    group_level.append([temp,c.replace(' Peak height','')])\n",
    "#     print temp\n",
    "#     group_level.append([temp])\n",
    "list_of_lists = map(list, zip(*group_level))\n",
    "# list_of_lists = [list(elem) for elem in group_level]\n",
    "# df.columns = pd.MultiIndex.from_arrays(list_of_lists,names=('project','pathway','strain_code','iptg','species'))\n",
    "df.columns = pd.MultiIndex.from_arrays(list_of_lists,names=('group','file'))\n",
    "df.head()\n",
    "# print len(group_level),len(atlas_df.columns)\n",
    "# group_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('~/Downloads/dangle_c18_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(target-ppm,target+ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz = 363.2394162\n",
    "target = mz + 1.007276\n",
    "ppm = target * 15 / 1e6\n",
    "cpds = metob.database.query('select * from compounds where mono_isotopic_molecular_weight between %.4f and %.4f'%(target-ppm,target+ppm))\n",
    "results = [c for c in cpds]\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "638.4049378 - 1.007276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpds = metob.retrieve('Compounds',mono_isotopic_molecular_weight = '637.39%')\n",
    "for c in cpds:\n",
    "    print c.name,(c.mono_isotopic_molecular_weight + 1.007276 - 638.4049378) / 638.4049378 * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "\n",
    "fig,ax = plt.subplots(4,6,figsize=(20,13))\n",
    "\n",
    "for i,s in enumerate(df.columns.get_level_values('species').unique()):\n",
    "    idx = np.unravel_index(i,(4,6)) #convert to row column index\n",
    "    xdata = df.xs(('Pathway=0',s),level=['pathway','species'],axis=1).max(axis=1)\n",
    "    ydata = df.xs(('Pathway=1',s),level=['pathway','species'],axis=1).max(axis=1)\n",
    "    ax[idx].plot(xdata.fillna(0)+1,ydata.fillna(0)+1,'.',markersize=20)\n",
    "    ax[idx].set_title('\\n'.join(wrap(s,18)))\n",
    "    ax[idx].set_xlabel('wild type')\n",
    "    ax[idx].set_ylabel('engineered')\n",
    "    ax[idx].set_yscale('log')\n",
    "    ax[idx].set_xscale('log')\n",
    "\n",
    "    plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal = pd.DataFrame()\n",
    "for i,s in enumerate(df.columns.get_level_values('species').unique()):\n",
    "    idx = np.unravel_index(i,(4,6)) #convert to row column index\n",
    "    xdata = df.xs(('Pathway=0',s),level=['pathway','species'],axis=1).max(axis=1)\n",
    "    ydata = df.xs(('Pathway=1',s),level=['pathway','species'],axis=1).max(axis=1)\n",
    "    df_signal[s] = (xdata<1e5) & (ydata>1e7)\n",
    "df_signal['product count'] = df_signal.sum(axis=1)\n",
    "df_signal = df_signal.sort_values('product count',ascending=False)\n",
    "# for i,s in enumerate(df.columns.get_level_values('species').unique()):\n",
    "#     df_signal = df_signal.drop(s, 1)\n",
    "# df_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (7,7))\n",
    "ax = plt.hist(df_signal['product count'],bins=24)\n",
    "plt.xlabel('Number of species')\n",
    "plt.ylabel('Number of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal.reset_index(inplace=True)\n",
    "#add intensity\n",
    "df_signal[(df_signal['product count']>2) & (df_signal['mz']>200)].sort_values('max_intensity',ascending=False).to_csv('Pathway_1_Products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df.index.name\n",
    "print df.index.get_values()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 223,217,396\n",
    "filter_col = [col for col in list(atlas_df) if 'Peak height' in col if '_P0_' in col if '223' in col]\n",
    "atlas_df['P0 Intensity'] = atlas_df[filter_col].max(axis=1)\n",
    "filter_col = [col for col in list(atlas_df) if 'Peak height' in col if '_P10_' in col if '223' in col]\n",
    "atlas_df['P10 Intensity'] = atlas_df[filter_col].max(axis=1)\n",
    "filter_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.gca()\n",
    "plt.plot(atlas_df['P0 Intensity']+1,atlas_df['P10 Intensity']+1,'.',markersize=20)\n",
    "plt.xlabel('Wild Type')\n",
    "plt.ylabel('Engineered Strain')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = atlas_df[(atlas_df['P0 Intensity']<1e5)]\n",
    "df = df.sort_values('P10 Intensity',ascending=False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print atlas_df.shape\n",
    "print myAtlas.name\n",
    "atlas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove compounds from an atlas where peak height less than cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = peak_height.max(axis=1)\n",
    "print len(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ancient Codes and Partially Developed Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store data to a pickle file\n",
    "# saved_filename = '/global/homes/b/bpb/Downloads/20160818_POS_MO_HEfungusonly_V1.pkl'\n",
    "# with open(output_filename,'w') as f:\n",
    "#     dill.dump(metatlas_dataset,f)\n",
    "\n",
    "### Load a pre-existing metatlas dataset  \n",
    "# metatlas_dataset = ma_data.get_dill_data(saved_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### copy files to $SCRATCH\n",
    "### You will likely never have to do this, but just in case, here is the code.\n",
    "# from shutil import copyfile\n",
    "# scratch = os.environ['SCRATCH']\n",
    "# for my_group in groups:\n",
    "#     for my_file in my_group.items:\n",
    "#         new_path = os.path.join(scratch,'temp_metatlas')\n",
    "#         if not os.path.isdir(new_path):\n",
    "#             os.mkdir(new_path)\n",
    "#         new_file = os.path.join(new_path,os.path.basename(my_file.hdf5_file))\n",
    "#         copyfile(my_file.hdf5_file, new_file)\n",
    "#         my_file.hdf5_file = new_file\n",
    "#         print my_file.hdf5_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# dp = reload(dp)\n",
    "# pickles = ['/global/homes/b/bpb/Downloads/KZ_Avena_Exudate_atlases_and_groups_1/neg_data.pkl',\n",
    "#           '/global/homes/b/bpb/Downloads/KZ_Avena_Exudate_atlases_and_groups_1/pos_data.pkl',\n",
    "# '/global/homes/b/bpb/Downloads/KZ_Avena_Uptake_atlases_and_group_2/pos_data.pkl',\n",
    "# '/global/homes/b/bpb/Downloads/KZ_Avena_Uptake_atlases_and_group_2/neg_data.pkl']\n",
    "# for p in pickles:\n",
    "#     plot_location_label = p.split('.')[0]+'/'\n",
    "#     print plot_location_label\n",
    "#     if not os.path.exists(plot_location_label):\n",
    "#         os.makedirs(plot_location_label)\n",
    "#     metatlas_dataset = ma_data.get_dill_data(p)\n",
    "#     dp.make_identification_figure(input_dataset = metatlas_dataset, input_fname = p, include_lcmsruns = [],exclude_lcmsruns = ['RootCass','QC','Blank','blank'], output_loc=plot_location_label+'/identification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######### DO NOT USE #######\n",
    "# output_filename = '/global/homes/b/bpb/Downloads/20160531_KBL_C18_Vio_cells_384_Q_1_to_4.pkl'\n",
    "# data = dp.get_data_for_groups_and_atlas(groups,myAtlas,output_filename)\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### DO NOT USE #######\n",
    "### THIS STILL NEEDS SOME REPAIRS ###\n",
    "# rt_corrector.display_atlases()\n",
    "### USE AT YOUR OWN RISK ###\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msmls_files = metob.retrieve('Lcmsruns',experiment = '20161007_KBL_MPZHILIC3um_MSMLS_stds',name = '%pos%',username = '*')\n",
    "# print len(msmls_files)\n",
    "# kate_files = metob.retrieve('Lcmsruns',experiment = '20161007_KBL_MPZHILIC3um_KateStandards',name = '%pos%', username = '*')\n",
    "# print len(kate_files)\n",
    "# g = metob.Group()\n",
    "# g.name = '20161007_MP3umZHILIC_V12_POS_MetIDJamboree'\n",
    "# for f in msmls_files:\n",
    "#     g.items.append(f)\n",
    "# for f in kate_files:\n",
    "#     g.items.append(f)\n",
    "# metob.store([g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep compounds that are removed and let the project know that this compound is below the intensity requirement.\n",
    "peak_height = dp.make_output_dataframe(input_fname = '',input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_height' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "min_intensity = 1e5\n",
    "to_drop = []\n",
    "peak_height.max(axis=1) > min_intensity\n",
    "ids = [myAtlas.compound_identifications[i] for i,b in enumerate(peak_height.max(axis=1) > min_intensity) if b == True]\n",
    "print(len(ids))\n",
    "myAtlas.compound_identifications = ids\n",
    "metob.store(myAtlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "mass spec cori",
   "language": "python",
   "name": "nersc_python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
