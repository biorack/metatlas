{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pactolus on metatlas files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING: Deprecated\n",
    "# use pactolus/pactolus/run_pactolus_on_folder_of_files.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You run it like this\n",
    "\n",
    "```\n",
    "python ../run_pactolus_on_folder_of_files.py --indir /global/project/projectdirs/metatlas/raw_data/kblouie/20150914_actinorhodin_finalset_50mm/ --outfile actinorhodin_jobs.sh\n",
    "```\n",
    "\n",
    "It will make a bunch of compressed csv's in the same directory as your raw data sits.\n",
    "\n",
    "Its a good idea to run the command from an empty sub-directory somewhere because it generates a ton of sbatch files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/metatlas/')\n",
    "sys.path.insert(1,'/global/homes/b/bpb/repos/pactolus/')\n",
    "import pactolus.scoring as pactolus\n",
    "# sys.path.insert(1,'/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages' )\n",
    "\n",
    "from metatlas import metatlas_objects as metob\n",
    "from metatlas.helpers import pactolus_tools as pt\n",
    "from metatlas.helpers import dill2plots as dp\n",
    "from metatlas.helpers import metatlas_get_data_helper_fun as mgd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "\n",
    "from matplotlib import collections as mplib_collections\n",
    "import matplotlib.colors as mpl_colors\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get a file containing Glutamate which elutes at 11.2 minutes\n",
    "files = metob.retrieve('Lcmsruns',name='20161007_MP3umZHILIC_V12___POS_MSMS_KBL_QE139_Plate_1_%',username='*')\n",
    "my_file = files[-1]\n",
    "# raw_data = mgd.df_container_from_metatlas_file(my_file.hdf5_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(0, u'Scoelicolor_media_WT_M145_Day6', datetime.datetime(2017, 6, 20, 19, 14, 37))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = dp.select_groups_for_analysis(name = 'Scoelicolor%Day6',\n",
    "                                       most_recent = True,\n",
    "                                       remove_empty = True,\n",
    "                                       include_list = [], exclude_list = ['Ref','pellet','_Del_'])#['QC','Blank'])\n",
    "files = []\n",
    "for g in groups:\n",
    "    for i in g.items:\n",
    "        files.append(i)\n",
    "len(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call([\"srun -p debug -N 1 -t 00:20:00 -J pactolus -C haswell python /global/homes/b/bpb/pyfile.py \"],shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# b = [1.,2.,3.,4.]\n",
    "# c = 'asdfasdf %s'%(' '.join(map(str,b)))\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash -l\n",
      "#SBATCH --account=m2650\n",
      "#SBATCH --job-name=\"pactolus\"\n",
      "#SBATCH --time=03:59:00\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --output=\"/project/projectdirs/metatlas/projects/logs/pactolus_logs/out.out\"\n",
      "#SBATCH --error=\"/project/projectdirs/metatlas/projects/logs/pactolus_logs/err.out\"\n",
      "#SBATCH --partition=realtime\n",
      "#SBATCH -C haswell\n",
      "#SBATCH -L project\n",
      "python score_pactolus.py --infile 'None' --outfile 'None' --polarity positive --ms2_tolerance 0.0100 --ms1_tolerance 0.0100 --ms1_neutralizations 1.007276 18.033823 22.989218 --ms2_neutralizations -1.00727646677 -2.01510150677 0.00054857990946 --tree_file '/project/projectdirs/metatlas/projects/clean_pactolus_trees/tree_lookup.npy' --num_cores 64 &\n"
     ]
    }
   ],
   "source": [
    "\n",
    "create_job()\n",
    "\n",
    "# job_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call([job_str],shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def dataframe_container_from_metatlas_hdf5_file(my_file):\n",
    "#     data_df = pd.DataFrame()\n",
    "#     pd_h5_file  = pd.HDFStore(my_file)\n",
    "#     keys = pd_h5_file.keys()\n",
    "#     pd_h5_file.close()\n",
    "#     df_container = {}\n",
    "#     for k in keys:\n",
    "#         if ('ms' in k) and not ('_mz' in k):\n",
    "#             new_df = pd.read_hdf(my_file,k)\n",
    "#             df_container[k[1:]] = new_df\n",
    "#     return df_container\n",
    "\n",
    "# def create_msms_dataframe(df):\n",
    "#     \"\"\"\n",
    "#     create a dataframe organized into spectra from a raw dataframe of points\n",
    "#     \"\"\"\n",
    "#     #removed polarity and hdf5_file\n",
    "#     grouped = df.groupby(['precursor_MZ','rt','precursor_intensity','collision_energy']).aggregate(lambda x: tuple(x))\n",
    "#     grouped.mz = grouped.mz.apply(list)\n",
    "#     grouped.i = grouped.i.apply(list)\n",
    "#     grouped = grouped.reset_index()\n",
    "#     grouped['spectrum'] = map(lambda x,y:(x,y),grouped['mz'],grouped['i'])\n",
    "#     grouped['spectrum'] = grouped['spectrum'].apply(lambda x: zip(x[0],x[1]))\n",
    "#     grouped.drop(['mz','i'], axis=1, inplace=True)\n",
    "#     return grouped\n",
    "\n",
    "def do_score(input):\n",
    "    tree_filename = input[0]\n",
    "    max_depth = input[1]\n",
    "    indices = input[2]\n",
    "    spectra = input[3]\n",
    "    params = input[4]\n",
    "    tree,inchikey = get_tree(tree_filename,max_depth=spectra_trees.loc[indices[0],'max_depth'])\n",
    "    output = []\n",
    "    for i,idx in enumerate(indices):\n",
    "        score,match_matrix = pactolus.calculate_MIDAS_score(spectra[i],\n",
    "                                                            tree,\n",
    "                                                            params['ms2_tolerance'],\n",
    "                                                            neutralizations=params['ms2_neutralizations'],\n",
    "                                                            want_match_matrix=True)\n",
    "        output.append((idx,score,inchikey,match_matrix))\n",
    "    return output\n",
    "\n",
    "def assemble_results(r,spectra_trees):\n",
    "    list_concat  =[]\n",
    "    for rr in r:\n",
    "        for jj in rr:\n",
    "            list_concat.append((jj[0],jj[1],jj[2],jj[3]))\n",
    "    return pd.DataFrame(list_concat,columns=['index','score','inchikey','match_matrix'])\n",
    "\n",
    "def get_tree(tree_file,max_depth=None):\n",
    "    \"\"\"\n",
    "    Given a path to an hdf5 tree file, \n",
    "    return the tree at max_depth and the inchikey\n",
    "    \"\"\"\n",
    "    with h5py.File(tree_file,'r') as fid:\n",
    "        inchikey = fid.keys()[0]\n",
    "        if max_depth:\n",
    "            data_key = 'FragTree_at_max_depth=%d'%max_depth\n",
    "        else:\n",
    "            data_key = fid[inchikey].keys()[0]\n",
    "        tree = fid[inchikey][data_key][:]\n",
    "    return tree,inchikey\n",
    "\n",
    "def filtered_spectrum(spectrum,precursor_mz,tolerance):\n",
    "    \"\"\"\n",
    "    remove items in spectrum greather than precursor mz + tolerance\n",
    "    \"\"\"\n",
    "    return [t for t in spectrum if t[0] < (precursor_mz - tolerance)]\n",
    "\n",
    "\n",
    "def setup_inputs(unique_tree_files,spectra_trees,params):\n",
    "    \"\"\"\n",
    "    setup inputs for running pactolus in parallel\n",
    "    \"\"\"\n",
    "    mp_setup = []\n",
    "    for tree_filename,indices in unique_tree_files.items():\n",
    "        temp = []\n",
    "        temp.append(tree_filename)\n",
    "        temp.append(spectra_trees.loc[indices[0],'max_depth'])\n",
    "        temp.append(indices)\n",
    "        temp_spectra = []\n",
    "        for idx in indices:\n",
    "            mz_arr = np.asarray(spectra_trees.loc[idx,'spectrum'])\n",
    "            temp_spectra.append(mz_arr)\n",
    "        temp.append(temp_spectra)\n",
    "        temp.append(params)\n",
    "        mp_setup.append(temp)\n",
    "    return mp_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'ms1_tolerance':0.01,'ms2_tolerance':0.01,\n",
    "          'ms1_neutralizations':[1.007276,18.033823,22.989218],\n",
    "          'ms2_neutralizations':[-1.00727646677,-2.0151015067699998,0.00054857990946]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6046, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectra = mgd.create_msms_dataframe(raw_data['ms2_pos'])\n",
    "\n",
    "###################################\n",
    "######## TEMP for debugging #######\n",
    "# spectra = spectra[(abs(spectra.rt - 11.2)<0.3) &\n",
    "#                  (abs(spectra.precursor_MZ - 148.1)<0.2)]\n",
    "######## TEMP for debugging #######\n",
    "###################################\n",
    "\n",
    "for i,row in spectra.iterrows():\n",
    "    spectra.set_value(i,'spectrum',filtered_spectrum(row.spectrum,row.precursor_MZ,params['ms1_tolerance']))\n",
    "spectra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_file = '/project/projectdirs/metatlas/projects/clean_pactolus_trees/tree_lookup.npy'\n",
    "# trees = pactolus.compound_metadata_from_trees(tree_file)\n",
    "trees = np.load(tree_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('filename',\n",
       " 'ms1_mass',\n",
       " 'inchi',\n",
       " 'permanent_charge',\n",
       " 'num_atoms',\n",
       " 'num_bonds',\n",
       " 'num_fragments',\n",
       " 'max_depth',\n",
       " 'time_to_build')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree_match = []\n",
    "for i,row in spectra.iterrows():\n",
    "    for adduct in params['ms1_neutralizations']:\n",
    "        hits = np.argwhere(abs(trees['ms1_mass'] - (row.precursor_MZ-adduct)) < params['ms1_tolerance']).flatten()\n",
    "        if len(hits)>0:\n",
    "            for h in hits:\n",
    "                tree_match.append((i,trees['filename'][h],trees['max_depth'][h],adduct,params['ms1_tolerance']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precursor_MZ</th>\n",
       "      <th>rt</th>\n",
       "      <th>precursor_intensity</th>\n",
       "      <th>collision_energy</th>\n",
       "      <th>spectrum</th>\n",
       "      <th>tree_filename</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>ms1_neutralization</th>\n",
       "      <th>ms1_tolerance</th>\n",
       "      <th>ms2_tolerance</th>\n",
       "      <th>ms2_neutralizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.059998</td>\n",
       "      <td>0.151029</td>\n",
       "      <td>292054.31250</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(50.1552, 1188.3), (54.0324, 2181.01), (54.03...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[-1.00727646677, -2.01510150677, 0.00054857990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.059998</td>\n",
       "      <td>0.326877</td>\n",
       "      <td>293917.96875</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(54.0324, 2672.91), (54.0348, 58206.3), (55.1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[-1.00727646677, -2.01510150677, 0.00054857990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.059998</td>\n",
       "      <td>0.504052</td>\n",
       "      <td>314578.03125</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(54.0324, 2526.09), (54.0349, 58217.3), (58.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[-1.00727646677, -2.01510150677, 0.00054857990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.059998</td>\n",
       "      <td>1.058288</td>\n",
       "      <td>329977.28125</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(50.9907, 1149.02), (54.0324, 2889.57), (54.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[-1.00727646677, -2.01510150677, 0.00054857990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.059998</td>\n",
       "      <td>2.077559</td>\n",
       "      <td>275257.06250</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(53.3035, 1249.92), (53.7244, 1202.82), (54.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[-1.00727646677, -2.01510150677, 0.00054857990...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precursor_MZ        rt  precursor_intensity  collision_energy  \\\n",
       "0     71.059998  0.151029         292054.31250              20.0   \n",
       "1     71.059998  0.326877         293917.96875              20.0   \n",
       "2     71.059998  0.504052         314578.03125              20.0   \n",
       "3     71.059998  1.058288         329977.28125              20.0   \n",
       "4     71.059998  2.077559         275257.06250              20.0   \n",
       "\n",
       "                                            spectrum tree_filename  max_depth  \\\n",
       "0  [(50.1552, 1188.3), (54.0324, 2181.01), (54.03...           NaN        NaN   \n",
       "1  [(54.0324, 2672.91), (54.0348, 58206.3), (55.1...           NaN        NaN   \n",
       "2  [(54.0324, 2526.09), (54.0349, 58217.3), (58.6...           NaN        NaN   \n",
       "3  [(50.9907, 1149.02), (54.0324, 2889.57), (54.0...           NaN        NaN   \n",
       "4  [(53.3035, 1249.92), (53.7244, 1202.82), (54.0...           NaN        NaN   \n",
       "\n",
       "   ms1_neutralization  ms1_tolerance  ms2_tolerance  \\\n",
       "0                 NaN            NaN           0.01   \n",
       "1                 NaN            NaN           0.01   \n",
       "2                 NaN            NaN           0.01   \n",
       "3                 NaN            NaN           0.01   \n",
       "4                 NaN            NaN           0.01   \n",
       "\n",
       "                                 ms2_neutralizations  \n",
       "0  [-1.00727646677, -2.01510150677, 0.00054857990...  \n",
       "1  [-1.00727646677, -2.01510150677, 0.00054857990...  \n",
       "2  [-1.00727646677, -2.01510150677, 0.00054857990...  \n",
       "3  [-1.00727646677, -2.01510150677, 0.00054857990...  \n",
       "4  [-1.00727646677, -2.01510150677, 0.00054857990...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectra_trees = pd.merge(spectra,\n",
    "         pd.DataFrame(tree_match,columns=['hit_index','tree_filename','max_depth','ms1_neutralization','ms1_tolerance']),how='outer',\n",
    "         left_index=True,\n",
    "         right_on='hit_index').drop('hit_index',1)\n",
    "# spectra_trees['score'] = 0\n",
    "# spectra_trees['match_matrix'] = ''\n",
    "# spectra_trees['match_matrix'] = spectra_trees['match_matrix'].astype(object)\n",
    "spectra_trees['ms2_tolerance'] = params['ms2_tolerance']\n",
    "spectra_trees['ms2_neutralizations'] = ''\n",
    "spectra_trees['ms2_neutralizations'] = spectra_trees['ms2_neutralizations'].astype(object)\n",
    "spectra_trees['ms2_neutralizations'] = spectra_trees.ms2_neutralizations.apply(lambda x: params['ms2_neutralizations'])\n",
    "spectra_trees.reset_index(inplace=True,drop=True)\n",
    "unique_tree_files = spectra_trees.groupby('tree_filename').indices\n",
    "spectra_trees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reshape match matrix to correspond to neutralizations\n",
    "# match_matrix.sum(0)\n",
    "# match_matrix.sum(0).reshape(3,-1).sum(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188209, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectra_trees.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14638"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_tree_files.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-497e32bd5e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'123.123'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'546456'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number"
     ]
    }
   ],
   "source": [
    "float(['123.123','546456'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.65 s, sys: 8.36 s, total: 16 s\n",
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mp_data = setup_inputs(unique_tree_files,spectra_trees,params)\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "p = mp.Pool(32)\n",
    "r = p.map(do_score,mp_data)\n",
    "p.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "temp_hits = assemble_results(r,spectra_trees)\n",
    "temp = pd.merge(spectra_trees,temp_hits,how='outer',left_index=True,right_on='index').drop('index',1)\n",
    "temp.sort_values('score',ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spectra_trees.loc[6754,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spectra_trees.sort_values('score',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tree_filename,indices in unique_tree_files.items():\n",
    "    tree,inchikey = get_tree(tree_filename,max_depth=spectra_trees.loc[indices[0],'max_depth'])\n",
    "    for idx in indices:\n",
    "        mz_arr = np.asarray(spectra_trees.loc[idx,'spectrum'])\n",
    "        score,match_matrix = pactolus.calculate_MIDAS_score(mz_arr,\n",
    "                                                            tree,\n",
    "                                                            params['ms2_tolerance'],\n",
    "                                                            neutralizations=params['ms2_neutralizations'],\n",
    "                                                            want_match_matrix=True)\n",
    "        spectra_trees.set_value(idx,'score',score)\n",
    "        spectra_trees.set_value(idx,'inchikey',inchikey)\n",
    "        spectra_trees.set_value(idx,'match_matrix', match_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spectra_trees.loc[143,'match_matrix'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WHUUTDBJXJRKMK is glutamate\n",
    "spectra_trees.sort_values('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.shape,tree.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pactolus = reload(pactolus)\n",
    "neutralizations = [-1.00727646677,-2.0151015067699998,0.00054857990946]\n",
    "score,match_matrix = pactolus.calculate_MIDAS_score(mz_arr,\n",
    "                                                    tree,\n",
    "                                                    0.01,\n",
    "                                                    neutralizations=neutralizations,\n",
    "                                                    want_match_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parent is C5O4H10N+\n",
    "* 84.04517 --> likely C4ONH6+\n",
    "* 102.0556 --> likeley C4O2H8N+\n",
    "* 130.0502 --> likely C5O3NH8+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mz_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score,match_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_matrix.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in np.argwhere(match_matrix.max(axis=0)):\n",
    "    print(tree[np.where(match_matrix[:,idx[-1]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.reshape(sum(match_matrix),(1,26))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a list of files\n",
    "\n",
    "<strong>Through whatever means, get a list of paths to hdf5 metatlas files.</strong> These files will be read using metatlas data access tools and formated for Pactolus.\n",
    "\n",
    "Typically you will either:\n",
    "* upload a spreadsheet and read in a list of runs\n",
    "* get a list of runs using the \"retrieve\" command in metatlas\n",
    "* get a list of groups using the \"retrieve\" command in metatlas\n",
    "\n",
    "Regardless, preparing the list of full paths to the hdf5 metatlas files is a necessary first step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the files manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%system ls -ltr $SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myfiles = ['/project/projectdirs/metatlas/raw_data/kblouie/20150914_actinorhodin_finalset_50mm/20150910_C18_MeOH_NEG_MSMS_Scoelicolor_media_WT_M145_Day6_3of4___Run61.h5',\n",
    "'/project/projectdirs/metatlas/raw_data/kblouie/20150914_actinorhodin_finalset_50mm/20150910_C18_MeOH_NEG_MSMS_Scoelicolor_media_Ref_TwoNine_Day6_1of4___Run65.h5',\n",
    "'/project/projectdirs/metatlas/raw_data/kblouie/20150914_actinorhodin_finalset_50mm/20150910_C18_MeOH_NEG_MSMS_Scoelicolor_media_Del_TwoFour_Day6_3of4___Run21.h5']\n",
    "\n",
    "my_groups = ['wild type','refactored','deleted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get files from metatlas groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#20160413_Bhedlund_pHILIC_POS_JAD2_GBS_Set1\n",
    "# EMA_%_QE144_50447_20170120\n",
    "temp_group = dp.select_groups_for_analysis(name = '%UV_Fungus_1to10%',\n",
    "                                       most_recent = True,\n",
    "                                       remove_empty = True,#'Strain=SB214'\n",
    "                                       include_list = [], exclude_list = ['QC','Blank'])\n",
    "\n",
    "# temp_group = metob.retrieve('Groups', name = '20160413%GBS%Set1', username='*')\n",
    "my_files = []\n",
    "my_groups = []\n",
    "for i,g in enumerate(temp_group):\n",
    "#     if not '32' in g.name:\n",
    "#         if not '4O' in g.name:\n",
    "    print g.name#,g.last_modified\n",
    "    if (len(g.items) > 0):\n",
    "        for f in g.items:\n",
    "            #print f.hdf5_file\n",
    "            my_files.append(f.hdf5_file)\n",
    "            my_groups.append(g.name)\n",
    "#for f in my_files:\n",
    "#    print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a list of files from \"retrieve\" os LcmsRuns from metatlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_run = metob.retrieve('LcmsRun',experiment='20170718_KBL_SD%',name='%', username='*')\n",
    "my_files = []\n",
    "# (not '_qc-' in m.hdf5_file.lower()) | \n",
    "for m in my_run:\n",
    "    if (not '_qc-' in m.hdf5_file.lower()) & (not '_fps' in m.hdf5_file.lower()) & (not '_tsb' in m.hdf5_file.lower()):\n",
    "        temp = m.hdf5_file.split('MSMS_')[-1]\n",
    "        temp = temp.split('_____')[0]\n",
    "#         print len(temp.split('_')),m.name\n",
    "        if len(temp.split('_')) > 3:\n",
    "            my_files.append( m.hdf5_file )\n",
    "my_files = np.unique(my_files)\n",
    "print len(my_files)\n",
    "f = [os.path.basename(f) for f in my_files]\n",
    "for ff in f:\n",
    "    print ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a list of files from a spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# files = pd.read_csv('phylogenetic c18 files.csv')\n",
    "files = pd.read_excel('all cameron files_RCC_selected (2).xls')\n",
    "# print files.head()\n",
    "all_myfiles = files['full path'].tolist()\n",
    "pat = 'P_halotolerans'\n",
    "myfiles = []\n",
    "for f in all_myfiles:\n",
    "    if pat in f:\n",
    "        myfiles.append(f)\n",
    "print len(myfiles)\n",
    "print myfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify directory for working in\n",
    "\n",
    "The Pactolus jobs can create a large amount of temporary results.  These will likely fill your home directory.  \n",
    "* $SCRATCH\n",
    "* /project/projectdirs/metatlas/projects\n",
    "* /project/projectdirs/openmsi/projects\n",
    "are all good places you can create your folders.\n",
    "\n",
    "I usually create my temporary storage here:\n",
    "\n",
    "<pre><code>target_dir = '/project/projectdirs/openmsi/projects/ben_run_pactolus/test_tools_4'</code></pre>\n",
    "\n",
    "Replace <code>test_tools_4</code> with an appropriately named temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_path = %system echo $SCRATCH\n",
    "root_path = root_path[0]\n",
    "# root_path = root_path.replace('/cscratch1/sd','/scratch2/scratchdirs').replace('/global','')\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = '/project/projectdirs/metatlas/projects/jgi_projects/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# target_dir = os.path.join(root_path,'pactolus_runs','20161011_actinorhodin')\n",
    "target_dir = os.path.join(root_path,'Pactolus_Results_20170718_KBL_SD_Hiroshi_CoCulture')\n",
    "if not os.path.isdir(target_dir):\n",
    "    os.mkdir(target_dir)\n",
    "target_dir\n",
    "#     '/project/projectdirs/openmsi/projects/ben_run_pactolus/20161011_actinorhodin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %cat $target_dir/20161209_SK_Standards_MSMLS_QE144_50447-638867_MS1_MSMS-NEG_MSMLS-P2-RD_IR2_31_31.h5_polarity_0.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%system ls $target_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt = reload(pt)\n",
    "pt.create_pactolus_msms_data_container(my_files,target_dir,3e5,min_rt = 0.5, max_rt = 8.0,make_container=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %system cat /global/cscratch1/sd/bpb/pactolus_runs/Cori_20161031_KBL_C18_HO_SecMet_Plate1to3/*.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('/global/homes/b/bpb/Downloads/pactolus_jobs_20170718_KBL_SD_Hiroshi.sh','w') as fid:\n",
    "    check_path = os.path.join(target_dir,'*.sbatch')\n",
    "    sbatch_files = %system ls $check_path\n",
    "    for s in sbatch_files:\n",
    "        fid.write('%s %s\\n'%('sbatch',s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sbatch_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sf in sbatch_files:\n",
    "    print 'sbatch',sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "df = %squeue -u bpb -p realtime\n",
    "print len(myfiles), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "h = HTML(df.to_html())\n",
    "with open('current_jobs.html', 'w') as my_file:\n",
    "    my_file.write(h.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit your jobs to the Cori realtime queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt = reload(pt)\n",
    "mydirs = ['rexmalm_pos_pellet']\n",
    "for d in mydirs:\n",
    "    root_path = %system echo $SCRATCH\n",
    "    root_path = root_path[0]\n",
    "    target_dir = os.path.join(root_path,'pactolus_runs',d)\n",
    "    print d\n",
    "    my_session = pt.submit_all_jobs(target_dir)#,usr='bpb',pwd='Bron$e00',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of your jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt = reload(pt)\n",
    "jobs = pt.check_job_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%system ls /project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/*.sbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacking on spectral similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/pactolus/')\n",
    "from pactolus import score_frag_dag_wip as sfd\n",
    "sys.path.insert(1,'/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages' )\n",
    "from metatlas import metatlas_objects as metob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select rtreferences.rt_peak, rtreferences.rt_min, rtreferences.rt_max, rtreferences.rt_units, rtreferences.last_modified, rtreferences.username\n",
    "from rtreferences, compoundidentifications, compoundidentifications_rt_references, compoundidentifications_compound, compounds\n",
    "where\n",
    "rtreferences.unique_id = compoundidentifications_rt_references.target_id and\n",
    "compoundidentifications.unique_id = compoundidentifications_rt_references.source_id and\n",
    "compoundidentifications.unique_id = compoundidentifications_compound.source_id and\n",
    "compounds.unique_id = compoundidentifications_compound.target_id and\n",
    "compounds.inchi_key = 'MTCFGRXMJLQNBG-REOHCLBHSA-N'\n",
    "\"\"\"\n",
    "result = [e for e in metob.database.query(q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(entries)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fragmentationreferences.precursor_mz, fragmentationreferences.polarity, fragmentationreferences.collision_energy, fragmentationreferences.technique, fragmentationreferences.username\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select fragmentationreferences.precursor_mz, fragmentationreferences.polarity, fragmentationreferences.collision_energy, fragmentationreferences.technique, fragmentationreferences.username\n",
    "from fragmentationreferences, compoundidentifications, compoundidentifications_frag_references, compoundidentifications_compound, compounds\n",
    "where\n",
    "fragmentationreferences.unique_id = compoundidentifications_frag_references.target_id and\n",
    "compoundidentifications.unique_id = compoundidentifications_frag_references.source_id and\n",
    "compoundidentifications.unique_id = compoundidentifications_compound.source_id and\n",
    "compounds.unique_id = compoundidentifications_compound.target_id and\n",
    "compounds.inchi_key = 'MTCFGRXMJLQNBG-REOHCLBHSA-N'\n",
    "\"\"\"\n",
    "result = [e for e in metob.database.query(q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(entries)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacking on getting the serial jobs to go faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/pactolus/')\n",
    "from pactolus import score_frag_dag_wip as sfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sfd = reload(sfd)\n",
    "container_file = '/project/projectdirs/metatlas/projects/pactolus_runs/20170425_EMA_For_MAGI_PAPER/container_file_polarity_1.h5'\n",
    "sample_file = '20161209_SK_Standards_MSMLS_QE144_50447-638867_MS1_MSMS-POS_MSMLS-PKZ-R9_IR1_148_148.h5'\n",
    "# input_file = container_file + ':' + sample_file\n",
    "tree_file = '/project/projectdirs/metatlas/projects/clean_pactolus_trees/tree_lookup.npy'\n",
    "out_file = '/project/projectdirs/metatlas/projects/magi_paper/test_pactolus.h5'\n",
    "#results is just the score matrix\n",
    "results = sfd.score_main(use_command_line=False,\n",
    "                     ms1_mass_tolerance=0.01,\n",
    "                     ms2_mass_tolerance=0.01,\n",
    "                     max_depth=3,\n",
    "                     neutralizations=[-1.00727646677,-2.0151015067699998,0.00054857990946],\n",
    "                     schedule='',\n",
    "                     trees=tree_file,\n",
    "                     metabolite_database=None,\n",
    "                     input_filepath=container_file,\n",
    "                     input_grouppath=sample_file,\n",
    "                     output_filepath=out_file,\n",
    "                     output_grouppath='asdf',\n",
    "                     match_matrix=False,\n",
    "                     precursor_mz=-1,\n",
    "                     pass_scanmeta=True,\n",
    "                     pass_scans=True,\n",
    "                     loglevel='ERROR', #use ERROR,INFO, or DEBUG\n",
    "                     tempdir='/project/projectdirs/metatlas/projects/pactolus_tempdir',\n",
    "                     clean_tempdir=True,\n",
    "                     clean_output=True,\n",
    "                     pass_compound_meta=False,\n",
    "                     start_barrier=False)\n",
    "# This creates a temp file and that temp file is then converted into the standard pactolus file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%system mkdir /project/projectdirs/metatlas/projects/pactolus_tempdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# jobs = %system cat /project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/*.sbatch | grep 'srun -n 32 -N 1'\n",
    "# for j in jobs:\n",
    "#     print j.replace('srun -n 32 -N 1 python','%run').replace('/tmp/packages/pactolus/','/project/projectdirs/openmsi/projects/ben_run_pactolus/metaiq/pactolus/')\n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %run /project/projectdirs/openmsi/projects/ben_run_pactolus/metaiq/pactolus/score_frag_dag.py --clean_tempdir True --loglevel DEBUG --input \"/project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/container_file_polarity_1.h5:20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_7_HighExp_Media_Fungus__1001_A__Run42.h5\" --neutralizations \"[-1.00727646677,-2.0151015067699998,0.00054857990946]\" --trees /project/projectdirs/openmsi/projects/ben_trees/metacyc_max_depth_5.npy --ms1_mass_tolerance 0.025 --ms2_mass_tolerance 0.025 --max_depth 5 --save \"/project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/pactolus_results_20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_7_HighExp_Media_Fungus__1001_A__Run42.h5\" --precursor_mz -1 --match_matrix False --clean_output True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sys.path.insert(1,'/global/homes/b/bpb/metaiq/pactolus/')\n",
    "# import no_bastet_score_frag_dag as pactolus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scan_list, scan_metadata, experiment_metadata = load_scan_data_hdf5(filepath=input_filepath,\n",
    "#                                                                        grouppath=input_grouppath)\n",
    "\n",
    "# #     # Determine the ms1_mz, i.e., the precursor m/z\n",
    "# #     ms1_mz = scan_metadata['ms1_mz'] if 'ms1_mz' in scan_metadata else None\n",
    "\n",
    "# #     file_lookup_table = load_file_lookup_table(path=trees)\n",
    "\n",
    "# #     # size input variables\n",
    "# #     num_scans = len(scan_list)\n",
    "# #     num_compounds = len(file_lookup_table)\n",
    "\n",
    "# #     results = score_scan_list_against_trees(scan_list=scan_list,\n",
    "# #                                             ms1_mz=ms1_mz,\n",
    "# #                                             file_lookup_table=file_lookup_table,\n",
    "# #                                             neutralizations=neutralizations,\n",
    "# #                                             ms2_mass_tol=ms2_mass_tol,\n",
    "# #                                             ms1_mass_tol=ms1_mass_tol,\n",
    "# #                                             max_depth=max_depth,\n",
    "# #                                             temp_out_group=temp_out_group,\n",
    "# #                                             want_match_matrix=match_matrix,\n",
    "# #                                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# polarity = 0\n",
    "# import os\n",
    "# sfd = '/global/homes/b/bpb/metaiq/pactolus/score_frag_dag.py'\n",
    "# cf = os.path.join(target_dir,'container_file_polarity_%d.h5'%polarity)\n",
    "# import h5py\n",
    "# with h5py.File(cf,'r') as hf:\n",
    "#     dfs = hf.keys()\n",
    "# ofs = [os.path.join(target_dir,'pactolus_results_%s'%f) for f in dfs]\n",
    "\n",
    "# of = ofs[0]\n",
    "# df = dfs[0]\n",
    "# tp = '/project/projectdirs/openmsi/projects/ben_trees/metacyc_max_depth_5.npy'\n",
    "# pos_neut = '[-1.00727646677,-2.0151015067699998,0.00054857990946]'\n",
    "# neg_neut = '[+1.00727646677,+2.0151015067699998,-0.00054857990946]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %system cat $sfd\n",
    "# %system ls -lt $target_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %system ps -lu bpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print job_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# params = (sfd,cf,df,neg_neut,tp,of)\n",
    "# #job_script = '%s --input \"%s:%s\" --neutralizations \"%s\" --trees %s --ms1_mass_tolerance 0.015 --ms2_mass_tolerance 0.015 --max_depth 5 --save \"%s\" --match_matrix False'%params\n",
    "\n",
    "# job_script = '%s --clean_tempdir True --loglevel DEBUG --input \"%s:%s\" --neutralizations \"%s\" --trees %s --ms1_mass_tolerance 0.015 --ms2_mass_tolerance 0.015 --max_depth 5 --save \"%s\" --precursor_mz -1 --match_matrix False --clean_output True'%params\n",
    "# %run $job_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %run /project/projectdirs/openmsi/projects/ben_run_pactolus/metaiq/pactolus/score_frag_dag.py --clean_tempdir True --loglevel DEBUG --input \"/project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/container_file_polarity_1.h5:20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_6_HighExp_Media_Fungus__1001_A__Run30.h5\" --neutralizations \"[-1.00727646677,-2.0151015067699998,0.00054857990946]\" --trees /project/projectdirs/openmsi/projects/ben_trees/metacyc_max_depth_5.npy --ms1_mass_tolerance 0.025 --ms2_mass_tolerance 0.025 --max_depth 5 --save \"/project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/pactolus_results_20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_6_HighExp_Media_Fungus__1001_A__Run30.h5\" --precursor_mz -1 --match_matrix False --clean_output True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %run /project/projectdirs/openmsi/projects/ben_run_pactolus/metaiq/pactolus/score_frag_dag.py --clean_tempdir True --loglevel DEBUG --input \"/project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/container_file_polarity_1.h5:20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_7_HighExp_Media_Fungus__1001_A__Run42.h5\" --neutralizations \"[-1.00727646677,-2.0151015067699998,0.00054857990946]\" --trees /project/projectdirs/openmsi/projects/ben_trees/metacyc_max_depth_5.npy --ms1_mass_tolerance 0.025 --ms2_mass_tolerance 0.025 --max_depth 5 --save \"/project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/pactolus_results_20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_7_HighExp_Media_Fungus__1001_A__Run42.h5\" --precursor_mz -1 --match_matrix False --clean_output True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #%run /project/projectdirs/openmsi/projects/ben_run_pactolus/metaiq/pactolus/score_frag_dag.py --clean_tempdir True --loglevel DEBUG --input \"/project/projectdirs/openmsi/projects/ben_run_pactolus/20160727_OE_TURNBAUGH_Potato2_neg/container_file_polarity_0.h5:20160726_SK-OE_Turnbaugh_Swtpotato2_QE119_C18-R15180_NEG_raw-BR3_IR2_28.h5\" --neutralizations \"[1.00727646677,2.0151015067699998,-0.00054857990946]\" --trees /project/projectdirs/openmsi/projects/ben_trees/metacyc_max_depth_5.npy --ms1_mass_tolerance 0.025 --ms2_mass_tolerance 0.025 --max_depth 5 --save \"/project/projectdirs/openmsi/projects/ben_run_pactolus/20160727_OE_TURNBAUGH_Potato2_neg/pactolus_results_20160726_SK-OE_Turnbaugh_Swtpotato2_QE119_C18-R15180_NEG_raw-BR3_IR2_28.h5\" --precursor_mz -1 --match_matrix False --clean_output True\n",
    "# %run /project/projectdirs/openmsi/projects/ben_run_pactolus/metaiq/pactolus/score_frag_dag.py \n",
    "# --clean_tempdir True \n",
    "# --loglevel DEBUG \n",
    "# --input \"/project/projectdirs/openmsi/projects/ben_run_pactolus/20160727_OE_TURNBAUGH_Potato2_neg/container_file_polarity_0.h5:20160726_SK-OE_Turnbaugh_Swtpotato2_QE119_C18-R15180_NEG_cooked-BR1_IR2_10.h5\" \n",
    "# --neutralizations \"[1.00727646677,2.0151015067699998,-0.00054857990946]\" \n",
    "# --trees /project/projectdirs/openmsi/projects/ben_trees/metacyc_max_depth_5.npy \n",
    "# --ms1_mass_tolerance 0.025 \n",
    "# --ms2_mass_tolerance 0.025 \n",
    "# --max_depth 5 \n",
    "# --save \"/project/projectdirs/openmsi/projects/ben_run_pactolus/20160727_OE_TURNBAUGH_Potato2_neg/pactolus_results_20160726_SK-OE_Turnbaugh_Swtpotato2_QE119_C18-R15180_NEG_cooked-BR1_IR2_10.h5\" \n",
    "# --precursor_mz -1 --match_matrix False --clean_output True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After jobs finish, look for failed runs (missing hdf5 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = pt.check_for_failed_jobs(target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pt = reload(pt)\n",
    "#metatlas_name,neutral_inchi,neutral_mass =pt.get_neutral_inchi_and_name(use_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target_dir = '/project/projectdirs/openmsi/projects/ben_run_pactolus/HighExp_Media_Fungus_pos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "import os\n",
    "import h5py\n",
    "files = glob.glob(os.path.join(target_dir,'*.h5'))\n",
    "for i,f in enumerate(files):\n",
    "    print 'File=%d\\t%s'%(i,os.path.basename(f))\n",
    "    with h5py.File(f,'r') as output_file:\n",
    "        my_keys = output_file.keys()\n",
    "#         counter = 0\n",
    "#         for k in my_keys:\n",
    "#             if 'match_matrix' not in k:\n",
    "#                 counter = counter +1\n",
    "#         try:\n",
    "#             score_matrix = output_file['score_matrix'][:]\n",
    "#             num = score_matrix.shape[0]\n",
    "#         except:\n",
    "#             num = 0\n",
    "        \n",
    "#     print 'File=%d\\tKeys=%d\\tScans=%d\\t%s'%(i,counter,num,os.path.basename(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(target_dir,'pactolus_results_20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_6_HighExp_Media_Fungus__1001_A__Run30.h5')) as output_file:\n",
    "    print output_file.keys()\n",
    "    #[a[0] for a in output_file['tree_file_lookup_table']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt = reload(pt)\n",
    "\n",
    "all_dfs = pt.make_output_tables(target_dir)\n",
    "#,metatlas_name,neutral_inchi,neutral_mass,score_cutoff=0.001,intensity_min=1e5,to_excel=True)\n",
    "#TODO: This takes a surprisingly long time to run for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge_sheets applies a delta mass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pt = reload(pt)\n",
    "\n",
    "my_sheets = glob.glob(os.path.join(target_dir,'pactolus_results_*.csv'))\n",
    "print my_sheets\n",
    "\n",
    "df_all_files = pt.merge_sheets(my_sheets)\n",
    "\n",
    "my_piv=df_all_files.pivot(columns='source_file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_df = pd.read_pickle('/project/projectdirs/openmsi/projects/ben_run_pactolus/unique_compounds.pkl')\n",
    "#df = pd.read_csv('/project/projectdirs/openmsi/projects/compound_data/jgi_molecules/new_jgi_compounds.csv')\n",
    "# df.rename(columns = {'monoisotopoic_mw':'monoisotopic_mw'},inplace=True)\n",
    "\n",
    "print ref_df.keys()\n",
    "print df_all_files.keys()\n",
    "print df_all_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp= df_all_files.reset_index()\n",
    "# pd.merge(restaurant_ids_dataframe, restaurant_review_frame, on='business_id', how='outer')\n",
    "\n",
    "big_data = pd.merge(temp,ref_df,on='inchi_key')#.reset_index()\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "print big_data.shape\n",
    "big_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_data.to_csv(os.path.join(target_dir,'named_pactolus_all_results_out.csv'))#, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_piv.to_csv(os.path.join(target_dir,'pactolus_pivot_out.csv'))#, index=False)\n",
    "df_all_files.to_csv(os.path.join(target_dir,'pactolus_all_results_out.csv'))#, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_piv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "def make_tarball(output_dir,do_timestr=True,csv_only=False):\n",
    "    if do_timestr:\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\") + '_'\n",
    "    else:\n",
    "        timestr = ''\n",
    "    tarball_name = timestr + os.path.basename(os.path.normpath(output_dir)) + '.tar.gz'\n",
    "    if not csv_only:\n",
    "        %system tar -zcf $tarball_name -C $output_dir .\n",
    "    else:\n",
    "        temp = os.path.join(output_dir,'*.csv')\n",
    "        %system tar -zcf $tarball_name $temp\n",
    "    print 'done'\n",
    "    from IPython.core.display import display, HTML\n",
    "    f1 = os.path.join(os.getcwd(), tarball_name).replace('/global/u2/b/bpb','/user/bpb/notebooks')\n",
    "    print f1\n",
    "    f2 = tarball_name\n",
    "    display(HTML('<a href=\"%s\" download=\"%s\">Start automatic download!</a>'%(f1,f2)))\n",
    "make_tarball(target_dir,csv_only=True)\n",
    "# https://jupyter-dev.nersc.gov/user/bpb/files/notebooks/Pactolus%20Tools/20161108-131105_20161011_actinorhodin.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "intensity = my_piv['precursor intensity']\n",
    "files = intensity.keys()\n",
    "print files\n",
    "# plt.plot(intensity[files[2]],intensity[files[1]],'.')\n",
    "# ax = plt.gca()\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_xlabel(files[0])\n",
    "# ax.set_ylabel(files[1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-import just the pivot if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_piv = pd.read_csv(os.path.join(target_dir,'pactolus_pivot_out.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# import a network layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pt = reload(pt)\n",
    "# network = pt.import_network()\n",
    "def network_cyjs_to_dataframe(network_file='network_v1p0.cyjs'):\n",
    "    import json\n",
    "    with open(network_file) as data_file:    \n",
    "        data = json.load(data_file)\n",
    "    nodes = pd.DataFrame(data['elements']['nodes'])\n",
    "    node_data = pd.DataFrame(nodes.data.to_dict()).T\n",
    "    node_position = pd.DataFrame(nodes.position.to_dict()).T\n",
    "    node_data = node_data.join(node_position)\n",
    "    node_data.x = node_data.x.astype(float)\n",
    "    node_data.y = node_data.y.astype(float)\n",
    "    \n",
    "    edges = pd.DataFrame(data['elements']['edges'])\n",
    "    edge_data = pd.DataFrame(edges.data.to_dict()).T\n",
    "\n",
    "    edge_data.source = edge_data.source.astype(int)\n",
    "    edge_data.target = edge_data.target.astype(int)\n",
    "    node_data.SUID = node_data.SUID.astype(int)\n",
    "\n",
    "    edge_data = edge_data.merge(node_data[['SUID','x','y']], how='inner', left_on='source', right_on='SUID')\n",
    "    edge_data.rename(columns={'x':'source_x','y':'source_y'},inplace=True)\n",
    "    edge_data = edge_data.merge(node_data[['SUID','x','y']], how='inner', left_on='target', right_on='SUID')\n",
    "    edge_data.rename(columns={'x':'target_x','y':'target_y'},inplace=True)\n",
    "\n",
    "    return (node_data,edge_data)\n",
    "\n",
    "(nodes,edges) = network_cyjs_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_data2 = pd.merge(big_data,nodes,on='inchi_key')#.reset_index()\n",
    "big_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = []\n",
    "segs = []\n",
    "\n",
    "norm = mpl_colors.Normalize(vmin=edges.weight.min(), vmax=edges.weight.max())\n",
    "cmap = plt.cm.plasma\n",
    "my_color = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "for i,row in edges.iterrows():\n",
    "    colors.append(my_color.to_rgba(row.weight))\n",
    "    segs.append(( (row.source_x, row.source_y),\n",
    "                 (row.target_x,row.target_y) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,15),facecolor='black')\n",
    "ax = plt.gca()\n",
    "\n",
    "myMarker = [0.299324789, 0.960615657, 0.2439362] #'aqua'# #'aqua'\n",
    "myEdges = [0.126700401, 0.00487433, 0.32941519] #\n",
    "\n",
    "plt.scatter(nodes['x'],nodes['y'], s=4, c='white', alpha=0.015,lw = 0)\n",
    "\n",
    "vertices = list(zip(zip(edges.source_x,edges.source_y),zip(edges.target_x,edges.target_y)))\n",
    "\n",
    "ln_coll = mplib_collections.LineCollection(segs,colors = colors,alpha = 1,linewidth=1)\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "# fyi: if you don't draw the scatter points then you need to set the axes limits manually\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map my_piv inchi_key to str.contains() for nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(myfiles)\n",
    "my_piv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(33,\n",
    "  'pactolus_results_20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_5_HighExp_Media_Fungus__1001_A__Run24.csv'),\n",
    " (58,\n",
    "  'pactolus_results_20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_14_HighExp_Media_Control_Conditioned_1001_A__Run18.csv'),\n",
    "     (64,\n",
    "  'pactolus_results_20160629_C18_ACN___POS_MSMS_KBL_MO_Qex_UV_1_LowExp_Media_Fungus__1001_A__Run21.csv'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_piv.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_table = my_piv[['Unnamed: 0','precursor intensity']]\n",
    "small_table = small_table[small_table['precursor intensity'] > 0]\n",
    "small_table.rename(columns = {'Unnamed: 0':'inchi_key'}, inplace = True)\n",
    "small_table.drop(0,inplace=True)\n",
    "small_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my_file = my_piv.columns.get_level_values(1)[0]\n",
    "# print my_file\n",
    "# small_table = my_piv['precursor intensity'][my_file].reset_index()\n",
    "# small_table = small_table[np.isfinite(small_table[my_file])]\n",
    "small_table = my_piv[['Unnamed: 0','precursor intensity']]\n",
    "small_table = small_table[small_table['precursor intensity'] > 0]\n",
    "small_table.rename(columns = {'Unnamed: 0':'inchi_key'}, inplace = True)\n",
    "small_table.drop(0,inplace=True)\n",
    "\n",
    "print small_table.shape\n",
    "# small_table.head()\n",
    "for i,row in small_table.iterrows():\n",
    "    idx = nodes.inchi_key.str.contains(row.inchi_key)\n",
    "    if sum(idx) > 0:\n",
    "        small_table.loc[i,'x'] = nodes[idx]['x'].tolist()[0]\n",
    "        small_table.loc[i,'y'] = nodes[idx]['y'].tolist()[0]\n",
    "\n",
    "# pos = small_table.inchi_key.apply(lambda x: nodes[nodes.inchi_key.str.contains(x)][['x','y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hits not in network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_in_network = small_table[~np.isfinite(small_table['x'])]\n",
    "not_in_network.to_csv('solar_pactolus_hits_not_in_network.csv')\n",
    "# nodes[nodes.inchi_key.str.contains(small_table.inchi_key.tolist()[0])][['x','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_table = small_table[np.isfinite(small_table['x'])]\n",
    "small_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import collections as mplib_collections\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig = plt.figure(figsize=(50,50),facecolor='cornsilk')\n",
    "ax = plt.gca()\n",
    "\n",
    "myMarker = [0.299324789, 0.960615657, 0.2439362] #'aqua'# #'aqua'\n",
    "myEdges = [0.126700401, 0.00487433, 0.32941519] #\n",
    "\n",
    "plt.scatter(nodes['x'],nodes['y'], s=0.1, c='white', alpha=0.015,lw = 0)\n",
    "\n",
    "vertices = list(zip(zip(edges.source_x,edges.source_y),zip(edges.target_x,edges.target_y)))\n",
    "\n",
    "ln_coll = mplib_collections.LineCollection(segs,colors = colors,alpha = 0.251,linewidth=2)\n",
    "\n",
    "ax.add_collection(ln_coll)\n",
    "# fyi: if you don't draw the scatter points then you need to set the axes limits manually\n",
    "norm = mpl.colors.Normalize(vmin=small_table[my_file].min()**0.5, vmax=small_table[my_file].max()**0.5)\n",
    "cmap = cm.viridis\n",
    "my_color = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "# plt.scatter(small_table['x'],small_table['y'], s=12, c='white', alpha=1,lw = 0)\n",
    "plt.scatter(small_table['x'],small_table['y'], s=20, c=my_color.to_rgba(small_table[my_file]**0.5), alpha=1,lw = 0)\n",
    "\n",
    "# for i,row in small_table.iterrows():\n",
    "#     plt.text(row.x,row.y,row['metatlas name'])\n",
    "\n",
    "# plt.xlim(-150000,-80000)\n",
    "# plt.ylim(40000,100000)\n",
    "# plt.axis('off')\n",
    "temp= my_file.replace('pactolus_results_','').replace('.xls','')\n",
    "ax.set_title(temp.replace('.csv',''),color='b',fontsize=14)\n",
    "plt.show()\n",
    "fig.savefig('HighExp_Media_Control.pdf',facecolor='cornsilk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import collections as mplib_collections\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import os\n",
    "my_groups = files\n",
    "sub_string = os.path.commonprefix(files)\n",
    "new_groups = [s.replace(sub_string,'').replace('Set','') for s in my_groups]\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "cmap = cm.plasma\n",
    "\n",
    "my_color = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "#w,h\n",
    "fig = plt.figure(figsize=(15,30),facecolor='black')\n",
    "\n",
    "num_files = 2#len(list(set(my_piv.columns.get_level_values(1).tolist())))\n",
    "# print p.index.get_level_values(0)\n",
    "# p.xs('precursor intensity',axis=1,level=0)[p.columns.get_level_values(1)[0]]\n",
    "for iii in range(num_files):\n",
    "    my_file = my_piv.columns.get_level_values(1)[iii]\n",
    "#     print my_file\n",
    "    small_table = my_piv['precursor intensity'][my_file]\n",
    "    # df_all_files.reset_index(inplace=True,drop=True)\n",
    "    # df_all_files.head()\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    df = pd.DataFrame(small_table).fillna(0).reset_index()\n",
    "    names = df[df[my_file]>0]['metatlas name'].tolist()\n",
    "    print df.keys()\n",
    "    vals = np.asarray(df[df[my_file]>0][my_file])\n",
    "\n",
    "    idx = np.argwhere(vals > 0).flatten()\n",
    "    temp = vals[idx]\n",
    "    temp = np.log10(temp)\n",
    "    temp = temp - np.min(temp)\n",
    "    temp = temp / np.max(temp)\n",
    "    vals[idx] = temp\n",
    "\n",
    "\n",
    "    M = np.zeros((len(network['node_name'])))\n",
    "    idx = []\n",
    "    not_found = 0\n",
    "    for i,n in enumerate(network['node_name']):\n",
    "        try:\n",
    "            idx = names.index(n)\n",
    "            M[i] = vals[idx]\n",
    "        except:\n",
    "            not_found += 1\n",
    "#     print not_found, i, len(vals)\n",
    "\n",
    "    plt.subplot(2,1,iii+1)\n",
    "    myMarker = [0.299324789, 0.960615657, 0.2439362] #'aqua'# #'aqua'\n",
    "    myEdges = [0.126700401, 0.00487433, 0.32941519] #\n",
    "    idx_z = np.argwhere(M[:] == 0).flatten()\n",
    "    idx_nz = np.argwhere(M[:] > 0.2).flatten()\n",
    "#     plt.plot(network['x'][idx_z],network['y'][idx_z],'o',markersize=1, markeredgecolor='k', markerfacecolor = 'k',alpha=0.3)\n",
    "    plt.scatter(network['x'][idx_nz],network['y'][idx_nz], s=10, c=my_color.to_rgba(M[idx_nz]), alpha=1,lw = 0)\n",
    "    plt.scatter(network['x'][idx_z],network['y'][idx_z], s=1, c='blue', alpha=0.1,lw = 0)\n",
    "#     plt.plot(network['x'][idx_nz],network['y'][idx_nz],'o',markersize=2, markeredgecolor=my_color.to_rgba(M[idx_nz]), markerfacecolor = my_color.to_rgba(M[idx_nz]))\n",
    "    colors = []\n",
    "    segs = []\n",
    "    for e in network['data']['elements']['edges']:\n",
    "        idx1 = np.argwhere(network['node_id'] == float(e['data']['source']))[0][0]\n",
    "        idx2 = np.argwhere(network['node_id'] == float(e['data']['target']))[0][0]\n",
    "        colors.append('grey')\n",
    "        segs.append(( (network['x'][idx1], network['y'][idx1]),\n",
    "                     (network['x'][idx2], network['y'][idx2]) ))\n",
    "\n",
    "    ln_coll = mplib_collections.LineCollection(segs, colors=colors,alpha=0.3)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.add_collection(ln_coll)\n",
    "    \n",
    "    temp= my_file.replace('pactolus_results_','').replace('.xls','')\n",
    "    a = [g for i,g in enumerate(new_groups) if temp in myfiles[i]]\n",
    "    \n",
    "    if 'blank' in my_file:\n",
    "        ax.set_title('blank',color='w')\n",
    "    elif a:\n",
    "        ax.set_title(a[0],color='w')#my_file.replace('pactolus_results_','').replace('.xls','').replace('20150322','').replace('20151124','').replace('_MSMS_','').replace('','').replace('pHILIC_',''),color='w')\n",
    "    else:\n",
    "        ax.set_title(temp,color='w')\n",
    "    # fig.set_facecolor('w')\n",
    "    # ax.set_xlim(0, 600)    \n",
    "    # ax.set_ylim(0, 400)\n",
    "    # plt.draw()\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(my_file.replace('pactolus_results_','').replace('.xls','')+'_networks_from_pactolus.pdf',facecolor='black')\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_string = os.path.commonprefix([my_piv.columns.get_level_values(1)[iii] for iii in range(39)])\n",
    "for iii in range(num_files):\n",
    "    my_file = my_piv.columns.get_level_values(1)[iii]\n",
    "    small_table = my_piv['precursor intensity'][my_file]\n",
    "    df = pd.DataFrame(small_table).fillna(0).reset_index()\n",
    "    vals = np.asarray(df[df[my_file]>0][my_file])\n",
    "\n",
    "    idx = np.argwhere(vals > 0.2).flatten()\n",
    "    \n",
    "#     temp= my_file.replace('pactolus_results_','').replace('.xls','')\n",
    "#     a = [g for i,g in enumerate(new_groups) if temp in myfiles[i]]\n",
    "\n",
    "    print len(idx),'\\t','','\\t',my_file.replace(sub_string,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for iii in range(39):\n",
    "    my_file = my_piv.columns.get_level_values(1)[iii]\n",
    "#     print my_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#compound found in all replicates of groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_files = len(list(set(my_piv.columns.get_level_values(1).tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "MetAtlas 2.7",
   "language": "python",
   "name": "metatlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
