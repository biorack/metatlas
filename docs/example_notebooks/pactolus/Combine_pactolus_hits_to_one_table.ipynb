{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/metatlas/')\n",
    "# sys.path.insert(1,'/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages' )\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import metatlas.metatlas_objects as metob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import glob\n",
    "# %matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "from metatlas.helpers import mzmine_helpers as mzm\n",
    "from metatlas.helpers import pactolus_tools as pt\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# peak_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/20160824_C18_LIPID___POS_mzmine_output.csv'\n",
    "# peak_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/Scoelicolor_media_WT_mzmine_output.csv'\n",
    "# peak_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/Psim_super_C18_pos_mzmine_output.csv'\n",
    "# peak_file = '/global/homes/b/bpb/Psim_super_C18_pos_mzmine_output_456peaks.csv'\n",
    "# Psim_pellet_C18_neg\n",
    "# hedlund_jad2_and_media\n",
    "\n",
    "# peak_file = '/project/projectdirs/metatlas/projects/mzmine_parameters/Psim_super_C18_neg_mzmine_output.csv'\n",
    "\n",
    "# pactolus_results = '/scratch2/scratchdirs/bpb/pactolus_runs/hedlund_jad2_and_media/'\n",
    "# pactolus_results = '/global/cscratch1/sd/bpb/pactolus_runs/rexmalm_pos_super/'\n",
    "# pactolus_results = '/global/project/projectdirs/metatlas/projects/jgi_projects/Pactolus_Results_20170512_SK_-MR_SupprSoils_EthylAc2/'\n",
    "# pactolus_results = '/project/projectdirs/metatlas/projects/jgi_projects/SolarPanel/Pactolus_Results_20160824_KBL_SolarPanel_MP/'\n",
    "# pactolus_results = '/project/projectdirs/metatlas/projects/jgi_projects/Pactolus_Results_20170718_KBL_SD_Hiroshi_CoCulture/'\n",
    "pactolus_results = '/global/project/projectdirs/metatlas/raw_data/kblouie/20150914_actinorhodin_finalset_50mm/'\n",
    "# ctolus_results = '/project/projectdirs/metatlas/projects/pactolus_runs/20170317_SK_Arkin_PseudoAbxCsource/'\n",
    "\n",
    "\n",
    "# my_polarity = 'negative'\n",
    "\n",
    "import glob as glob\n",
    "trees = glob.glob('/global/cscratch1/sd/bpb/level_3_trees/*.h5')\n",
    "ref_df = pd.read_pickle('/project/projectdirs/metatlas/projects/magi_paper/unique_compounds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_path = '/project/projectdirs/metatlas/projects/jgi_projects/Coelicolor_Day6_MAGI_paper/'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.path.mkdir(output_path)\n",
    "output_pickle = os.path.join(output_path,'pactolus_hits.pkl')\n",
    "output_csv = os.path.join(output_path,'pactolus_hits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "pactolus_files = [f for f in glob.glob(os.path.join(pactolus_results,'*.h5')) if 'pactolus_results' in os.path.basename(f.lower())]\n",
    "print len(pactolus_files)\n",
    "# pactolus_files = [f for f in glob.glob(pactolus_results+'*.h5') if 'pactolus_results_' in f.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pt.read_pacolus_results(pactolus_files[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pactolus_results = '/global/cscratch1/sd/bpb/pactolus_runs/Cori_20161209_Manuel_SolarPanel'\n",
    "max_processes = 64\n",
    "pt = reload(pt)\n",
    "pool = mp.Pool(processes=min(max_processes, len(pactolus_files)))\n",
    "output = pool.map(pt.read_pacolus_results, pactolus_files)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "for i,f in enumerate(pactolus_files):\n",
    "    fname = os.path.basename(f).split('.')[0]\n",
    "    output[i][0]['filename'] = fname\n",
    "#output has scan_df,tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# important to note that compound==0 is a spectrum with no pactolus hits\n",
    "msms_df = pd.concat([df[0] for df in output], axis=0)\n",
    "msms_df.rename(columns={'precursor mz':'precursor_mz','retention time':'retention_time','index':'spectrum_index'},inplace=True)\n",
    "msms_df['compound'] = msms_df['compound'].fillna(0.0).astype(int)\n",
    "msms_df['compound_index'] = msms_df['compound']\n",
    "msms_df.reset_index(inplace=True)\n",
    "msms_df = msms_df.drop(['index'],1)\n",
    "msms_df['score'].fillna(0,inplace=True)\n",
    "msms_df['compound'].fillna(0,inplace=True)\n",
    "msms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pactolus_path = '/project/projectdirs/metatlas/projects/pactolus_runs/'\n",
    "# pactolus_file = 'pactolus_results_20161209_SK_Standards_MSMLS_QE144_50447-638867_MS1_MSMS-POS_MSMLS-PKZ-R9_IR1_148_148.h5'\n",
    "# import h5py\n",
    "# min_score=0\n",
    "# with h5py.File('/project/projectdirs/metatlas/projects/magi_paper/pactolus_results/pactolus_results_20161209_SK_Standards_MSMLS_QE144_50447-638867_MS1_MSMS-POS_MSMLS-PKZ-R9_IR1_148_148.h5','r') as fid:\n",
    "# #read score_matrix, convert all by all matrix to lists of scores\n",
    "#     idx = range(fid['score_matrix'].shape[0])  \n",
    "#     d = {'retention time':fid['scan_metadata']['peak_rt'][idx],\n",
    "#         'precursor intensity':fid['scan_metadata']['peak_intensity'][idx],\n",
    "#         'precursor mz':fid['scan_metadata']['peak_mz'][idx],\n",
    "#         'polarity': fid['scan_metadata']['polarity'][idx],\n",
    "#         'index': idx}\n",
    "#     scan_df = pd.DataFrame(d)\n",
    "#     scan_df['filename'] = pactolus_file\n",
    "\n",
    "#     m = fid['score_matrix'][:]\n",
    "#     hits = []\n",
    "#     for mm in m:\n",
    "#         idx = np.where(mm>min_score)[0]\n",
    "#         hits.append(sorted([(mm[i],i) for i in idx])[::-1])\n",
    "#     df = pd.DataFrame({'scores':hits})\n",
    "#     b_flat = pd.DataFrame([[i, x[0], x[1]] \n",
    "#                        for i, y in df.scores.apply(list).iteritems() \n",
    "#                        for x in y], columns=['index','score','compound']).set_index('index')\n",
    "#     scan_df = scan_df.merge(b_flat, how = 'outer',left_index=True, right_index=True)\n",
    "\n",
    "#     #get a list of True/False if any hits for a compound:\n",
    "#     f = np.any(m.T>min_score,axis=1)\n",
    "#     #only do this for ones that get a hit\n",
    "#     idx = np.where(f)[0]#range(fid['score_matrix'].shape[1])\n",
    "# #     lookup = fid['tree_file_lookup_table'][:]\n",
    "#     d = {'filename': fid['tree_file_lookup_table']['filename'][idx],\n",
    "#          'ms1_mass': fid['tree_file_lookup_table']['ms1_mass'][idx],\n",
    "#          'inchi': fid['tree_file_lookup_table']['inchi'][idx],\n",
    "#          'permanent_charge': fid['tree_file_lookup_table']['permanent_charge'][idx],\n",
    "#           'index': idx}\n",
    "# #     get inchikey like this:\n",
    "#     d['inchi_key'] = [os.path.basename(a).split('.')[0].split('_')[-1] for a in fid['tree_file_lookup_table']['filename'][idx]]\n",
    "\n",
    "#     tree_df = pd.DataFrame(d)\n",
    "#     # tree_df.set_index('index',drop=True,inplace=True)\n",
    "# #     return scan_df,tree_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compound_df = pd.concat([df[1] for df in output], axis=0)\n",
    "compound_df.drop_duplicates(inplace=True)\n",
    "compound_df.set_index('index',drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_use = list(set(ref_df.columns.tolist())  - set(compound_df.columns.tolist()))\n",
    "cols_to_use.append('inchi_key')\n",
    "\n",
    "compound_df2 = compound_df.reset_index().merge(ref_df[cols_to_use],on='inchi_key',how='inner').reset_index().set_index('index').drop(['level_0'],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compound_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "temp = msms_df.merge(compound_df2,how='left',left_on='compound',right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.inchi_key.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp.to_pickle('/global/homes/b/bpb/Downloads/pseudo5_pactolus.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove peaks that are outside of mz tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_ppm(theoretical_mass,measured_mz,adduct_masses):\n",
    "    \"\"\"\n",
    "    given theoretical mass vector, measured mz vector, and adduct mass vector\n",
    "    return the ppm\n",
    "    #### TODO: add in the adduct names and with an argmin list the adduct name for pactolus hit ####\n",
    "\n",
    "    Note: \n",
    "    theoretical_mass and measured_mz must be [N,1] where N is the number\n",
    "    of features.\n",
    "    adduct_masses must be [1,M] where M is the number of adducts\n",
    "    typical adduct masses for positive mode are [0, 1.007276]\n",
    "    typical adduct masses negative mode are [-1.007276]\n",
    "\n",
    "    \"\"\"\n",
    "    measured_mz = np.outer(measured_mz,np.ones(adduct_masses.shape))\n",
    "    theoretical_mass = np.outer(theoretical_mass,np.ones(adduct_masses.shape))\n",
    "    mz_neutralizations = np.outer(np.ones(measured_mz.shape[0]),adduct_masses)\n",
    "    mass_difference = abs(measured_mz - mz_neutralizations - theoretical_mass)\n",
    "    ppm_difference = np.divide(mass_difference,theoretical_mass)*1e6\n",
    "    return ppm_difference.min(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = temp['polarity'] == 1\n",
    "temp['detected_polarity'] = ''\n",
    "\n",
    "temp.loc[idx,'detected_polarity'] = 'positive' #this sets things up for metatlas\n",
    "adduct_masses = np.asarray([1.007276]) #assume [M+] and [M+H] are the adducts\n",
    "\n",
    "temp.loc[idx,'ppm'] = calculate_ppm(temp[idx]['mono_isotopic_molecular_weight'].values,\n",
    "                                    temp[idx]['precursor_mz'].values,\n",
    "                                   adduct_masses)\n",
    "idx = temp['polarity'] == 0\n",
    "temp.loc[idx,'detected_polarity'] = 'negative' #this sets things up for metatlas\n",
    "adduct_masses = np.asarray([-1.007276]) #assume [M-H] are the adducts\n",
    "temp.loc[idx,'ppm'] = calculate_ppm(temp[idx]['mono_isotopic_molecular_weight'].values,\n",
    "                                    temp[idx]['precursor_mz'].values,\n",
    "                                   adduct_masses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp.ppm.hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_filtered = temp[temp.ppm < 10].copy()\n",
    "fig = plt.figure()\n",
    "temp_filtered.ppm.hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_filtered.rename(columns={'inchi_key':'original_compound','score':'compound_score'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(temp_filtered.original_compound.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_filtered.to_pickle(output_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_filtered.to_csv(output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pactolus_df.fillna(0,inplace=True)\n",
    "# peak_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# see if compounds are in ema atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ema_df_pos = pd.read_pickle('/project/projectdirs/metatlas/projects/magi_paper/ema_pos_hilic_atlas_50447.pkl')\n",
    "ema_df_neg = pd.read_pickle('/project/projectdirs/metatlas/projects/magi_paper/ema_neg_hilic_atlas_50447.pkl')\n",
    "inchikeys = list(set(ema_df_pos.inchi_key.tolist() + ema_df_neg.inchi_key.tolist()))\n",
    "len(inchikeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pactolus_inchikeys = temp_filtered.inchi_key.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(list(set(inchikeys) - set(pactolus_inchikeys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(list(set([i.split('-')[0] for i in inchikeys]) - set([i.split('-')[0] for i in pactolus_inchikeys])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_filtered[(abs(temp_filtered.precursor_mz - 222.097213)<0.001)].sort_values('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected = temp_filtered[(temp_filtered.filename_x.str.contains('20161209_SK_Standards_MSMLS_QE144_50447-638867_MS1_MSMS-NEG_MSMLS-P1-RH_IR2_22_22')) &\n",
    "                         (abs(temp_filtered.precursor_mz - 220.0827)<0.01) & \n",
    "              (temp_filtered.detected_polarity == 'negative') &\n",
    "              (abs(temp_filtered.retention_time - 5.5)<200.5)].sort_values('score',ascending=False)\n",
    "selected[['inchi_key','ppm','score','name','retention_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ema_df = pd.read_pickle('/project/projectdirs/metatlas/projects/magi_paper/ema_posneg_monoisotopicweights.pkl')\n",
    "msms = []\n",
    "for i,row in ema_df.iterrows():\n",
    "    temp = pd.DataFrame(row.msms)\n",
    "    temp['key'] = i\n",
    "    msms.append(temp)\n",
    "msms = pd.concat(msms)\n",
    "msms_ema_df = pd.merge(ema_df[[c for c in ema_df.columns if not 'msms' in c]],msms,how='inner',left_index=True,right_on='key')\n",
    "msms_ema_df.to_csv('/global/u2/b/bpb/Downloads/ema_pos_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,row in ema_df.iterrows():\n",
    "    matching = temp_filtered[(temp_filtered.inchi_key.str.contains(row.inchi_key.split('-')[0])) &\n",
    "#                     (temp_filtered.precursor_mz > (row.mz - row.mz*25/row.mz/1e6)) & \n",
    "#                     (temp_filtered.precursor_mz < (row.mz + row.mz*25/row.mz/1e6)) &\n",
    "                    (temp_filtered.retention_time > row.rt_min-0.2) & \n",
    "                    (temp_filtered.retention_time < row.rt_max+0.2) ]\n",
    "    if (matching.shape[0] == 0) & (row.msms != []):\n",
    "        print 'msms=',row.msms != [], row.adduct, '%.4f'%row.mz,'%.2f'%row.rt_peak,row.label,row.inchi_key,\n",
    "        print [os.path.basename(f) for f in row.filenames]\n",
    "        print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,row in ema_df.iterrows():\n",
    "    matching = temp_filtered[(temp_filtered.inchi_key.str.contains(row.inchi_key.split('-')[0])) &\n",
    "#                     (temp_filtered.precursor_mz > (row.mz - row.mz*25/row.mz/1e6)) & \n",
    "#                     (temp_filtered.precursor_mz < (row.mz + row.mz*25/row.mz/1e6)) &\n",
    "                    (temp_filtered.retention_time > row.rt_min-0.2) & \n",
    "                    (temp_filtered.retention_time < row.rt_max+0.2) ]\n",
    "    if (matching.shape[0] == 0) & (row.msms != []):\n",
    "        print 'msms=',row.msms != [], row.adduct, '%.4f'%row.mz,'%.2f'%row.rt_peak,row.label,row.inchi_key,\n",
    "        print [os.path.basename(f) for f in row.filenames]\n",
    "        print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ema_df[ema_df.label=='BETAINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp[temp.inchi_key.str.contains('OEYIOHPDSNJKLS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bpb@edison09:/project/projectdirs/metatlas/projects/pactolus_trees> \n",
    "# cp /project/projectdirs/openmsi/projects/level_3_trees/*.h5 .\n",
    "# cp /project/projectdirs/openmsi/projects/ben_trees/*.h5 .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%system ls -f /project/projectdirs/metatlas/projects/clean_pactolus_trees/ | grep OVRNDRQMDRJTHS-ZTVVOAFPSA-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%system ls -f /project/projectdirs/openmsi/projects/level_3_trees/ | grep OVRNDRQMDRJTHS-ZTVVOAFPSA-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('/project/projectdirs/openmsi/projects/level_3_trees/FragTreeLibrary_test_hdf5_3_OVRNDRQMDRJTHS-ZTVVOAFPSA-N.h5') as fid:\n",
    "    k = fid.keys()\n",
    "    print k\n",
    "    k2 = fid[k[0]].keys()\n",
    "    print k2\n",
    "    k3 = fid[k[0]][k2[0]]\n",
    "    print k3\n",
    "    \n",
    "with h5py.File('/project/projectdirs/metatlas/projects/clean_pactolus_trees/FragTreeLibrary_test_hdf5_5_OVRNDRQMDRJTHS-ZTVVOAFPSA-N.h5') as fid:\n",
    "    k = fid.keys()\n",
    "    print k\n",
    "    k2 = fid[k[0]].keys()\n",
    "    print k2\n",
    "    k3 = fid[k[0]][k2[0]]\n",
    "    print k3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp[(temp_filtered.precursor_mz > (104.10699 - 104.10699)*25/row.mz/1e6) & \n",
    "                    (temp_filtered.precursor_mz > (row.mz - row.mz)*25/row.mz/1e6) &\n",
    "                    (temp_filtered.retention_time > row.rt_min-0.2) & \n",
    "                    (temp_filtered.retention_time < row.rt_max+0.2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.load('/project/projectdirs/openmsi/projects/level_3_trees/tree_lookup.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%system ls -l /project/projectdirs/openmsi/projects/ben_trees/*.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('/project/projectdirs/metatlas/projects/mzmine_parameters/actinorhodin_dataset.pkl')\n",
    "# df.to_csv('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp[temp.synonyms.fillna('').str.contains('prodigiosin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# temp_filtered.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def take_best_hit(df_in,compound_df,mz_tolerance,mz,polarity):\n",
    "#     \"\"\"\n",
    "#     given a dataframe take the hits and filename and return sorted scores with only the highest score remaining\n",
    "#     \"\"\"\n",
    "    \n",
    "#     all_hits = [hh + (f,mz,compound_df.loc[hh[1],'ms1_mass'],) for (h,f) in zip(df_in['hits'],df_in['filename']) for hh in h]\n",
    "#     all_hits = sorted(all_hits)[::-1]\n",
    "#     if polarity == 'positive':\n",
    "#         multiplier = 1\n",
    "#     else:\n",
    "#         multiplier = -1\n",
    "        \n",
    "#     #remove hits that have a ppm difference greater than a threshold\n",
    "#     all_hits = [h for h in all_hits if abs(h[3] - h[4] - (multiplier * 1.007276))/h[4]*1e6 < mz_tolerance]\n",
    "      \n",
    "#     df = pd.DataFrame(all_hits,columns=['score','compound_idx','filename','mz','mass'])\n",
    "#     df[df['score'] == df.groupby(['compound_idx'])['score'].transform(max)] #take only the highest pactolus score\n",
    "#     return [tuple(r) for r in df.values]\n",
    "\n",
    "\n",
    "# peak_df['compound_indices'] = hits #This references the indices in compound_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove peaks that don't have msms in any file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# peak_has_msms = [False if h=='no msms' else True for h in hits]\n",
    "# peak_df = peak_df[peak_has_msms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# peak_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# items_as_cols = df.apply(lambda x: pd.Series(x['samples']), axis=1)\n",
    "# # Keep original df index as a column so it's retained after melt\n",
    "# items_as_cols['orig_index'] = items_as_cols.index\n",
    "\n",
    "# melted_items = pd.melt(items_as_cols, id_vars='orig_index', \n",
    "#                        var_name='sample_num', value_name='sample')\n",
    "# melted_items.set_index('orig_index', inplace=True)\n",
    "\n",
    "# df.merge(melted_items, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of hits\n",
    "# Score of best hit\n",
    "# Avg Score\n",
    "# Median Score\n",
    "# Number of hits within 50% of best hit\n",
    "# List of compound names from top hits (<N)\n",
    "# Show the full info for the best hit\n",
    "# export hit tables for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# peak_df['num_pactolus_hits'] = peak_df.compound_indices.apply(lambda x: len(x))\n",
    "# def pactolus_stats(x):\n",
    "#     best_score = None\n",
    "#     worst_score = None\n",
    "#     avg_score = None\n",
    "#     median_score = None\n",
    "#     best_score_file = None\n",
    "#     best_score_precursor_mz = None\n",
    "#     best_score_precursor_mass = None\n",
    "#     best_score_compound_idx = None\n",
    "#     if x:\n",
    "#         best_score = x[0][0]\n",
    "#         worst_score = x[-1][0]\n",
    "#         avg_score = np.mean([xx[0] for xx in x])\n",
    "#         median_score = np.median([xx[0] for xx in x])\n",
    "#         best_score_file = x[0][2]\n",
    "#         best_score_precursor_mass = x[0][4]\n",
    "#         best_score_precursor_mz = x[0][3]\n",
    "#         best_score_compound_idx = int(x[0][1])\n",
    "        \n",
    "\n",
    "#     return pd.Series({'best_score':best_score,\n",
    "#                       'worst_score':worst_score,\n",
    "#                       'avg_score':avg_score,\n",
    "#                       'median_score':median_score,\n",
    "#                       'best_score_file':best_score_file,\n",
    "#                       'best_score_precursor_mz':best_score_precursor_mz,\n",
    "#                       'best_score_precursor_mass':best_score_precursor_mass,\n",
    "#                       'best_score_compound_idx':best_score_compound_idx\n",
    "#                      })\n",
    "   \n",
    "# temp = peak_df.compound_indices.apply(pactolus_stats)\n",
    "# peak_df[temp.columns] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# peak_df = peak_df.merge(compound_df2, how='inner',left_on='best_score_compound_idx', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# peak_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# peak_df.drop('compound_indices',1).to_csv('~/Downloads/peak_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make pactolus table: feature ID, compound info, pactolus score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# N=100\n",
    "# items_as_cols = peak_df.head(N).apply(lambda x: pd.Series(x['compound_indices']), axis=1)\n",
    "# # Keep original df index as a column so it's retained after melt\n",
    "# items_as_cols['orig_index'] = items_as_cols.index\n",
    "\n",
    "# melted_items = pd.melt(items_as_cols, id_vars='orig_index', var_name='sample_num', value_name='compound_indices')['compound_indices']\n",
    "\n",
    "# tuple_cols = ['pactolus_score','compound_index','pactolus_file','precursor_mass','precursor_mz']\n",
    "# temp = pd.DataFrame(melted_items.head(),columns=tuple_cols)\n",
    "\n",
    "# # melted_items[]\n",
    "# # temp = melted_items['compound_indices'].apply(pd.Series)\n",
    "# # melted_items.set_index('orig_index', inplace=True)\n",
    "# # df2 = df.head(N).merge(melted_items, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# items_as_cols = peak_df.head(N).apply(lambda x: pd.Series(x['compound_indices']), axis=1)\n",
    "# temp = pd.melt(items_as_cols).value.apply(pd.Series)\n",
    "# temp.columns = tuple_cols\n",
    "# temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp = melted_items.to_frame()['compound_indices'].apply(pd.Series)\n",
    "# temp.columns = tuple_cols\n",
    "# temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compound_df2.ix[[h[1] for h in peak_df.loc[5,'compound_indices']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Number of hits\n",
    "* Score of best hit\n",
    "* Avg Score\n",
    "* Median Score\n",
    "* Number of hits within 50% of best hit\n",
    "* Show the full info for the best hit\n",
    "* export hit tables for each feature\n",
    "\n",
    "* delete hit table colum from peak_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# best_hit_df = pd.DataFrame(columns=compound_df2.columns)\n",
    "# empty_df = pd.DataFrame(columns=compound_df2.columns)\n",
    "\n",
    "# for i in range(10):\n",
    "#     print i\n",
    "#     idx = peak_df.loc[i,'compound_indices']\n",
    "# #     if idx:\n",
    "#     best_hit_df.append(compound_df2.ix[[idx[2]]])#,ignore_index=True,)\n",
    "# #     else:\n",
    "# #         best_hit_df.append(empty_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# best_hit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### long term, export three views to an interactive webpage\n",
    "* Feature table, when a row is selected:\n",
    "* populates a pactolus hit table, when a row is selected:\n",
    "* populates a chem_network table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # import numpy as np\n",
    "# # import pandas as pd\n",
    "# from textwrap import wrap\n",
    "# HEADER = '''\n",
    "# <link rel=\"stylesheet\" type=\"text/css\" href=\"http://cdn.datatables.net/1.10.13/css/jquery.dataTables.css\">\n",
    "# <style>\n",
    "\n",
    "# </style>\n",
    "# <script src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js\" type=\"text/javascript\"></script>\n",
    "# <script type=\"text/javascript\" charset=\"utf8\" src=\"http://cdn.datatables.net/1.10.13/js/jquery.dataTables.js\"></script>\n",
    "# <html>\n",
    "#     <head>\n",
    "#         <script >\n",
    "#             $(document).ready( function () { $('#table_id').DataTable() } );\n",
    "#         </script>\n",
    "#     </head>\n",
    "#     <body>\n",
    "# '''\n",
    "# FOOTER = '''\n",
    "#     </body>\n",
    "# </html>\n",
    "\n",
    "\n",
    "# <script type=\"text/javascript\" >\n",
    "#     $(document).ready( function () {\n",
    "#     $('#table_id').DataTable();\n",
    "# } );\n",
    "# </script>\n",
    "# '''\n",
    "\n",
    "# # title = ax.set_title(\"\\n\".join(wrap(\"Some really really long long long title I really really need - and just can't - just can't - make it any - simply any - shorter - at all.\", 60)))\n",
    "# # df.rename(columns=lambda x: x[1:], inplace=True)\n",
    "\n",
    "# with open('test.html', 'w') as f:\n",
    "#     f.write(HEADER)\n",
    "#     f.write(compound_df2.ix[[h[1] for h in peak_df.loc[1,'compound_indices']]].to_html(classes='df').replace('class=\"dataframe df\"','id=\"table_id\" class=\"hover\"').replace('border=\"1\"','td {word-wrap: break-word}'))\n",
    "# #     f.write(peak_df.rename(columns=lambda x: \"\\n\".join(wrap(x,25))).head(100).to_html(classes='df').replace('class=\"dataframe df\"','id=\"table_id\" class=\"hover\"').replace('border=\"1\"','td {word-wrap: break-word}'))\n",
    "#     f.write(FOOTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "MetAtlas 2.7",
   "language": "python",
   "name": "metatlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
