{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Atlas to Database\n",
    "## Parameters\n",
    "The next code block sets parameters that are used throughout the remainder of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Required: atlas data in table format (csv or tsv) to be deposited, direct path\n",
    "atlas_file_name = \"\"\n",
    "\n",
    "# Required: name to assign to atlas, string without spaces\n",
    "atlas_name = \"\"\n",
    "\n",
    "# Optional: value for mz_tolerance in ppm - defaults to keep input column values or use 5.0 ppm if not specified in input table\n",
    "mz_tolerance = None\n",
    "\n",
    "# Optional: specify the polarity if it's not a column in the input atlas table - defaults to keep input column value or infers from adducts\n",
    "polarity = None\n",
    "\n",
    "# Optional: choose to sort the atlas by RT and MZ in ascending order\n",
    "sort_atlas = True\n",
    "\n",
    "# Optional: is the atlas to be deposited an internal standard atlas (i.e., with unlabeled and labeled compounds)?\n",
    "istd_atlas = False\n",
    "\n",
    "# Optional: run a check to see if the number of compounds in deposited atlas matches number in input atlas\n",
    "# defaulted to False because it can take a non-trivial amount of time for larger atlases\n",
    "run_retrieval_check = False\n",
    "\n",
    "############ The rest of this block contains project independent parameters\n",
    "\n",
    "# to use an older version of the metatlas source code, set this to a commit id,\n",
    "# branch name, or tag. If None, then use the the \"main\" branch.\n",
    "source_code_version_id = None\n",
    "\n",
    "# Threshold for how much status information metatlas functions print in the notebook\n",
    "# levels are 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'\n",
    "log_level = \"INFO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "assert atlas_file_name is not None\n",
    "assert atlas_name is not None\n",
    "\n",
    "logger = logging.getLogger(\"metatlas.jupyter\")\n",
    "\n",
    "kernel_def = \"\"\"{\"argv\":[\"shifter\",\"--entrypoint\",\"--image=ghcr.io/biorack/metatlas/metatlas_shifter:latest\",\"/usr/local/bin/python\",\"-m\",\n",
    "                 \"ipykernel_launcher\",\"-f\",\"{connection_file}\"],\"display_name\": \"Metatlas Targeted\",\"language\": \"python\",\n",
    "                 \"metadata\": { \"debugger\": true }}\"\"\"\n",
    "kernel_file_name = Path.home() / \".local\" / \"share\" / \"jupyter\" / \"kernels\" / \"metatlas-targeted\" / \"kernel.json\"\n",
    "try:\n",
    "    has_root_kernel = Path(\"/root/.local/share/jupyter/kernels/papermill/kernel.json\").is_file()\n",
    "except PermissionError:\n",
    "    has_root_kernel = False\n",
    "if not has_root_kernel and not kernel_file_name.is_file():\n",
    "    kernel_file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with kernel_file_name.open(mode=\"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(kernel_def)\n",
    "    logger.critical('CRITICAL: Notebook kernel has been installed. Set kernel to \"Metatlas Targeted\" and re-run notebook.')\n",
    "    raise StopExecution\n",
    "try:\n",
    "    from metatlas.tools import notebook\n",
    "except ImportError as err:\n",
    "    logger.critical('CRITICAL: Set notebook kernel to \"Metatlas Targeted\" and re-run notebook.')\n",
    "    raise StopExecution from err\n",
    "\n",
    "# Check if any required variables are None\n",
    "if atlas_file_name == \"\" or atlas_name == \"\":\n",
    "    raise SystemExit(\"Exiting notebook due to unset variables in cell 1.\")\n",
    "\n",
    "notebook.setup(log_level, source_code_version_id)\n",
    "from metatlas.plots.dill2plots import make_atlas_from_table\n",
    "from metatlas.io.metatlas_get_data_helper_fun import make_atlas_df,sort_atlas_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlas sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if sort_atlas == True:\n",
    "    deposit_atlas_file_name = sort_atlas_table(atlas_file_name, \"rt_peak\", 'mz', istd_atlas)    \n",
    "else:\n",
    "    deposit_atlas_file_name = atlas_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlas generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logger.info('Reading in atlas from ' + deposit_atlas_file_name + ' and depositing to MySQL database at NERSC')\n",
    "\n",
    "atlas = make_atlas_from_table(deposit_atlas_file_name, atlas_name, store=True, mz_tolerance=mz_tolerance, polarity=polarity)\n",
    "logger.info('Making atlas df from ' + atlas.name + ' for downstream checks')\n",
    "atlas_df = make_atlas_df(atlas)\n",
    "display(Markdown(f\"### Atlas unique_id: {atlas.unique_id}\"))\n",
    "display(Markdown(f\"### Atlas name: {atlas.name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deposit check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if run_retrieval_check == True:\n",
    "\n",
    "    import pandas as pd\n",
    "    from metatlas.datastructures.utils import get_atlas\n",
    "\n",
    "    def atlas_id_to_df(atlas_unique_id: str) -> pd.DataFrame:\n",
    "        \"\"\"Retrieve atlas from database using unique id and create DataFrame from compound identification data.\"\"\"\n",
    "\n",
    "        atlas = get_atlas(atlas_unique_id)\n",
    "\n",
    "        atlas_df = make_atlas_df(atlas)\n",
    "\n",
    "        return atlas_df\n",
    "    \n",
    "    # Ensure atlas can be retrieved from database\n",
    "    retrieved_atlas_df = atlas_id_to_df(atlas.unique_id)\n",
    "    \n",
    "    # Convert input atlas to df\n",
    "    input_atlas_df = pd.read_csv(deposit_atlas_file_name)\n",
    "    \n",
    "    # Check dataframe dims against expectations\n",
    "    if input_atlas_df.shape[0] == retrieved_atlas_df.shape[0]:\n",
    "        \n",
    "        logger.info('Input and deposited atlas have the same number of compounds.')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        logger.info('Warning! Input and deposited atlas do not have the same number of compounds.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Metatlas Targeted",
   "language": "python",
   "name": "metatlas-targeted"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
