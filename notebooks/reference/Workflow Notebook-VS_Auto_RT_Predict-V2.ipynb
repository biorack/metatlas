{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Python Packages\n",
    "\n",
    "To install the kernel used by NERSC-metatlas users, copy the following text to $HOME/.ipython/kernels/mass_spec_cori/kernel.json\n",
    "\n",
    "```\n",
    "{\n",
    " \"argv\": [\n",
    "  \"/global/common/software/m2650/python-cori/bin/python\",\n",
    "  \"-m\",\n",
    "  \"IPython.kernel\",\n",
    "  \"-f\",\n",
    "  \"{connection_file}\"\n",
    " ],\n",
    " \"env\": {\n",
    "    \"PATH\": \"/global/common/software/m2650/python-cori/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\"\n",
    " },\n",
    " \"display_name\": \"mass_spec_cori\",\n",
    " \"language\": \"python\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown, display, clear_output, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "%matplotlib inline\n",
    "%env HDF5_USE_FILE_LOCKING=FALSE\n",
    "import sys, os\n",
    "\n",
    "#### add a path to your private code if not using production code ####\n",
    "#print ('point path to metatlas repo')\n",
    "sys.path.insert(0,\"/global/homes/v/vrsingan/repos/metatlas\") #where your private code is\n",
    "######################################################################\n",
    "\n",
    "from metatlas.plots import dill2plots as dp\n",
    "from metatlas.io import metatlas_get_data_helper_fun as ma_data\n",
    "from metatlas.plots import chromatograms_mp_plots as cp\n",
    "from metatlas.plots import chromplotplus as cpp\n",
    "from metatlas.datastructures import metatlas_objects as metob\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import operator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set atlas, project and output directories from your nersc home directory\n",
    "\n",
    "1. Create a project folder name for this analysis by replacing the PROJECTDIRECTORY string text in red below.  Make sure to update the rest of the direcory to point to your home directory.  The pwd block will print out the directory where this jupyter notebook is stored.\n",
    "2. Create a subdirectory name for the output, each run through you may want to create a new output folder.\n",
    "3. When you run the block the folders will be created in your home directory.  If the directory already exists, the block will just set the path for use with future code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_directory='/global/homes/FIRST-INITIAL-OF-USERNAME/USERNAME/PROJECTDIRECTORY/'  # <- edit this line, do not copy the path directly from NERSC (ex. the u1, or u2 directories)\n",
    "output_subfolder='HILIC_POS_20190830/'  # <- edit this as 'chromatography_polarity_yyyymmdd/'\n",
    "output_dir = os.path.join(project_directory,output_subfolder)\n",
    "output_data_qc = os.path.join(output_dir,'data_QC')\n",
    "\n",
    "if not os.path.exists(project_directory):\n",
    "    os.makedirs(project_directory)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if not os.path.exists(output_data_qc):\n",
    "    os.makedirs(output_data_qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select groups and get QC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = dp.select_groups_for_analysis(name = '%20201106%505892%HILIC%KLv1%',\n",
    "                                       most_recent = True,\n",
    "                                       remove_empty = True,\n",
    "                                       include_list = ['QC'], exclude_list = ['NEG'])  #['QC','Blank']\n",
    "groups = sorted(groups, key=operator.attrgetter('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = pd.DataFrame(columns=['file','time','group'])\n",
    "for g in groups:\n",
    "    for f in g.items:\n",
    "        if hasattr(f, 'acquisition_time'):\n",
    "            file_df = file_df.append({'file':f, 'time':f.acquisition_time,'group':g}, ignore_index=True)\n",
    "        else:\n",
    "            file_df = file_df.append({'file':f, 'time':0,'group':g}, ignore_index=True)\n",
    "\n",
    "file_df = file_df.sort_values(by=['time'])\n",
    "for file_data in file_df.iterrows():\n",
    "    print(file_data[1].file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get template QC atlas from database\n",
    "\n",
    "Available templates in Database:\n",
    "\n",
    "Index  Atlas_name(POS)\\\n",
    "0   HILICz150_ANT20190824_TPL_EMA_Unlab_POS\\\n",
    "1   HILICz150_ANT20190824_TPL_QCv3_Unlab_POS\\\n",
    "2   HILICz150_ANT20190824_TPL_ISv5_Unlab_POS\\\n",
    "3   HILICz150_ANT20190824_TPL_ISv5_13C15N_POS\\\n",
    "4   HILICz150_ANT20190824_TPL_IS_LabUnlab2_POS\n",
    "\n",
    "Index  Atlas_name(NEG)\\\n",
    "0   HILICz150_ANT20190824_TPL_EMA_Unlab_NEG\\\n",
    "1   HILICz150_ANT20190824_TPL_QCv3_Unlab_NEG\\\n",
    "2   HILICz150_ANT20190824_TPL_ISv5_Unlab_NEG\\\n",
    "3   HILICz150_ANT20190824_TPL_ISv5_13C15N_NEG\\\n",
    "4   HILICz150_ANT20190824_TPL_IS_LabUnlab2_NEG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS BLOCK\n",
    "pos_templates = ['HILICz150_ANT20190824_TPL_EMA_Unlab_POS',\n",
    "'HILICz150_ANT20190824_TPL_QCv3_Unlab_POS',\n",
    "'HILICz150_ANT20190824_TPL_ISv5_Unlab_POS',\n",
    "'HILICz150_ANT20190824_TPL_ISv5_13C15N_POS',\n",
    "'HILICz150_ANT20190824_TPL_IS_LabUnlab2_POS']\n",
    "\n",
    "neg_templates = ['HILICz150_ANT20190824_TPL_EMA_Unlab_NEG',\n",
    "'HILICz150_ANT20190824_TPL_QCv3_Unlab_NEG',\n",
    "'HILICz150_ANT20190824_TPL_ISv5_Unlab_NEG',\n",
    "'HILICz150_ANT20190824_TPL_ISv5_13C15N_NEG',\n",
    "'HILICz150_ANT20190824_TPL_IS_LabUnlab2_NEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atlas File Name \n",
    "QC_template_filename = pos_templates[1]\n",
    "\n",
    "atlases = metob.retrieve('Atlas',name=QC_template_filename,\n",
    "                         username='vrsingan')\n",
    "names = []\n",
    "for i,a in enumerate(atlases):\n",
    "    print(i,a.name,pd.to_datetime(a.last_modified,unit='s'),len(a.compound_identifications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Alternatively use this block to create QC atlas from spreadsheet\n",
    "# import datetime\n",
    "#dp = reload(dp)\n",
    "\n",
    "# QC_template_filename = \" \" #<- Give the template filename to be used for storing in Database\n",
    "\n",
    "#myAtlas = dp.make_atlas_from_spreadsheet('/global/project/projectdirs/metatlas/projects/1_TemplateAtlases/TemplateAtlas_HILICz150mm_Annotation20190824_QCv3_Unlabeled_Positive.csv',\n",
    "#                                       QC_template_filename,\n",
    "#                                        filetype='csv',\n",
    "#                                        sheetname='',\n",
    "#                                        polarity = 'positive',\n",
    "#                                        store=True,\n",
    "#                                       mz_tolerance = 20)\n",
    "#atlases = dp.get_metatlas_atlas(name=QC_template_filename,do_print = True,most_recent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAtlas = atlases[-1]\n",
    "atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "atlas_df['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "print(myAtlas.name)\n",
    "print(myAtlas.username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. Uncomment the block below to adjust RT window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rt_allowance = 1.5\n",
    "# atlas_df['rt_min'] = atlas_df['rt_peak'].apply(lambda rt: rt-rt_allowance)\n",
    "# atlas_df['rt_max'] = atlas_df['rt_peak'].apply(lambda rt: rt+rt_allowance)\n",
    "# for compound in range(len(myAtlas.compound_identifications)):\n",
    "#     rt_peak = myAtlas.compound_identifications[compound].rt_references[0].rt_peak\n",
    "#     myAtlas.compound_identifications[compound].rt_references[0].rt_min = rt_peak - rt_allowance\n",
    "#     myAtlas.compound_identifications[compound].rt_references[0].rt_max = rt_peak + rt_allowance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create metatlas dataset from QC files and QC atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for file_data in file_df.iterrows():\n",
    "    all_files.append((file_data[1].file,file_data[1].group,atlas_df,myAtlas))\n",
    "pool = mp.Pool(processes=min(4, len(all_files)))\n",
    "t0 = time.time()\n",
    "metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "#If you're code crashes here, make sure to terminate any processes left open.\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5b Optional: Filter atlas for compounds with no or low signals\n",
    "\n",
    "Uncomment the below 3 blocks to filter the atlas.\n",
    "Please ensure that correct polarity is used for the atlases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp = reload(dp)\n",
    "# num_data_points_passing = 3\n",
    "# peak_height_passing = 1e4\n",
    "# atlas_df_passing = dp.filter_atlas(atlas_df=atlas_df, input_dataset=metatlas_dataset, num_data_points_passing = num_data_points_passing, peak_height_passing = peak_height_passing)\n",
    "# print(\"# Compounds in Atlas: \"+str(len(atlas_df)))\n",
    "# print(\"# Compounds passing filter: \"+str(len(atlas_df_passing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas_passing = myAtlas.name+'_filteredby-datapnts'+str(num_data_points_passing)+'-pkht'+str(peak_height_passing)\n",
    "# myAtlas_passing = dp.make_atlas_from_spreadsheet(atlas_df_passing,\n",
    "#                           atlas_passing,\n",
    "#                           filetype='dataframe',\n",
    "#                           sheetname='',\n",
    "#                           polarity = 'positive',\n",
    "#                           store=True,\n",
    "#                           mz_tolerance = 20)\n",
    "\n",
    "# atlases = dp.get_metatlas_atlas(name=atlas_passing,do_print = True, most_recent=True)\n",
    "\n",
    "# myAtlas = atlases[-1]\n",
    "# atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "# atlas_df['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "# print(myAtlas.name)\n",
    "# print(myAtlas.username)\n",
    "# metob.to_dataframe([myAtlas])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_files = []\n",
    "# for file_data in file_df.iterrows():\n",
    "#     all_files.append((file_data[1].file,file_data[1].group,atlas_df,myAtlas))\n",
    "# pool = mp.Pool(processes=min(4, len(all_files)))\n",
    "# t0 = time.time()\n",
    "# metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "# pool.close()\n",
    "# pool.terminate()\n",
    "# #If you're code crashes here, make sure to terminate any processes left open.\n",
    "# print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summarize RT peak across files and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "dp=reload(dp)\n",
    "rts_df = dp.make_output_dataframe(input_dataset = metatlas_dataset, fieldname='rt_peak', use_labels=True, output_loc = output_data_qc, summarize=True)\n",
    "rts_df.to_csv(os.path.join(output_data_qc,\"QC_Measured_RTs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Compound atlas RTs plot and choose file for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "from __future__ import division\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "rows = int(math.ceil((rts_df.shape[0]+1)/8))\n",
    "cols = 8\n",
    "fig = plt.figure()\n",
    "\n",
    "gs = gridspec.GridSpec(rows, cols, figure=fig, wspace=1, hspace=2)\n",
    "\n",
    "\n",
    "rts_df_copy = rts_df.sort_values(by='standard deviation', ascending=False, na_position='last')\n",
    "\n",
    "i = 0\n",
    "for line, (index, row) in enumerate(rts_df_copy.iterrows()):\n",
    "    if not np.isnan(row[:-7]).all():\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        ax.tick_params(direction='out', length=1, pad=0.3, width=0.1, labelsize=0.5)\n",
    "        ax.scatter(range(rts_df.shape[1]-7),row[:-7], s=0.2)\n",
    "        i += 1\n",
    "        ticks_loc = np.arange(0,len(rts_df.columns)-7 , 1.0)\n",
    "        ax.set_xlim(-0.5,len(rts_df.columns)-7+0.5)\n",
    "        ax.xaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\n",
    "        ax.set_yticks(ax.get_yticks().tolist())\n",
    "        ax.set_ylim(np.nanmin(row[:-7])-0.12,np.nanmax(row[:-7])+0.12)\n",
    "        [i.set_linewidth(0.1) for i in ax.spines.values()]\n",
    "        ax.set_title(row.name, fontsize=0.1)\n",
    "        ax.set_xlabel('Files', fontsize=1)\n",
    "        ax.set_ylabel('Actual RTs', fontsize=1)\n",
    "\n",
    "plt.savefig(os.path.join(output_data_qc, 'Compound_Atlas_RTs.pdf'), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,a in enumerate(rts_df.columns):\n",
    "    print(i, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_column=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Create RT adjustment model - Linear & Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "actual_rts, pred_rts, polyfit_rts = [],[],[]\n",
    "\n",
    "current_actual_df = rts_df.loc[:,rts_df.columns[selected_column]]\n",
    "bad_qc_compounds = np.where(~np.isnan(current_actual_df))\n",
    "current_actual_df = current_actual_df.iloc[bad_qc_compounds]\n",
    "current_pred_df = atlas_df.iloc[bad_qc_compounds][['rt_peak']]\n",
    "actual_rts.append(current_actual_df.values.tolist())\n",
    "pred_rts.append(current_pred_df.values.tolist())\n",
    "\n",
    "ransac = RANSACRegressor(random_state=42)\n",
    "rt_model_linear = ransac.fit(current_pred_df, current_actual_df)\n",
    "coef_linear = rt_model_linear.estimator_.coef_[0]\n",
    "intercept_linear = rt_model_linear.estimator_.intercept_\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "X_poly = poly_reg.fit_transform(current_pred_df)\n",
    "rt_model_poly = LinearRegression().fit(X_poly, current_actual_df)\n",
    "coef_poly = rt_model_poly.coef_\n",
    "intercept_poly = rt_model_poly.intercept_\n",
    "\n",
    "for i in range(rts_df.shape[1]-5):\n",
    "    current_actual_df = rts_df.loc[:,rts_df.columns[i]]\n",
    "    bad_qc_compounds = np.where(~np.isnan(current_actual_df))\n",
    "    current_actual_df = current_actual_df.iloc[bad_qc_compounds]\n",
    "    current_pred_df = atlas_df.iloc[bad_qc_compounds][['rt_peak']]\n",
    "    actual_rts.append(current_actual_df.values.tolist())\n",
    "    pred_rts.append(current_pred_df.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot actual vs predict RT values and fit a  median coeff+intercept line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User can change to use particular qc file\n",
    "import itertools\n",
    "import math\n",
    "from __future__ import division\n",
    "from matplotlib import gridspec\n",
    "\n",
    "x = list(itertools.chain(*pred_rts))\n",
    "y = list(itertools.chain(*actual_rts))\n",
    "\n",
    "rows = int(math.ceil((rts_df.shape[1]+1)/5))\n",
    "cols = 5\n",
    "fig = plt.figure(constrained_layout=False)\n",
    "\n",
    "gs = gridspec.GridSpec(rows, cols, figure=fig)\n",
    "plt.rc('font', size=6)\n",
    "plt.rc('axes', labelsize=6)\n",
    "plt.rc('xtick', labelsize=3)\n",
    "plt.rc('ytick', labelsize=3)\n",
    "\n",
    "\n",
    "for i in range(rts_df.shape[1]-5):\n",
    "    x = list(itertools.chain(*pred_rts[i]))\n",
    "    y = actual_rts[i]\n",
    "    \n",
    "    ax = fig.add_subplot(gs[i])\n",
    "    ax.scatter(x, y, s=2)\n",
    "    ax.plot(np.linspace(0, max(x),100), coef_linear*np.linspace(0,max(x),100)+intercept_linear, linewidth=0.5,color='red')\n",
    "    ax.plot(np.linspace(0, max(x),100), (coef_poly[1]*np.linspace(0,max(x),100))+(coef_poly[2]*(np.linspace(0,max(x),100)**2))+intercept_poly, linewidth=0.5,color='green')\n",
    "    ax.set_title(\"File: \"+str(i))\n",
    "    ax.set_xlabel('predicted RTs')\n",
    "    ax.set_ylabel('actual RTs')\n",
    "    \n",
    "fig_legend = \"FileIndex       FileName\"\n",
    "for i in range(rts_df.shape[1]-5):\n",
    "    fig_legend = fig_legend+\"\\n\"+str(i)+\"        \"+rts_df.columns[i]\n",
    "\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.text(0,-0.03*rts_df.shape[1], fig_legend, transform=plt.gcf().transFigure)\n",
    "plt.savefig(os.path.join(output_data_qc, 'Actual_vs_Predicted_RTs.pdf'), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Choose your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qc_df = rts_df[[rts_df.columns[selected_column]]]\n",
    "qc_df = qc_df.copy()\n",
    "print(\"Linear Parameters :\", coef_linear, intercept_linear)\n",
    "print(\"Polynomial Parameters :\", coef_poly,intercept_poly)\n",
    "\n",
    "qc_df.columns = ['RT Measured']\n",
    "atlas_df.index = qc_df.index\n",
    "qc_df['RT Reference'] = atlas_df['rt_peak']\n",
    "qc_df['RT Linear Pred'] = qc_df['RT Reference'].apply(lambda rt: coef_linear*rt+intercept_linear)\n",
    "qc_df['RT Polynomial Pred'] = qc_df['RT Reference'].apply(lambda rt: (coef_poly[1]*rt)+(coef_poly[2]*(rt**2))+intercept_poly) \n",
    "qc_df['RT Diff Linear'] = qc_df['RT Measured'] - qc_df['RT Linear Pred']\n",
    "qc_df['RT Diff Polynomial'] = qc_df['RT Measured'] - qc_df['RT Polynomial Pred']\n",
    "qc_df.to_csv(os.path.join(output_data_qc, \"RT_Predicted_Model_Comparison.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE YOUR MODEL HERE (linear / polynomial).\n",
    "#model = 'linear' \n",
    "model = 'polynomial'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save RT model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "    \n",
    "with open(os.path.join(output_data_qc,'rt_model.txt'), 'w') as f:\n",
    "    if model == 'linear':\n",
    "        f.write('coef = {}\\nintercept = {}\\nqc_actual_rts = {}\\nqc_predicted_rts = {}'.format(coef_linear, \n",
    "                                                                intercept_linear, \n",
    "                                                                ', '.join([g.name for g in groups]),\n",
    "                                                                myAtlas.name))\n",
    "        f.write('\\n'+repr(rt_model_linear.set_params()))\n",
    "        \n",
    "    else:\n",
    "        f.write('coef = {}\\nintercept = {}\\nqc_actual_rts = {}\\nqc_predicted_rts = {}'.format(coef_poly, \n",
    "                                                                intercept_poly, \n",
    "                                                                ', '.join([g.name for g in groups]),\n",
    "                                                                myAtlas.name))\n",
    "        f.write('\\n'+repr(rt_model_poly.set_params()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Auto RT adjust Template atlases\n",
    "\n",
    "Available templates in Database:\n",
    "\n",
    "Index  Atlas_name(POS)\\\n",
    "0   HILICz150_ANT20190824_TPL_EMA_Unlab_POS\\\n",
    "1   HILICz150_ANT20190824_TPL_QCv3_Unlab_POS\\\n",
    "2   HILICz150_ANT20190824_TPL_ISv5_Unlab_POS\\\n",
    "3   HILICz150_ANT20190824_TPL_ISv5_13C15N_POS\\\n",
    "4   HILICz150_ANT20190824_TPL_IS_LabUnlab2_POS\n",
    "\n",
    "Index  Atlas_name(NEG)\\\n",
    "0   HILICz150_ANT20190824_TPL_EMA_Unlab_NEG\\\n",
    "1   HILICz150_ANT20190824_TPL_QCv3_Unlab_NEG\\\n",
    "2   HILICz150_ANT20190824_TPL_ISv5_Unlab_NEG\\\n",
    "3   HILICz150_ANT20190824_TPL_ISv5_13C15N_NEG\\\n",
    "4   HILICz150_ANT20190824_TPL_IS_LabUnlab2_NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_atlas_indices = [0,1,2,3,4]\n",
    "neg_atlas_indices = [0,1,2,3,4]\n",
    "free_text = '' # this will be appended to the end of the csv filename exported\n",
    "save_to_db = False\n",
    "\n",
    "for ix in pos_atlas_indices:\n",
    "    atlases = metob.retrieve('Atlas',name=pos_templates[ix], username='vrsingan')\n",
    "    prd_atlas_name = pos_templates[ix].replace('TPL', 'PRD')\n",
    "    if free_text != '':\n",
    "        prd_atlas_name = prd_atlas_name+\"_\"+free_text\n",
    "    prd_atlas_filename = prd_atlas_name+'.csv'\n",
    "    myAtlas = atlases[-1]\n",
    "    PRD_atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "    PRD_atlas_df['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "    if model == 'linear':\n",
    "        PRD_atlas_df['rt_peak'] = PRD_atlas_df['rt_peak'].apply(lambda rt: coef_linear*rt+intercept_linear)\n",
    "    else:\n",
    "        PRD_atlas_df['rt_peak'] = PRD_atlas_df['rt_peak'].apply(lambda rt: (coef_poly[1]*rt)+(coef_poly[2]*(rt**2))+intercept_poly)\n",
    "    PRD_atlas_df['rt_min'] = PRD_atlas_df['rt_peak'].apply(lambda rt: rt-.5)\n",
    "    PRD_atlas_df['rt_max'] = PRD_atlas_df['rt_peak'].apply(lambda rt: rt+.5)\n",
    "    \n",
    "    PRD_atlas_df.to_csv(os.path.join(output_data_qc, name=prd_atlas_filename, index=False)\n",
    "    \n",
    "    if save_to_db:\n",
    "            dp.make_atlas_from_spreadsheet(PRD_atlas_df,\n",
    "                          PRD_atlas_name,\n",
    "                          filetype='dataframe',\n",
    "                          sheetname='',\n",
    "                          polarity = 'positive',\n",
    "                          store=True,\n",
    "                          mz_tolerance = 12)\n",
    "    print(prd_atlas_name+\" Created!\")\n",
    "\n",
    "for ix in neg_atlas_indices:\n",
    "    atlases = metob.retrieve('Atlas',name=neg_templates[ix], username='vrsingan')\n",
    "    prd_atlas_name = neg_templates[ix].replace('TPL', 'PRD')\n",
    "    if free_text != '':\n",
    "        prd_atlas_name = prd_atlas_name+\"_\"+free_text\n",
    "    prd_atlas_filename = prd_atlas_name+'.csv'\n",
    "    myAtlas = atlases[-1]\n",
    "    PRD_atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "    PRD_atlas_df['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "    if model == 'linear':\n",
    "        PRD_atlas_df['rt_peak'] = PRD_atlas_df['rt_peak'].apply(lambda rt: coef_linear*rt+intercept_linear)\n",
    "    else:\n",
    "        PRD_atlas_df['rt_peak'] = PRD_atlas_df['rt_peak'].apply(lambda rt: (coef_poly[1]*rt)+(coef_poly[2]*(rt**2))+intercept_poly)\n",
    "    PRD_atlas_df['rt_min'] = PRD_atlas_df['rt_peak'].apply(lambda rt: rt-.5)\n",
    "    PRD_atlas_df['rt_max'] = PRD_atlas_df['rt_peak'].apply(lambda rt: rt+.5)\n",
    "    \n",
    "    PRD_atlas_df.to_csv(os.path.join(output_data_qc, name=prd_atlas_filename, index=False)\n",
    "    \n",
    "    if save_to_db:\n",
    "            dp.make_atlas_from_spreadsheet(PRD_atlas_df,\n",
    "                          PRD_atlas_name,\n",
    "                          filetype='dataframe',\n",
    "                          sheetname='',\n",
    "                          polarity = 'negative',\n",
    "                          store=True,\n",
    "                          mz_tolerance = 12)\n",
    "    \n",
    "    print(prd_atlas_name+\" Created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL BLOCK FOR RT PREDICTION OF CUSTOM ATLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional for custom template predictions\n",
    "\n",
    "# atlas_name = '' #atlas name\n",
    "# save_to_db = False\n",
    "\n",
    "# atlases = metob.retrieve('Atlas',name=atlas_name, username='*')\n",
    "# myAtlas = atlases[-1]\n",
    "# PRD_atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "# PRD_atlas_df['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "# if model == 'linear':\n",
    "#     PRD_atlas_df['rt_peak'] = PRD_atlas_df['rt_peak'].apply(lambda rt: coef_linear*rt+intercept_linear)\n",
    "# else:\n",
    "#     PRD_atlas_df['rt_peak'] = PRD_atlas_df['rt_peak'].apply(lambda rt: (coef_poly[1]*rt)+(coef_poly[2]*(rt**2))+intercept_poly)\n",
    "# PRD_atlas_df['rt_min'] = PRD_atlas_df['rt_peak'].apply(lambda rt: rt-.5)\n",
    "# PRD_atlas_df['rt_max'] = PRD_atlas_df['rt_peak'].apply(lambda rt: rt+.5)\n",
    "    \n",
    "# PRD_atlas_df.to_csv(os.path.join(output_data_qc, name=atlas_name.replace('TPL','PRD'), index=False)\n",
    "    \n",
    "# if save_to_db:\n",
    "#     dp.make_atlas_from_spreadsheet(PRD_atlas_df,\n",
    "#                     PRD_atlas_name,\n",
    "#                     filetype='dataframe',\n",
    "#                     sheetname='',\n",
    "#                     polarity = 'positive', # NOTE - Please make sure you are choosing the correct polarity\n",
    "#                     store=True,\n",
    "#                     mz_tolerance = 12)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "metatlas py3",
   "language": "python",
   "name": "metatlas_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
