{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Python Packages\n",
    "\n",
    "To install the kernel used by NERSC-metatlas users, copy the following text to $HOME/.ipython/kernels/mass_spec_cori/kernel.json\n",
    "\n",
    "```\n",
    "{\n",
    " \"argv\": [\n",
    "  \"/global/common/software/m2650/python-cori/bin/python\",\n",
    "  \"-m\",\n",
    "  \"IPython.kernel\",\n",
    "  \"-f\",\n",
    "  \"{connection_file}\"\n",
    " ],\n",
    " \"env\": {\n",
    "    \"PATH\": \"/global/common/software/m2650/python-cori/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\"\n",
    " },\n",
    " \"display_name\": \"mass_spec_cori\",\n",
    " \"language\": \"python\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown, display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "%matplotlib inline\n",
    "%env HDF5_USE_FILE_LOCKING=FALSE\n",
    "import sys, os\n",
    "\n",
    "#### add a path to your private code if not using production code ####\n",
    "#print ('point path to metatlas repo')\n",
    "sys.path.insert(0,\"/global/homes/b/bpb/repos/metatlas/\") #where your private code is\n",
    "######################################################################\n",
    "\n",
    "from metatlas.plots import dill2plots as dp\n",
    "from metatlas.io import metatlas_get_data_helper_fun as ma_data\n",
    "from metatlas.plots import chromatograms_mp_plots as cp\n",
    "from metatlas.plots import chromplotplus as cpp\n",
    "from metatlas.datastructures import metatlas_objects as metob\n",
    "\n",
    "import qgrid\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, IntProgress\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import time\n",
    "import dill\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set atlas, project and output directories from your nersc home directory\n",
    "\n",
    "1. Create a project folder name for this analysis by replacing the PROJECTDIRECTORY string text in red below.  Make sure to update the rest of the direcory to point to your home directory.  The pwd block will print out the directory where this jupyter notebook is stored.\n",
    "2. Create a subdirectory name for the output, each run through you may want to create a new output folder.\n",
    "3. When you run the block the folders will be created in your home directory.  If the directory already exists, the block will just set the path for use with future code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_directory='/global/homes/FIRST-INITIAL-OF-USERNAME/USERNAME/PROJECTDIRECTORY/'  # <- edit this line, do not copy the path directly from NERSC (ex. the u1, or u2 directories)\n",
    "output_subfolder='HILIC_POS_20190830/'  # <- edit this as 'chromatography_polarity_yyyymmdd/'\n",
    "output_dir = os.path.join(project_directory,output_subfolder)\n",
    "output_data_qc = os.path.join(output_dir,'data_QC')\n",
    "\n",
    "if not os.path.exists(project_directory):\n",
    "   os.makedirs(project_directory)\n",
    "if not os.path.exists(output_dir):\n",
    "   os.makedirs(output_dir)\n",
    "if not os.path.exists(output_data_qc):\n",
    "    os.makedirs(output_data_qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select groups and get QC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "#groups = dp.select_groups_for_analysis(name = '%20190308_KBL_IG-SS_BETO_Algae_Mono26B_HF_LipV7_47560%',\n",
    "groups = dp.select_groups_for_analysis(name = '%20181126_CondTann_SoilEnrich_ 20180709-Aq_HIL_FPS_MS1_QC-PrimMet-SOPv3%',\n",
    "                                       most_recent = True,\n",
    "                                       remove_empty = True,\n",
    "                                       include_list = ['QC'], exclude_list = [])  #['QC','Blank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in groups:\n",
    "    for f in g.items:\n",
    "         print f.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get template QC atlas from database\n",
    "\n",
    "Available templates in Database:\n",
    "\n",
    "MSMLS_HILICz150mm_Annotation20190824_Template_EMA_Unlabeled_Positive\\\n",
    "MSMLS_HILICz150mm_Annotation20190824_Template_EMA_Unlabeled_Negative\\\n",
    "MSMLS_HILICz150mm_Annotation20190824_Template_QCv3_Unlabeled_Positive\\\n",
    "MSMLS_HILICz150mm_Annotation20190824_Template_QCv3_Unlabeled_Negative\\\n",
    "MSMLS_HILICz150mm_Annotation20190824_Template_ISv5_Unlabeled_Positive\\\n",
    "MSMLS_HILICz150mm_Annotation20190824_Template_ISv5_Unlabeled_Negative\\\n",
    "MSMLS_HILICz150mm_Annotation20190824_Template_ISv5_13C15N_Positive\\\n",
    "MSMLS_HILICz150mm_Annotation20190824_Template_ISv5_13C15N_Negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atlas File Name \n",
    "LCS = 'MSMLS' # Library Compound Set\n",
    "CTY = 'HILICz150mm' # Chromatography\n",
    "LR = 'Annotation20190824' # Library Run\n",
    "RTS = 'Template' # RT space\n",
    "CPD = 'QCv3' # Set of Compounds\n",
    "LAB = 'Unlabeled' # Isolabeling\n",
    "POL = 'Positive' # Polarity\n",
    "\n",
    "QC_template_filename = \"_\".join((LCS,CTY,LR,RTS,CPD,LAB,POL))\n",
    "\n",
    "atlases = metob.retrieve('Atlas',name=QC_template_filename,\n",
    "                         username='vrsingan')\n",
    "names = []\n",
    "for i,a in enumerate(atlases):\n",
    "    print(i,a.name,pd.to_datetime(a.last_modified,unit='s'),len(a.compound_identifications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Alternatively use this block to create QC atlas from spreadsheet\n",
    "# import datetime\n",
    "#dp = reload(dp)\n",
    "\n",
    "# LCS = 'MSMLS' # Library Compound Set\n",
    "# CTY = 'HILICz150mm' # Chromatography\n",
    "# LR = 'Annotation20190824' # Library Run\n",
    "# RTS = 'Template' # RT space\n",
    "# CPD = 'QCv3' # Set of Compounds\n",
    "# LAB = 'Unlabeled' # Isolabeling\n",
    "# POL = 'Positive' # Polarity\n",
    "# DT = datetime.datetime.strftime(datetime.datetime.now(),'%Y%m%d')\n",
    "# QC_template_filename = \"_\".join((LCS,CTY,LR,RTS,CPD,LAB,POL,DT))\n",
    "\n",
    "#myAtlas = dp.make_atlas_from_spreadsheet('/global/project/projectdirs/metatlas/projects/1_TemplateAtlases/TemplateAtlas_HILICz150mm_Annotation20190824_QCv3_Unlabeled_Positive.csv',\n",
    "#                                       QC_template_filename,\n",
    "#                                        filetype='csv',\n",
    "#                                        sheetname='',\n",
    "#                                        polarity = 'positive',\n",
    "#                                        store=True,\n",
    "#                                       mz_tolerance = 20)\n",
    "#atlases = dp.get_metatlas_atlas(name=QC_template_filename,do_print = True,most_recent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAtlas = atlases[-1]\n",
    "atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "atlas_df['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "print myAtlas.name\n",
    "print myAtlas.username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. Uncomment the block below to adjust RT window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rt_allowance = 0.5\n",
    "# atlas_df['rt_min'] = atlas_df['rt_peak'].apply(lambda rt: rt-rt_allowance)\n",
    "# atlas_df['rt_max'] = atlas_df['rt_peak'].apply(lambda rt: rt+rt_allowance)\n",
    "# for compound in range(len(myAtlas.compound_identifications)):\n",
    "#     rt_peak = myAtlas.compound_identifications[compound].rt_references[0].rt_peak\n",
    "#     myAtlas.compound_identifications[compound].rt_references[0].rt_min = rt_peak - rt_allowance\n",
    "#     myAtlas.compound_identifications[compound].rt_references[0].rt_max = rt_peak + rt_allowance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create metatlas dataset from QC files and QC atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for my_group in groups:\n",
    "    for my_file in my_group.items:\n",
    "        all_files.append((my_file,my_group,atlas_df,myAtlas))\n",
    "        \n",
    "pool = mp.Pool(processes=min(4, len(all_files)))\n",
    "t0 = time.time()\n",
    "metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "#If you're code crashes here, make sure to terminate any processes left open.\n",
    "print time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5b Optional: Filter atlas for compounds with no or low signals\n",
    "\n",
    "Uncomment the below 3 blocks to filter the atlas.\n",
    "Please ensure that correct polarity is used for the atlases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp = reload(dp)\n",
    "# num_data_points_passing = 3\n",
    "# peak_height_passing = 1e4\n",
    "# rt_peak_passing = 0.8\n",
    "# atlas_df_passing = dp.filter_atlas(atlas_df=atlas_df, input_dataset=metatlas_dataset, num_data_points_passing = num_data_points_passing, peak_height_passing = peak_height_passing, rt_peak_passing = rt_peak_passing)\n",
    "# print(\"# Compounds in Atlas: \"+str(len(atlas_df)))\n",
    "# print(\"# Compounds passing filter: \"+str(len(atlas_df_passing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas_passing = myAtlas.name+'_filteredby-datapnts'+str(num_data_points_passing)+'-pkht'+str(peak_height_passing)+'-rtpk'+str(rt_peak_passing)\n",
    "# myAtlas_passing = dp.make_atlas_from_spreadsheet(atlas_df_passing,\n",
    "#                           atlas_passing,\n",
    "#                           filetype='dataframe',\n",
    "#                           sheetname='',\n",
    "#                           polarity = 'positive',\n",
    "#                           store=True,\n",
    "#                           mz_tolerance = 20)\n",
    "\n",
    "# atlases = dp.get_metatlas_atlas(name=atlas_passing,do_print = True, most_recent=True)\n",
    "\n",
    "# myAtlas = atlases[-1]\n",
    "# atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "# atlas_df['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "# print myAtlas.name\n",
    "# print myAtlas.username\n",
    "# metob.to_dataframe([myAtlas])# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_files = []\n",
    "# for my_group in groups:\n",
    "#     for my_file in my_group.items:\n",
    "#         all_files.append((my_file,my_group,atlas_df,myAtlas))\n",
    "        \n",
    "# pool = mp.Pool(processes=min(4, len(all_files)))\n",
    "# t0 = time.time()\n",
    "# metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "# pool.close()\n",
    "# pool.terminate()\n",
    "# #If you're code crashes here, make sure to terminate any processes left open.\n",
    "# print time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create RT adjustment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "ransac = RANSACRegressor(random_state=42)\n",
    "qc_actual_df = dp.make_output_dataframe(input_dataset = metatlas_dataset, fieldname='rt_peak', use_labels=True) # Peak height filter??\n",
    "maes, coefs, intercepts = [],[],[]\n",
    "actual_rts, pred_rts = [],[]\n",
    "for i in range(qc_actual_df.shape[1]):\n",
    "    current_actual_df = qc_actual_df.loc[:,qc_actual_df.columns[i]]\n",
    "    bad_qc_compounds = np.where(~np.isnan(current_actual_df))\n",
    "    current_actual_df = current_actual_df.iloc[bad_qc_compounds]\n",
    "    current_pred_df = atlas_df.iloc[bad_qc_compounds][['rt_peak']]\n",
    "    actual_rts.append(current_actual_df.values.tolist())\n",
    "    pred_rts.append(current_pred_df.values.tolist())\n",
    "    \n",
    "    rt_model = ransac.fit(current_pred_df, current_actual_df)\n",
    "    \n",
    "    coefs.append(rt_model.estimator_.coef_[0])\n",
    "    intercepts.append(rt_model.estimator_.intercept_)\n",
    "    maes.append(mae(rt_model.estimator_.coef_*current_pred_df+\n",
    "                   rt_model.estimator_.intercept_, current_actual_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot MAE (mean absolute error) for all QC files  \n",
    "Index and file name of the QC file with the least MAE is highlighted.<br />\n",
    "Dark Red and Dark Blue lines represent Coeff and Intercept values for each of the QC files.<br /> \n",
    "Light Red and Light Blue lines show the median Coeff and Intercept value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "fig_legend = \"FileIndex       FileName\"\n",
    "for i in range(qc_actual_df.shape[1]):\n",
    "    if maes[i] == min(maes):\n",
    "        QCFileIndex = i\n",
    "        fname = qc_actual_df.columns[i][1].replace(\"_\", \"\\_\")\n",
    "        fig_legend = fig_legend+ \"\\n\" + r\"$\\bf{\"+ str(i)+ \"}$\"+\"\\t\"+ r\"$\\bf{\"+str(fname)+\"}$\"\n",
    "    else:\n",
    "        fig_legend = fig_legend+\"\\n\"+str(i)+\"        \"+qc_actual_df.columns[i][1]\n",
    "\n",
    "plt.rc('font', size=10)\n",
    "plt.rc('axes', labelsize=8)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "fig, axes = plt.subplots(2, sharex=True)\n",
    "color = 'tab:red'\n",
    "axes[0].set_ylabel('coef', color=color)\n",
    "axes[0].plot(coefs, color=color)\n",
    "axes[0].tick_params(axis='y', labelcolor=color)\n",
    "axes[0].axhline(y=np.median(rt_model.estimator_.coef_),color='orangered')\n",
    "\n",
    "ax2 = axes[0].twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('intercept', color=color)  \n",
    "ax2.plot(intercepts, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.axhline(y=np.median(rt_model.estimator_.intercept_),color='lightblue')\n",
    "ax2.set_title('Coefficients and Intercepts of Regression')\n",
    "\n",
    "axes[1].plot(maes)\n",
    "axes[1].set_xticks(np.arange(len(maes)))\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_xlabel('Files')\n",
    "axes[1].set_title('Mean Absolute Error for all files')\n",
    "\n",
    "plt.text(0,-0.04*qc_actual_df.shape[1], fig_legend, transform=plt.gcf().transFigure)\n",
    "plt.text(0, -0.05*qc_actual_df.shape[1], 'NOTE: The file with the least MEA (Mean Absolute Error) is highlighted with bold fonts.', transform=plt.gcf().transFigure)\n",
    "fig.tight_layout(pad=2.5)\n",
    "plt.savefig(os.path.join(output_data_qc,'MAE_allFiles.pdf'), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot actual vs predict RT values and fit a  median coeff+intercept line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User can change to use particular qc file\n",
    "import itertools\n",
    "import math\n",
    "from __future__ import division\n",
    "from matplotlib import gridspec\n",
    "\n",
    "x = list(itertools.chain(*pred_rts))\n",
    "y = list(itertools.chain(*actual_rts))\n",
    "\n",
    "coef = np.median(coefs)\n",
    "intercept = np.median(intercepts)\n",
    "\n",
    "rows = int(math.ceil((qc_actual_df.shape[1]+1)/5))\n",
    "cols = 5\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "\n",
    "gs = gridspec.GridSpec(rows, cols)\n",
    "plt.rc('font', size=6)\n",
    "plt.rc('axes', labelsize=6)\n",
    "plt.rc('xtick', labelsize=3)\n",
    "plt.rc('ytick', labelsize=3)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[0])\n",
    "ax.scatter(x,y, s=3)\n",
    "ax.plot(np.linspace(0, max(x), 100), coef*np.linspace(0, max(x), 100)+intercept, linewidth=0.5)\n",
    "ax.set_title(\"Median of Files\")\n",
    "ax.set_xlabel('predicted RTs')\n",
    "ax.set_ylabel('actual RTs')\n",
    "\n",
    "for i in range(qc_actual_df.shape[1]):\n",
    "    coef = coefs[i]\n",
    "    intercept = intercepts[i]\n",
    "    x = list(itertools.chain(*pred_rts[i]))\n",
    "    y = actual_rts[i]\n",
    "    \n",
    "    ax = fig.add_subplot(gs[i+1])\n",
    "    ax.scatter(x, y, s=3)\n",
    "    ax.plot(np.linspace(0, max(x),100), coefs[i]*np.linspace(0,max(x),100)+intercept, linewidth=0.5)\n",
    "    ax.set_title(\"File: \"+str(i))\n",
    "    ax.set_xlabel('predicted RTs')\n",
    "    ax.set_ylabel('actual RTs')\n",
    "    \n",
    "fig_legend = \"FileIndex       FileName\"\n",
    "for i in range(qc_actual_df.shape[1]):\n",
    "    fig_legend = fig_legend+\"\\n\"+str(i)+\"        \"+qc_actual_df.columns[i][1]\n",
    "\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.text(0,-0.03*qc_actual_df.shape[1], fig_legend, transform=plt.gcf().transFigure)\n",
    "plt.savefig(os.path.join(output_data_qc, 'Actual_vs_Predicted_RTs.pdf'), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot actual vs predict RT values and fit a coeff+intercept line for a specific QC file (optional)\n",
    "\n",
    "Use this if you want coef and intercept of a particular QC file for prediction instead of the median values from all QC files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #QCFileIndex = 1\n",
    "# coef = coefs[QCFileIndex]\n",
    "# intercept = intercepts[QCFileIndex]\n",
    "\n",
    "# x = list(itertools.chain(*pred_rts[QCFileIndex]))\n",
    "# y = actual_rts[QCFileIndex]\n",
    "\n",
    "# plt.scatter(x, y)\n",
    "# plt.plot(np.linspace(0, max(x),100), coef*np.linspace(0,max(x),100)+intercept)\n",
    "# plt.xlabel('predicted RTs')\n",
    "# plt.ylabel('actual RTs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save RT model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open(os.path.join(output_data_qc,'rt_model.txt'), 'w') as f:\n",
    "   f.write('coef = {}\\nintercept = {}\\nqc_actual_rts = {}\\nqc_predicted_rts = {}'.format(coef, \n",
    "                                                                intercept, \n",
    "                                                                ', '.join([g.name for g in groups]),\n",
    "                                                                myAtlas.name))\n",
    "   f.write('\\n'+repr(rt_model.set_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Auto RT adjust original QC atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#Atlas File Name\n",
    "LCS = 'MSMLS' # Library Compound Set\n",
    "CTY = 'HILICz150mm' # Chromatography\n",
    "LR = 'Annotation20190824' # Library Run\n",
    "RTS = 'Predicted' # RT space\n",
    "CPD = 'QCv3' # Set of Compounds\n",
    "LAB = 'Unlabeled' # Isolabeling\n",
    "POL = 'Positive' # Polarity\n",
    "FT = '' # Free Text\n",
    "DT = datetime.datetime.strftime(datetime.datetime.now(),'%Y%m%d')\n",
    "\n",
    "\n",
    "if FT != '':\n",
    "    QC_predicted_filename = \"_\".join((LCS,CTY,LR,RTS,CPD,LAB,POL,FT,DT))+\".csv\"\n",
    "else:\n",
    "    QC_predicted_filename = \"_\".join((LCS,CTY,LR,RTS,CPD,LAB,POL,DT))+\".csv\"\n",
    "\n",
    "atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "QC_atlas_df = atlas_df.copy()\n",
    "QC_atlas_df['rt_peak'] = QC_atlas_df['rt_peak'].apply(lambda rt: coef*rt+intercept)\n",
    "QC_atlas_df['rt_min'] = QC_atlas_df['rt_peak'].apply(lambda rt: rt-.5)\n",
    "QC_atlas_df['rt_max'] = QC_atlas_df['rt_peak'].apply(lambda rt: rt+.5)\n",
    "\n",
    "QC_atlas_df.to_csv(os.path.join(output_data_qc, QC_predicted_filename), index=False)\n",
    "\n",
    "all_files = []\n",
    "for my_group in groups:\n",
    "    for my_file in my_group.items:\n",
    "        all_files.append((my_file,my_group,QC_atlas_df,myAtlas))\n",
    "\n",
    "pool = mp.Pool(processes=min(4, len(all_files)))\n",
    "t0 = time.time()\n",
    "metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "#If you're code crashes here, make sure to terminate any processes left open.\n",
    "print time.time() - t0\n",
    "\n",
    "group = 'index' # 'page' or 'index' or None\n",
    "save = True\n",
    "share_y = True\n",
    "dp.make_chromatograms(input_dataset=metatlas_dataset, group=group, share_y=share_y, save=save, output_loc=output_data_qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save adjusted QC to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.make_atlas_from_spreadsheet(QC_atlas_df,\n",
    "                          QC_predicted_filename,\n",
    "                          filetype='dataframe',\n",
    "                          sheetname='',\n",
    "                          polarity = 'positive',\n",
    "                          store=True,\n",
    "                          mz_tolerance = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Auto RT adjust template EMA atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#Atlas File Name\n",
    "LCS = 'MSMLS' # Library Compound Set\n",
    "CTY = 'HILICz150mm' # Chromatography - Dont Change, should be same as above\n",
    "LR = 'Annotation20190824' # Library Run - Dont Change, should be same as above \n",
    "RTS = 'Template' # RT space\n",
    "CPD = 'EMA' # Set of Compounds\n",
    "LAB = 'Unlabeled' # Isolabeling\n",
    "POL = 'Positive' # Polarity\n",
    "FT = '' # Free Text\n",
    "DT = datetime.datetime.strftime(datetime.datetime.now(),'%Y%m%d')\n",
    "\n",
    "EMA_template_filename = \"_\".join((LCS,CTY,LR,RTS,CPD,LAB,POL))\n",
    "\n",
    "#EMA_template_filename = \"Custom FileName\"\n",
    "\n",
    "RTS = 'Predicted' # RT space\n",
    "if FT != '':\n",
    "    EMA_predicted_filename = \"_\".join((LCS,CTY,LR,RTS,CPD,LAB,POL,FT,DT))+\".csv\"\n",
    "else:\n",
    "    EMA_predicted_filename = \"_\".join((LCS,CTY,LR,RTS,CPD,LAB,POL,DT))+\".csv\"\n",
    "\n",
    "atlases = metob.retrieve('Atlas',name=EMA_template_filename,\n",
    "                         username='vrsingan')\n",
    "myAtlas = atlases[-1]\n",
    "EMA_atlas_df = ma_data.make_atlas_df(myAtlas)\n",
    "EMA_atlas_df['label'] = [cid.name for cid in myAtlas.compound_identifications]\n",
    "\n",
    "EMA_atlas_df['rt_peak'] = EMA_atlas_df['rt_peak'].apply(lambda rt: coef*rt+intercept)\n",
    "EMA_atlas_df['rt_min'] = EMA_atlas_df['rt_peak'].apply(lambda rt: rt-.5)\n",
    "EMA_atlas_df['rt_max'] = EMA_atlas_df['rt_peak'].apply(lambda rt: rt+.5)\n",
    "\n",
    "EMA_atlas_df.to_csv(os.path.join(output_data_qc,EMA_predicted_filename), index=False)\n",
    "\n",
    "# Optionally save in database\n",
    "#dp.make_atlas_from_spreadsheet(EMA_atlas_df,\n",
    "#                           EMA_predicted_filename,\n",
    "#                           filetype='dataframe',\n",
    "#                           sheetname='',\n",
    "#                           polarity = 'positive',\n",
    "#                           store=True,\n",
    "#                           mz_tolerance = 20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "mass spec cori",
   "language": "python",
   "name": "mass_spec_cori"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
