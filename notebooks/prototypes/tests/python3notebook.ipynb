{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (fastanalysis.py, line 565)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/global/common/software/m2650/python3-cori/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3326\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a5f96a838028>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from metatlas.tools import fastanalysis as fa\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/global/homes/b/bpb/repos/metatlas/metatlas/tools/fastanalysis.py\"\u001b[0;36m, line \u001b[0;32m565\u001b[0m\n\u001b[0;31m    print 'Error: ' + column + ' not in scores_df. Either set column where pass/fail boolean values are or run test_scores_df().'\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# optional: run this block to adjust the width of the notebook.  Change the width percent.\n",
    "\n",
    "from  IPython.core.display  import  display, HTML \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%matplotlib notebook\n",
    "import sys, os\n",
    "\n",
    "# v edit this line\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/metatlas/')\n",
    "# ^ edit this line\n",
    "\n",
    "from metatlas.tools import fastanalysis as fa\n",
    "from metatlas.plots import dill2plots as dp\n",
    "from metatlas.io import metatlas_get_data_helper_fun as ma_data\n",
    "from metatlas.plots import chromplotplus as cpp\n",
    "from metatlas.datastructures import metatlas_objects as metob\n",
    "import qgrid\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "import pickle\n",
    "import dill\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/global/homes/b/bpb/Downloads/test_metatlas'\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "atlas_filename = 'atlas.csv' \n",
    "atlas_dbname = 'tempatlas'\n",
    "group_dbname = '%20180502_KBL%POS%sweetpotato%raw%'\n",
    "fileinfo_filename = 'fileinfo.tab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = metob.retrieve('lcmsruns',name=group_dbname,username='*')\n",
    "for f in files:\n",
    "    print(f.name,f.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = dp.get_metatlas_files(experiment='20180502_KBL_C18_PT_SwtPotVeggies',name = group_dbname,most_recent = True)\n",
    "len(files)\n",
    "# ^ edit the text string in experiment and name fields\n",
    "\n",
    "df = metob.to_dataframe(files)\n",
    "# my_grid = qgrid.QGridWidget(df=df[['experiment','name','username','acquisition_time']])\n",
    "# my_grid.export()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: View the groups\n",
    "\n",
    "files = metob.retrieve('lcmsruns',experiment='20180502_KBL_C18_PT_SwtPotVeggies',name = group_dbname,username='*')\n",
    "controlled_vocab = ['QC','InjBl','ISTD'] #add _ to beginning. It will be stripped if at begining\n",
    "version_identifier = 'vrs3'\n",
    "file_dict = {}\n",
    "groups_dict = {}\n",
    "for f in files:\n",
    "    k = f.name.split('.')[0]\n",
    "    #     get index if any controlled vocab in filename\n",
    "    indices = [i for i, s in enumerate(controlled_vocab) if s.lower() in k.lower()]\n",
    "    prefix = '_'.join(k.split('_')[:11])\n",
    "    if len(indices)>0:\n",
    "        short_name = controlled_vocab[indices[0]].lstrip('_')\n",
    "        group_name = '%s_%s_%s'%(prefix,version_identifier,short_name)\n",
    "        short_name = k.split('_')[9]+'_'+short_name # Prepending POL to short_name\n",
    "    else:\n",
    "        short_name = k.split('_')[12]\n",
    "        group_name = '%s_%s_%s'%(prefix,version_identifier,short_name)\n",
    "        short_name = k.split('_')[9]+'_'+k.split('_')[12]  # Prepending POL to short_name\n",
    "    file_dict[k] = {'file':f,'group':group_name,'short_name':short_name}\n",
    "    groups_dict[group_name] = {'items':[],'name':group_name,'short_name':short_name}\n",
    "df = pd.DataFrame(file_dict).T\n",
    "df.index.name = 'filename'\n",
    "df.reset_index(inplace=True)#['group'].unique()\n",
    "df.drop(columns=['file'],inplace=True)\n",
    "for ug in groups_dict.keys():\n",
    "    for file_key,file_value in file_dict.items():\n",
    "        if file_value['group'] == ug:\n",
    "            groups_dict[ug]['items'].append(file_value['file'])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: create the groups variable, if the above looks OK\n",
    "\n",
    "groups = []\n",
    "for group_key,group_values in groups_dict.items():\n",
    "    g = metob.Group(name=group_key,items=group_values['items'],short_name=group_values['short_name'])\n",
    "    groups.append(g)        \n",
    "    for item in g.items:\n",
    "        print(g.name,g.short_name,item.name)\n",
    "    print('')\n",
    "\n",
    "# STEP 3 Option A: store the groups variable content in the DB (currently only the long group name is stored)\n",
    "# metob.store(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: Select files\n",
    "files = dp.get_metatlas_files(experiment='20180502_KBL_C18_PT_SwtPotVeggies',name = group_dbname,most_recent = True)\n",
    "# ^ edit the text string in experiment and name fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: Save spreadsheet file\n",
    "dp.make_empty_fileinfo_sheet('%s%s' % (output_dir,'empty_fileinfo.tab'),files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #STEP 3: create groups from file\n",
    "# g = dp.make_groups_from_fileinfo_sheet('%s%s' % (output_dir,'filled_fileinfo.txt'),\n",
    "#                                        filetype='tab',\n",
    "#                                        store=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STEP 4: check groups\n",
    "metob.to_dataframe(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make short_filename and short_samplename \n",
    "files = metob.retrieve('lcmsruns',experiment='20180502_KBL_C18_PT_SwtPotVeggies',name = group_dbname,username='vrsingan')\n",
    "short_filename_delim_ids = [0,2,4,5,7,9,14]\n",
    "short_samplename_delim_ids = [9,12,13,14]\n",
    "short_names_df = pd.DataFrame(columns=['sample_treatment','short_filename','short_samplename'])\n",
    "ctr = 0\n",
    "for f in files:\n",
    "    short_filename = []\n",
    "    short_samplename = []\n",
    "    tokens = f.name.split('.')[0].split('_')\n",
    "    for id in short_filename_delim_ids:\n",
    "        short_filename.append(str(tokens[id]))\n",
    "    for id in short_samplename_delim_ids:\n",
    "        short_samplename.append(str(tokens[id]))\n",
    "    short_filename = \"_\".join(short_filename)\n",
    "    short_samplename = \"_\".join(short_samplename)\n",
    "    short_names_df.loc[ctr, 'full_filename'] = f.name.split('.')[0]\n",
    "    short_names_df.loc[ctr, 'sample_treatment'] = str(tokens[12]) # delim 12\n",
    "    short_names_df.loc[ctr, 'short_filename'] = short_filename\n",
    "    short_names_df.loc[ctr, 'short_samplename'] = short_samplename\n",
    "    ctr +=1\n",
    "short_names_df.set_index('full_filename', inplace=True)\n",
    "short_names_df.to_csv(os.path.join(output_dir, 'short_names.csv'), sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional import edited short_names.csv \n",
    "short_names_df = pd.read_csv(os.path.join(output_dir, 'short_names.csv'), sep='\\t', index_col='full_filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = dp.select_groups_for_analysis(name = '20180502_KBL_PT_SwtPot_CkVsRw_MVeg_QE-HF_C18_105_POS_MSMS_vrs3_SP-R',    # <- edit text search string here\n",
    "                                       most_recent = True,\n",
    "                                       remove_empty = True,\n",
    "                                       include_list = [], exclude_list = [])# ex. ['QC','Blank'])\n",
    "print(\"sorted groups\")\n",
    "groups = sorted(groups, key=operator.attrgetter('name'))\n",
    "for i,a in enumerate(groups):\n",
    "    print(i, a.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view metadata about your groups, run the block below\n",
    "metob.to_dataframe(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/global/homes/b/bpb/Downloads/small_c18_atlas.tab',sep='\\t')\n",
    "# df = df.head()\n",
    "# df.rename(columns={'rt':'rt_peak'},inplace=True)\n",
    "# good_cols = [u'label', u'adduct', u'polarity', u'mz', u'rt_peak', u'rt_min', u'rt_max', u'inchi_key']\n",
    "# df = df[good_cols]\n",
    "# df['mz_tolerance'] = 20\n",
    "# df.to_csv('/global/homes/b/bpb/repos/metatlas/data/atlas/atlas_for_testing.csv',index=None)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# names = dp.make_atlas_from_spreadsheet('/global/homes/b/bpb/repos/metatlas/data/atlas/atlas_for_testing.csv',  # <- DO NOT EDIT THIS LINE\n",
    "#                                        atlas_dbname,\n",
    "#                                        filetype='csv',\n",
    "#                                        sheetname='',\n",
    "#                                        polarity = 'positive',\n",
    "#                                        store=False,\n",
    "# #                                        mz_tolerance = 20\n",
    "#                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlases = metob.retrieve('Atlas',name=atlas_dbname,username='bpb')\n",
    "names = []\n",
    "for i,a in enumerate(atlases):\n",
    "    print(i,a.name,pd.to_datetime(a.last_modified,unit='s'))#len(a.compound_identifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_atlas = atlases[-1]\n",
    "atlas_df = ma_data.make_atlas_df(my_atlas)\n",
    "atlas_df['label'] = [cid.name for cid in my_atlas.compound_identifications]\n",
    "print my_atlas.name\n",
    "metob.to_dataframe([my_atlas])\n",
    "# the first line of the output will show the dimensions of the atlas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: to view your atlas, run this block\n",
    "print my_atlas.name\n",
    "atlas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for my_group in groups:\n",
    "    for my_file in my_group.items:\n",
    "        extra_time = 0.1  \n",
    "        extra_mz = 0.00\n",
    "        all_files.append((my_file,my_group,atlas_df,my_atlas,extra_time,extra_mz))\n",
    "pool = mp.Pool(processes=min(4, len(all_files)))\n",
    "t0 = time.time()\n",
    "metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "print time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data sources tables (atlas_metadata.tab, groups_metadata.tab, groups.tab and [atlasname]_originalatlas.tab within data_sources subfolder)\n",
    "ma_data.make_data_sources_tables(groups, my_atlas, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = reload(dp)\n",
    "num_data_points_passing = 3\n",
    "peak_height_passing = 1e4\n",
    "rt_peak_passing = 0.8\n",
    "atlas_df_passing = dp.filter_atlas(atlas_df=atlas_df, input_dataset=metatlas_dataset, num_data_points_passing = num_data_points_passing, peak_height_passing = peak_height_passing, rt_peak_passing = rt_peak_passing)\n",
    "print(\"# Compounds in Atlas: \"+str(len(atlas_df)))\n",
    "print(\"# Compounds passing filter: \"+str(len(atlas_df_passing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BLOCK A\n",
    "t0 = time.time()\n",
    "\n",
    "hits=dp.get_msms_hits(metatlas_dataset,extra_time=True,keep_nonmatches=True,ref_loc='/global/project/projectdirs/metatlas/projects/spectral_libraries/msms_refs_v4.tab')\n",
    "pickle.dump(hits, open(os.path.join(output_dir,'hits.pkl'), \"wb\"))\n",
    "\n",
    "print time.time() - t0\n",
    "print '%s%s' % (len(hits),' <- total number of MSMS spectra found in your files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['num_matches'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ###STEP 1: Set the peak flag radio buttons using one of the two lines below, for custom flags or default flags\n",
    "\n",
    "# peak_flag_list=('','L1+ - 1 pk, good RT&MSMS','L1+ - known isomer overlap','L1+ - 1 pk, good RT, MSMS ok (coisolated mz/partial match/low int)','L1+ - 1 pk, good RT&MSMS from external library','L1 - 1 pk, correct RT, no MSMS or int too low for matching','L1 - 1 pk, good RT, very low intensity/poor pk shape','L2 put comp','L3 putative class','Remove - background/noise','Remove - bad EMA MSMS','Remove - bad MSMS NIST/MONA/Metlin')\n",
    "# #peak_flag_list =\"\"       # this will default to ('keep','remove','unresolvable isomers','poor peak shape')\n",
    "\n",
    "# ###STEP 2: Set the EIC line colors using on of the two lines below, for custom colors or default \n",
    "# colorlist= [['red','peas'],                                                     \n",
    "#            ['green','beets']]\n",
    "# #colorlist=\"\"   # this will default to black\n",
    "\n",
    "# ###STEP 3\n",
    "# a = dp.adjust_rt_for_selected_compound(metatlas_dataset, msms_hits=hits,peak_flags=peak_flag_list, color_me = colorlist, compound_idx=12,alpha=0.5,width=15,height=4.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_identifications = dp.export_atlas_to_spreadsheet(my_atlas,os.path.join(output_dir,'%s%s.csv' % (my_atlas.name,\"export\")))\n",
    "print my_atlas.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'min_intensity': 1e4,   # strict = 1e5, loose = 1e3\n",
    "          'rt_tolerance': .5,    #>= shift of median RT across all files for given compound to reference\n",
    "          'mz_tolerance': 20,      # strict = 5, loose = 25; >= ppm of median mz across all files for given compound relative to reference\n",
    "          'min_msms_score': .6, 'allow_no_msms': True,     # strict = 0.6, loose = 0.3 <= highest compound dot-product score across all files for given compound relative to reference\n",
    "          'min_num_frag_matches': 1, 'min_relative_frag_intensity': .001}   # strict = 3 and 0.1, loose = 1, 0.01 number of matching mzs when calculating max_msms_score and ratio of second highest to first highest intensity of matching sample mzs\n",
    "scores_df = fa.make_scores_df(metatlas_dataset,hits)\n",
    "scores_df['passing'] = fa.test_scores_df(scores_df, **kwargs)\n",
    "\n",
    "pass_atlas_df, fail_atlas_df, pass_dataset, fail_dataset = fa.filter_atlas_and_dataset(scores_df, atlas_df, metatlas_dataset, column='passing')\n",
    "\n",
    "fa.make_stats_table(input_dataset = metatlas_dataset, msms_hits = hits, output_loc = output_dir,min_peak_height=1e5,use_labels=True,min_msms_score=0.01,min_num_frag_matches=1,include_lcmsruns = [],exclude_lcmsruns = ['QC'])\n",
    "scores_df.to_csv(os.path.join(output_dir, 'stats_tables','compound_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "group = 'index' # 'page' or 'index' or None\n",
    "save = True\n",
    "share_y = True\n",
    "\n",
    "dp.make_chromatograms(input_dataset=metatlas_dataset, group=group, share_y=share_y, save=save, output_loc=output_dir, short_names_df=short_names_df, short_names_header='short_samplename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp.make_identification_figure_v2(input_dataset = metatlas_dataset, msms_hits=hits, use_labels=True, include_lcmsruns = [],exclude_lcmsruns = ['InjBl','QC','Blank','blank'], output_loc=os.path.join(output_dir,'msms_mirror_plots'),  short_names_df=short_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_height = dp.make_output_dataframe(input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_height', output_loc=os.path.join(output_dir,'data_sheets'), short_names_df=short_names_df)\n",
    "peak_area = dp.make_output_dataframe(input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_area', output_loc=os.path.join(output_dir,'data_sheets'), short_names_df=short_names_df)\n",
    "mz_peak = dp.make_output_dataframe(input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='mz_peak', output_loc=os.path.join(output_dir,'data_sheets'), short_names_df=short_names_df)\n",
    "rt_peak = dp.make_output_dataframe(input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [],fieldname='rt_peak', output_loc=os.path.join(output_dir,'data_sheets'), short_names_df=short_names_df)\n",
    "mz_centroid = dp.make_output_dataframe(input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='mz_centroid', output_loc=os.path.join(output_dir,'data_sheets'), short_names_df=short_names_df)\n",
    "rt_centroid = dp.make_output_dataframe(input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='rt_centroid', output_loc=os.path.join(output_dir,'data_sheets'), short_names_df=short_names_df)\n",
    "\n",
    "dp.plot_errorbar_plots(peak_height, output_loc=os.path.join(output_dir,'error_bar_peak_height'), ylabel=\"Peak Height\")\n",
    "dp.plot_errorbar_plots(rt_peak, output_loc=os.path.join(output_dir,'error_bar_rt_peak'), ylabel=\"RT Peak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.make_boxplot_plots(rt_peak, output_loc=os.path.join(output_dir,'boxplot_rt_peak'), ylabel=\"RT Peak\")\n",
    "dp.make_boxplot_plots(mz_centroid, output_loc=os.path.join(output_dir,'boxplot_mz_centroid'), ylabel=\"MZ Centroid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_fraction = 0.01\n",
    "min_mz = 50.0 #minimum m/z to export in msms\n",
    "max_mz = -40.0 # distance from precurosor to export (0.5 is a good number. crazy people use negative numbers)\n",
    "scale_intensity = True\n",
    "data = []\n",
    "for compound_index in range(len(metatlas_dataset[0])):\n",
    "    max_intensity = 0\n",
    "    d = {}\n",
    "    for file_index in range(len(metatlas_dataset)):\n",
    "        try:\n",
    "            pk_idx = metatlas_dataset[file_index][compound_index]['data']['msms']['data']['precursor_intensity'].argmax()\n",
    "            pk = metatlas_dataset[file_index][compound_index]['data']['msms']['data']['precursor_intensity'][pk_idx]\n",
    "            precursor_mz = metatlas_dataset[file_index][compound_index]['data']['msms']['data']['precursor_MZ'][pk_idx]\n",
    "            rt = metatlas_dataset[file_index][compound_index]['data']['msms']['data']['rt'][pk_idx]\n",
    "            if (pk>max_intensity) & (rt>metatlas_dataset[file_index][compound_index]['identification'].rt_references[-1].rt_min) & (rt<metatlas_dataset[file_index][compound_index]['identification'].rt_references[-1].rt_max):\n",
    "                good_index = file_index\n",
    "                max_intensity = pk\n",
    "                final_mz = precursor_mz #save this for filtering below\n",
    "        except:\n",
    "            pass\n",
    "#     print(compound_index,good_index,max_intensity)\n",
    "    if max_intensity>0:\n",
    "        msms = metatlas_dataset[good_index][compound_index]['data']['msms']['data']\n",
    "        idx = np.argwhere(msms['precursor_intensity']==max_intensity).flatten()\n",
    "        mz = msms['mz'][idx]\n",
    "        intensity = msms['i'][idx]\n",
    "        max_msms_intensity = intensity.max()\n",
    "        cutoff = intensity_fraction * max_msms_intensity\n",
    "        conditions = (intensity>cutoff) & (mz>min_mz) & (mz<(final_mz+max_mz))\n",
    "        if sum(conditions)>0:\n",
    "            keep_idx = np.argwhere(conditions).flatten()\n",
    "            mz = str(['%.2f'%x for x in list(mz[keep_idx])]).replace('\\'','')\n",
    "            if scale_intensity==True:\n",
    "                intensity = intensity / intensity.max()\n",
    "                intensity = intensity * 1e5\n",
    "                intensity = intensity.astype(int)\n",
    "            intensity = str(['%d'%x for x in list(intensity[keep_idx])]).replace('\\'','')\n",
    "            spectra = str([mz,intensity]).replace('\\'','')\n",
    "        else:\n",
    "            mz = None\n",
    "            intensity = None\n",
    "            spectra = None\n",
    "    else:\n",
    "        mz = None\n",
    "        intensity = None\n",
    "        spectra = None\n",
    "    data.append({'name':metatlas_dataset[file_index][compound_index]['identification'].name,'spectrum':spectra,'mz':mz,'intensity':intensity})\n",
    "data = pd.DataFrame(data)\n",
    "data[['name','mz','intensity']].to_csv(os.path.join(output_dir,'spectra_1pct_450cut.csv'),index=None)\n",
    "# to look at it type this:\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "mass spec cori python3",
   "language": "python",
   "name": "mass_spec_cori_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
