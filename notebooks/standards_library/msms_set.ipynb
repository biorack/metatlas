{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18bb836-3296-4213-a2f9-d18e71e2e945",
   "metadata": {},
   "source": [
    "# MSMS Standards Evaluation Tool (MSMS-Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c7991-44d9-4b3c-a806-b1a09ba7770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "#want to save pdf fonts? then do this:\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "#path to metatlas repo:\n",
    "metatlas_dir = '/global/homes/t/tharwood/repos/metatlas'\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,metatlas_dir)\n",
    "from metatlas.untargeted import tools as mzm\n",
    "\n",
    "sys.path.insert(0,metatlas_dir)\n",
    "from metatlas.io import feature_tools as ft\n",
    "\n",
    "# import ray\n",
    "# ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30eec5c-f038-4332-985e-ab60fdd20037",
   "metadata": {},
   "outputs": [],
   "source": [
    "chooser_output_dir = 'msms-chooser_outputs/20220308_JGI-AK-TH_TN_507992_PlantStds_Set1_QE-HF_HILICZ_USHXG01602_full/output_batch.tsv'\n",
    "experiment = '20220308_JGI-AK-TH_TN_507992_PlantStds_Set1_QE-HF_HILICZ_USHXG01602'\n",
    "\n",
    "# s = os.path.join('tharwood/MSMS-Chooser_507992_PlantStds_Set1_QE-HF',experiment)\n",
    "\n",
    "df_chooser = pd.read_csv(chooser_output_dir,sep='\\t')\n",
    "df_chooser.columns = [c.lower() for c in df_chooser.columns]\n",
    "df_chooser.rename(columns={'filename':'gnps_filename'},inplace=True)\n",
    "df_chooser['basename'] = df_chooser['gnps_filename'].apply(lambda x: x.split('/')[-1].replace('.mzML','.h5'))\n",
    "df_chooser['compound_name'] = df_chooser['compound_name'] + '-' + df_chooser['adduct']\n",
    "df_chooser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90480a-babe-4844-a4c1-d858c484c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = '/global/cfs/cdirs/metatlas/raw_data/jgi/'\n",
    "\n",
    "mydir = os.path.join(raw_data_dir,experiment)\n",
    "files = glob.glob(os.path.join(mydir,'*.h5'))\n",
    "print(len(files))\n",
    "df_files = pd.DataFrame()\n",
    "df_files['full_filename'] = files\n",
    "df_files['basename'] = df_files['full_filename'].apply(lambda x: os.path.basename(x))\n",
    "df_files['run_order'] = df_files['full_filename'].apply(lambda x: os.path.basename(x).split('_')[-1].replace('.h5','').replace('Run',''))\n",
    "df_files['run_order'] = df_files['run_order'].astype(int)\n",
    "df_files.sort_values('run_order',ascending=True,inplace=True)\n",
    "df_files.reset_index(inplace=True,drop=True)\n",
    "df_chooser = pd.merge(df_chooser,df_files,on='basename',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5153a2c-e6d5-48de-86b8-6fe9c0812d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_chooser['full_filename'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d05a3f-2006-421f-9beb-f2a85712630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chooser.loc[0,'full_filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71cf9d2-bc1e-4e6e-a4fa-5e49ce9bcf3a",
   "metadata": {},
   "source": [
    "# pre-filter MSMS-Chooser output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a8361-7442-4bc9-9b99-66e6ccbd0bb4",
   "metadata": {},
   "source": [
    "Lets wait for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc241797-5835-42c0-aae5-50b60ab5261e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a82ed133-985e-4be9-8ebf-5a53a6fe97f3",
   "metadata": {},
   "source": [
    "# translate scan number to retention time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478badec-2006-4d99-8774-b626ae8e1bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scan_rt = []\n",
    "for f in df_chooser['full_filename'].unique():\n",
    "    if os.path.isfile(f):\n",
    "        df = ft.df_container_from_metatlas_file(f,desired_key='ms1_%s'%os.path.basename(f).split('_')[9].lower())\n",
    "        df2 = ft.df_container_from_metatlas_file(f,desired_key='ms2_%s'%os.path.basename(f).split('_')[9].lower())\n",
    "        temp = df[['rt','i']].drop_duplicates('rt').reset_index(drop=True).copy()\n",
    "        temp2 = df2[['rt','i']].drop_duplicates('rt').reset_index(drop=True).copy()\n",
    "        temp = pd.concat([temp,temp2])\n",
    "        temp.sort_values('rt',inplace=True)\n",
    "        temp.reset_index(drop=True,inplace=True)\n",
    "        temp.index.name = 'scan_number'\n",
    "        temp.reset_index(drop=False,inplace=True)\n",
    "        temp = temp[['scan_number','rt']]\n",
    "        # df = pd.merge(df,temp,on='rt',how='left')\n",
    "        temp['file'] = f\n",
    "        scan_rt.append(temp)\n",
    "    else:\n",
    "        print('no file')\n",
    "scan_rt = pd.concat(scan_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c0c30-1700-4a04-b6f4-55e4cf84869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chooser = pd.merge(df_chooser,scan_rt,left_on=['full_filename','extractscan'],right_on=['file','scan_number'],how='left')\n",
    "df_chooser.drop(columns=['file','scan_number'],inplace=True)\n",
    "df_chooser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6dabeb-07b3-445a-83e0-c0a3233502cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(nrows=2,ncols=2,figsize=(18,18),sharex=True,sharey=True)\n",
    "# ax = ax.flatten()\n",
    "# counter = 0\n",
    "# for g in scan_rt[:4]:\n",
    "#     # print(g['file'].unique())\n",
    "#     x = g[['scan_number']].values\n",
    "#     y = g[['rt']].values\n",
    "#     ax[counter].plot(x,y,'.',label='Data')\n",
    "#     f = LinearRegression().fit(x, y)\n",
    "#     slope = f.coef_[0][0]\n",
    "#     intercept = f.intercept_[0]\n",
    "#     y2 = x*slope + intercept\n",
    "#     ax[counter].plot(x,y2,'-',label='Fit')\n",
    "#     ax[counter].legend()\n",
    "#     counter += 1\n",
    "#     print(slope,intercept)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7af4b4-02da-4aa9-9574-318abe1e825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slope = 0.0020046951007204436 \n",
    "# intercept = 0.17953672418209976\n",
    "ppm_tolerance = 10.0\n",
    "extra_time = 12\n",
    "\n",
    "cols = ['moleculemass', 'extractscan', 'inchi', 'charge',\n",
    "       'ionmode', 'adduct','compound_name','full_filename','rt']\n",
    "df_standards = df_chooser[cols].copy()\n",
    "df_standards.drop_duplicates(inplace=True)\n",
    "df_standards.rename(columns={'moleculemass':'mz','compound_name':'label','rt':'rt_peak'},inplace=True)\n",
    "\n",
    "# NOTE THAT RT_PEAK IS ACTUALLY THE RT OF WHEN THE MSMS WAS COLLECTED NOT THE PEAK\n",
    "# df_standards['rt_peak'] = df_standards['extractscan']*slope + intercept\n",
    "\n",
    "df_standards['rt_min'] = df_standards['rt_peak'] - 0.15\n",
    "df_standards['rt_max'] = df_standards['rt_peak'] + 0.15\n",
    "df_standards['ppm_tolerance'] = ppm_tolerance\n",
    "df_standards['extra_time'] = extra_time\n",
    "\n",
    "df_standards_pos = df_standards[df_standards['ionmode']=='Positive']\n",
    "df_standards_neg = df_standards[df_standards['ionmode']=='Negative']\n",
    "df_standards_pos['polarity'] = 'positive'\n",
    "df_standards_neg['polarity'] = 'negative'\n",
    "\n",
    "df_standards_pos['group_index'] = ft.group_consecutive(df_standards_pos['mz'].values[:],\n",
    "                                         stepsize=ppm_tolerance,\n",
    "                                         do_ppm=True)\n",
    "\n",
    "df_standards_neg['group_index'] = ft.group_consecutive(df_standards_neg['mz'].values[:],\n",
    "                                         stepsize=ppm_tolerance,\n",
    "                                         do_ppm=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bb837-1a49-4089-8f2d-955950c1050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarity,mz,scan_num = df_chooser.loc[0,['ionmode','moleculemass','extractscan']]\n",
    "# print(polarity,mz)\n",
    "# fig,ax = plt.subplots()\n",
    "# idx = abs(df['mz']-mz)<0.01\n",
    "# ax.plot(df.loc[idx,'scan_number'],df.loc[idx,'i'],'.-')\n",
    "# ax.set_xlim([scan_num-30,scan_num+30])\n",
    "# ax.axvline(scan_num,color='k')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c261d76-db2c-4375-a3cf-ff36d0279598",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for f in df_chooser['full_filename'].unique():\n",
    "    data_setup = {}\n",
    "    data_setup['lcmsrun'] = f\n",
    "    data_setup['file_index'] = int(os.path.basename(f).split('_')[-1].replace('.h5','').replace('Run',''))\n",
    "    polarity = os.path.basename(f).split('_')[9]\n",
    "    if polarity == 'POS':\n",
    "        data_setup['polarity'] = 'positive'\n",
    "        data_setup['atlas'] = df_standards_pos\n",
    "    else:\n",
    "        data_setup['polarity'] = 'negative'\n",
    "        data_setup['atlas'] = df_standards_neg\n",
    "        \n",
    "    data_list.append(data_setup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f63ea3-58c6-41d9-8b8f-0071761fa696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ray.remote\n",
    "def unmap_vars(x):\n",
    "    # sys.path.insert(0,metatlas_dir)\n",
    "    # from metatlas.io import feature_tools as ft\n",
    "    d = ft.get_data(x,return_data=True,save_file=False)\n",
    "    d['file_info'] = {}\n",
    "    d['file_info']['filename'] = x['lcmsrun']\n",
    "    d['file_info']['filename'] = os.path.basename(x['lcmsrun'])\n",
    "    group_str = os.path.basename(x['lcmsrun']).split('_')[12]\n",
    "    d['file_info']['group'] = group_str\n",
    "    sample_str = os.path.basename(x['lcmsrun']).split('_')[14]\n",
    "    d['file_info']['sample_blank'] = sample_str\n",
    "    d['file_info']['label'] = '%s-%s'%(group_str,'-'.join(sample_str.split('-')[1:3]))\n",
    "    d['file_info']['run_order'] = x['file_index']\n",
    "    \n",
    "    # keep atlas entries for all adducts for a particular compound being run\n",
    "    idx1 = d['ms1_data']['label'].str.contains(d['file_info']['label'])\n",
    "    d['ms1_data'] = d['ms1_data'][idx1]\n",
    "    idx1 = d['ms1_summary']['label'].str.contains(d['file_info']['label'])\n",
    "    d['ms1_summary'] = d['ms1_summary'][idx1]\n",
    "    idx1 = d['ms2_data']['label'].str.contains(d['file_info']['label'])\n",
    "    d['ms2_data'] = d['ms2_data'][idx1]\n",
    "    # if d['ms1_data'].shape[0]>0:\n",
    "    #     d['ms1_summary'] = ft.calculate_ms1_summary(d['ms1_data'])\n",
    "    return d#['ms1_data']\n",
    "\n",
    "\n",
    "# results = pd.concat(results)\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75478bd8-348e-484f-93f7-457a8dfee2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c4724-a75a-4ba8-a48d-45142bfa4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data_list:\n",
    "    res = unmap_vars(x)\n",
    "    results.append(res)\n",
    "    print(x['lcmsrun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb699ccf-1358-4490-a591-6bc8b576cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# futures = [unmap_vars.remote(x) for x in data_list]\n",
    "# results = ray.get(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c7dd4-3c65-4b80-b16b-a09f6265847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894d7d0-d415-4790-9164-9da208dec444",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['ms1_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bbb71-2fc8-489c-9443-16e51a1ec860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_spectrum(rt_peak,rt_msms):\n",
    "    \"\"\"\n",
    "    list of floats and a float, returns indices that are closest to float\n",
    "    \"\"\"\n",
    "    u_rt = np.unique(rt_msms)\n",
    "    closest_rt = np.argmin(abs(rt_peak-u_rt))\n",
    "    idx = np.argwhere(rt_msms==u_rt[closest_rt]).flatten()\n",
    "    return idx\n",
    "\n",
    "out = []       \n",
    "for r in results: # for each file contains all atlas hits with same:\n",
    "    # compoundname and collision energy as in filename\n",
    "    # will have potentially a hit for each adduct that might have been seen in other files.\n",
    "    for i,row in r['ms1_summary'].iterrows():\n",
    "        # if msms.shape[0]>0:\n",
    "        idx = r['ms1_data']['label']==row['label']\n",
    "        eic = ft.group_duplicates(r['ms1_data'].loc[idx,['label','rt','i','in_feature']],'label',make_string=False)\n",
    "        idx = (r['ms2_data']['label']==row['label']) & (r['ms2_data']['in_feature']==True)\n",
    "        msms = r['ms2_data'][idx].copy()\n",
    "        if msms.shape[0]>0:\n",
    "            msms.reset_index(drop=True,inplace=True)\n",
    "            idx = get_closest_spectrum(row['rt_peak'],msms['rt'].values)\n",
    "            msms = msms.loc[idx]\n",
    "            msms = ft.group_duplicates(msms[['label','mz','rt','i']],'label',make_string=False)\n",
    "            out.append(pd.concat([row,msms.add_suffix('_msms').loc[0],eic.add_suffix('_eic').loc[0]]))\n",
    "            # out.append(pd.concat([row.reset_index(drop=True),msms.add_suffix('_msms'),eic.add_suffix('_eic')],axis=1,ignore_index=False))\n",
    "out = pd.concat(out,axis=1).T#ignore_index=False)\n",
    "out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e172b-d043-46b2-bf7e-2bc9830284d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(df_chooser,out,left_on='compound_name',right_on='label',how='outer')\n",
    "temp.to_csv('diagnostic_peakheight_and_centroids.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376dcd5f-8043-4b59-ae3d-0068f6fa4123",
   "metadata": {},
   "source": [
    "# Old GridSpec Subplot Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5ebfd-805b-4cf8-8e4c-09c8c5e180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(13,17))\n",
    "#     gs=GridSpec(gg.shape[0],2)\n",
    "#     ax1=fig.add_subplot(gs[:,0])\n",
    "#     ax = []\n",
    "#     for i in range(gs.nrows):\n",
    "#         if i==0:\n",
    "#             ax.append(fig.add_subplot(gs[i,1]))\n",
    "#         else:\n",
    "#             ax.append(fig.add_subplot(gs[i,1],sharex=ax[0]))\n",
    "\n",
    "#     ax.insert(0,ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322ebcb-9870-494a-b8a1-96dd4326824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = temp.groupby('inchi')\n",
    "df_g = [gg for _, gg in g]\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "outdir = '/global/homes/t/tharwood/msms_set/downloads/plant_standards_diagnostic_plots_hilic'\n",
    "for gg in df_g:\n",
    "    nrows = gg.shape[0]+4\n",
    "    fig,ax = plt.subplots(nrows=nrows,ncols=1,figsize=(13,4*nrows))\n",
    "    # ax = ax.flatten()\n",
    "    # fig,ax = plt.subplots(nrows=4,ncols=2,figsize=(22,11),gridspec_kw={'width_ratios': [1, 2],'height_ratios':[4,1,1,1]})\n",
    "    # f, (a0, a1) = plt.subplots(2, 3, gridspec_kw={'width_ratios': [3, 1]})\n",
    "    count = 0\n",
    "    labels = []\n",
    "    gg.sort_values('peak_height',ascending=False,inplace=True)\n",
    "    for i,row in gg.iterrows():\n",
    "        if (type(row['mz_msms'])==np.ndarray) & (type(row['rt_eic'])==np.ndarray):\n",
    "            x = row['rt_eic']\n",
    "            y = row['i_eic']\n",
    "            in_feature = row['in_feature_eic']\n",
    "            idx = np.argsort(x)\n",
    "            x = x[idx]\n",
    "            y = y[idx]\n",
    "            in_feature = in_feature[idx]\n",
    "            rep_str = row['label'].index('-CE')\n",
    "            labels.append(row['label'][:rep_str])\n",
    "            idx_infeature = in_feature==True\n",
    "            h = ax[0].plot(x[idx_infeature],y[idx_infeature],label=row['label'],linewidth=2)\n",
    "            ax[0].legend()\n",
    "            ax[0].axvline(row['rt'],linewidth=6,alpha=0.23,color=h[-1].get_color())\n",
    "\n",
    "            ax[1].plot(x[idx_infeature],y[idx_infeature],color=h[-1].get_color(),linewidth=2)\n",
    "            ax[1].axvline(row['rt'],linewidth=6,alpha=0.23,color=h[-1].get_color())\n",
    "            ax[1].set_yscale('log')\n",
    "\n",
    "            ax[2].plot(x,y,color=h[-1].get_color(),linewidth=2)\n",
    "            ax[2].axvline(row['rt'],linewidth=6,alpha=0.23,)\n",
    "            \n",
    "            ax[3].plot(x,y,color=h[-1].get_color(),linewidth=2)\n",
    "            ax[3].axvline(row['rt'],linewidth=6,alpha=0.23,)\n",
    "            ax[3].set_yscale('log')\n",
    "            \n",
    "            # ax[0].set_yscale('log')\n",
    "            # if count<4:\n",
    "            y = row['i_msms']\n",
    "            ax[count+4].axvline(row['moleculemass'],color='grey',alpha=0.4,linewidth=6)\n",
    "            ax[count+4].axvline(row['exactmass'],color='brown',alpha=0.4,linewidth=6)\n",
    "            ax[count+4].vlines(row['mz_msms'],0*y,y,color='k',linewidth=3)\n",
    "            # ax[count+4].vlines(row['mz_msms'],0*y,y,color=h[-1].get_color(),linewidth=3)\n",
    "            # ax[count+4].set_facecolor(h[-1].get_color(),alpha=0.2)\n",
    "            for spine in ax[count+4].spines.values():\n",
    "                    spine.set_edgecolor(h[-1].get_color())\n",
    "            count += 1\n",
    "    if count>0: # plots were made!\n",
    "        ax[0].get_xaxis().set_visible(False)\n",
    "        ax[0].get_shared_x_axes().join(ax[0], ax[1])\n",
    "\n",
    "        ax[2].get_xaxis().set_visible(False)\n",
    "        ax[1].get_shared_x_axes().join(ax[1], ax[2])\n",
    "        for i,a in enumerate(ax[:-1]):\n",
    "            if i>=4:\n",
    "                ax[i].get_xaxis().set_visible(False)\n",
    "                ax[i].get_shared_x_axes().join(ax[i], ax[i+1])\n",
    "\n",
    "        for a in ax:\n",
    "            a.yaxis.get_offset_text().set_fontsize(14)\n",
    "            for spine in a.spines.values():\n",
    "                spine.set_linewidth(2)\n",
    "        for a in ax[4:]:\n",
    "            a.ticklabel_format(axis='y',style='sci', scilimits=(0,0))\n",
    "            a.set_ylim(bottom=0)\n",
    "\n",
    "        for a in ax:\n",
    "            a.tick_params(axis='both',length=10, width=2, which='major', labelsize=14)\n",
    "            a.tick_params(axis='both', which='minor', labelsize=14)\n",
    "        plt.setp(ax[0].get_legend().get_texts(), fontsize=12) # for legend text\n",
    "        ax[1].set_xlabel('Retention Time (min)',fontsize=20)\n",
    "        ax[3].set_xlabel('Retention Time (min)',fontsize=20)\n",
    "        for a in ax:\n",
    "            a.set_ylabel('Intensity',fontsize=20)\n",
    "        ax[-1].set_xlabel('m/z',fontsize=20)\n",
    "        plt.tight_layout()\n",
    "        if not os.path.isdir(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        for basename in pd.unique(labels):\n",
    "            print(basename)\n",
    "            filename = '%s.pdf'%os.path.join(outdir,basename)\n",
    "            fig.savefig(filename)\n",
    "        fig.clear()\n",
    "        plt.close('all')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2425b-268c-4284-980c-76b468716359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e3266-d404-4291-bee6-f7c40072f7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msms-set-env",
   "language": "python",
   "name": "msms-set-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
