{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up metatlas shifter environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_jupyterlab = True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import os\n",
    "from IPython.display import display\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "if in_jupyterlab is False:\n",
    "\n",
    "    sys.path.insert(1, '/global/homes/b/bkieft/metatlas') # Enter your own metatlas repo path here\n",
    "    try:\n",
    "        from metatlas.tools.standards_library import standard_annotation as sta\n",
    "    except ImportError as err:\n",
    "        print('CRITICAL: Could not import standard annotation tools.')\n",
    "        raise StopExecution from err\n",
    "    \n",
    "elif in_jupyterlab is True:\n",
    "\n",
    "    class StopExecution(Exception):\n",
    "        def _render_traceback_(self):\n",
    "            pass\n",
    "\n",
    "    kernel_def = \"\"\"{\"argv\":[\"shifter\",\"--entrypoint\",\"--image=ghcr.io/biorack/metatlas/metatlas_shifter:latest\",\"/usr/local/bin/python\",\"-m\",\n",
    "                    \"ipykernel_launcher\",\"-f\",\"{connection_file}\"],\"display_name\": \"Metatlas Targeted\",\"language\": \"python\",\n",
    "                    \"metadata\": { \"debugger\": true }}\"\"\"\n",
    "    kernel_file_name = Path.home() / \".local\" / \"share\" / \"jupyter\" / \"kernels\" / \"metatlas-targeted\" / \"kernel.json\"\n",
    "    \n",
    "    try:\n",
    "        has_root_kernel = Path(\"/root/.local/share/jupyter/kernels/papermill/kernel.json\").is_file()\n",
    "    except PermissionError:\n",
    "        has_root_kernel = False\n",
    "    if not has_root_kernel and not kernel_file_name.is_file():\n",
    "        kernel_file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with kernel_file_name.open(mode=\"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(kernel_def)\n",
    "        print('CRITICAL: Notebook kernel has been installed. Set kernel to \"Metatlas Targeted\" and re-run notebook.')\n",
    "        raise StopExecution\n",
    "        \n",
    "    try:\n",
    "        from metatlas.tools import notebook  # noqa: E402\n",
    "    except ImportError as err:\n",
    "        print('CRITICAL: Set notebook kernel to \"Metatlas Targeted\" and re-run notebook.')\n",
    "        raise StopExecution from err\n",
    "\n",
    "    source_code_version_id = None\n",
    "    notebook.setup(\"INFO\", source_code_version_id)\n",
    "\n",
    "    try:\n",
    "        from metatlas.tools.standards_library import standard_annotation as sta\n",
    "    except ImportError as err:\n",
    "        print('CRITICAL: Could not import standard annotation tools.')\n",
    "        raise StopExecution from err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read config file and set notebook options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/path/to/config.yaml\"\n",
    "with open(config_path, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(f\"Running with config: {os.path.basename(config_path)}\")\n",
    "print(f\"Running analysis with timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract EIC and Spectra information from files in the run table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"cache\"][\"full_data_from_cache\"] is False:\n",
    "    lcmsruns_table_with_adducts = sta.build_standard_lcmsrun_table(config)\n",
    "    eics_full, top_spectra_full, group_names_full, rt_peaks_full, atlas_full, mols_images = sta.extract_data(lcmsruns_table_with_adducts,config,method=\"find_peaks\")\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"full\", data=(eics_full, top_spectra_full, group_names_full, rt_peaks_full, atlas_full, mols_images, lcmsruns_table_with_adducts))\n",
    "elif config[\"cache\"][\"full_data_from_cache\"] is True:\n",
    "    eics_full, top_spectra_full, group_names_full, rt_peaks_full, atlas_full, mols_images, lcmsruns_table_with_adducts = sta.handle_data(mode=\"load\", config=config, file_suffix=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create interactive plot to choose adduct rt peaks for each standard compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"cache\"][\"selected_data_from_cache\"] is False:\n",
    "    processed_data = sta.process_data_for_plotting(eics_full, top_spectra_full, group_names_full, rt_peaks_full, config)\n",
    "\n",
    "    if config[\"cache\"][\"gui_data_from_cache\"] is True:\n",
    "        processed_data, selection_results_dict, running_notes_dict = sta.handle_data(mode=\"load\", config=config, file_suffix=\"selected\")\n",
    "\n",
    "    elif config[\"cache\"][\"gui_data_from_cache\"] is False:\n",
    "        selection_results_dict = {}\n",
    "        running_notes_dict = {\n",
    "            f\"{row['compound_name']};;{row['standard_lcmsrun']}\": row['annotation_notes']\n",
    "            for _, row in lcmsruns_table_with_adducts.iterrows()\n",
    "        }\n",
    "\n",
    "    sta.create_interactive_plots(processed_data, selection_results_dict, mols_images, running_notes_dict)\n",
    "    # Run next cell after manual selection of adducts\n",
    "\n",
    "elif config[\"cache\"][\"selected_data_from_cache\"] is True:\n",
    "    processed_data, selection_results_dict, running_notes_dict = sta.handle_data(mode=\"load\", config=config, file_suffix=\"selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all adducts have been selected\n",
    "for key, value in selection_results_dict.items():\n",
    "    if isinstance(value, tuple) and value == ([], [], []):\n",
    "        print(f\"WARNING: No selections made for {key}.\")\n",
    "        print(\"Please return to GUI and select adducts for this compound.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selections after GUI is completed\n",
    "if config[\"cache\"][\"selected_data_from_cache\"] is False:\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"selected\", \\\n",
    "                    data=(processed_data, selection_results_dict, running_notes_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter RT Peak, EICs, and Top Spectra by the selected compounds+adducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"cache\"][\"filtered_data_from_cache\"] is False:\n",
    "    all_selected_adducts = sta.filter_by_selected(eics_full, rt_peaks_full, top_spectra_full, selection_results_dict)\n",
    "    all_rt_peaks_formatted = sta.format_rt_peaks(all_selected_adducts['rt_peaks'])\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"filtered\", \\\n",
    "                    data=(all_selected_adducts, all_rt_peaks_formatted))\n",
    "\n",
    "elif config[\"cache\"][\"filtered_data_from_cache\"] is True:\n",
    "    all_selected_adducts, all_rt_peaks_formatted = sta.handle_data(mode=\"load\", config=config, file_suffix=\"filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate static summary reports for each compound and a combined summary document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"analysis\"][\"new_outputs\"][\"generate_static_summary_pdfs\"] is True:\n",
    "    sta.generate_static_summary_plots(processed_data, selection_results_dict, config, timestamp)\n",
    "\n",
    "if config[\"analysis\"][\"new_outputs\"][\"generate_selection_summary_table\"] is True:\n",
    "    sta.generate_selection_summary_table(all_rt_peaks_formatted, running_notes_dict, config, timestamp)\n",
    "\n",
    "if config[\"analysis\"][\"new_outputs\"][\"upload_to_gdrive\"] is True:\n",
    "    check_upload_status = sta.upload_to_google_drive(config[\"project\"][\"standards_output_path\"], config[\"project\"][\"standards_input_file\"], timestamp=\"20250624100944\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop here for compound review before moving to depositing to DBs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify compounds not in the metatlas database Compounds table and store if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"cache\"]['metatlas_db_data_from_cache'] is False:\n",
    "    in_db, notin_db = sta.search_for_matches_in_metatlas_db(all_rt_peaks_formatted, check_by_flat=False) # Check if selected compounds from ALL are in metatlas DB\n",
    "    if len(notin_db) > 0 and config['compounds']['direct_store_to_compounds_table'] is True: # Store selected compounds+adducts in metatlas db\n",
    "        sta.store_in_metatlas_db(notin_db)\n",
    "    sta.check_db_deposit(all_rt_peaks_formatted)\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"metatlas_db\", \\\n",
    "                    data=(in_db, notin_db, all_rt_peaks_formatted))\n",
    "\n",
    "elif config[\"cache\"]['metatlas_db_data_from_cache'] is True:\n",
    "    in_db, notin_db, all_rt_peaks_formatted = sta.handle_data(mode=\"load\", config=config, file_suffix=\"metatlas_db\")\n",
    "    if len(notin_db) > 0 and config['compounds']['direct_store_to_compounds_table'] is True: # Store selected compounds+adducts in metatlas db\n",
    "        sta.store_in_metatlas_db(notin_db)\n",
    "    sta.check_db_deposit(all_rt_peaks_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify compounds+adducts not in atlases and set up new atlas creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"cache\"][\"ema_atlas_data_from_cache\"] is False:\n",
    "    if config[\"atlases\"][\"new_ema_atlas_dtype\"] == \"all\":\n",
    "        rt_peaks_ema_input = all_rt_peaks_formatted\n",
    "    elif config[\"atlases\"][\"new_ema_atlas_dtype\"] == \"best\":\n",
    "        rt_peaks_ema_input = all_rt_peaks_formatted[all_rt_peaks_formatted['best_adduct'] == True]\n",
    "    ema_atlases_data = sta.get_ema_atlas_data(config[\"atlases\"][\"current_ema_atlases\"])\n",
    "    rt_peaks_ema_input_formatted = sta.convert_rt_peaks_to_atlas_format(rt_peaks_ema_input)\n",
    "    matches_to_atlases, nonmatches_to_atlases = sta.search_for_matches_in_atlases(rt_peaks_ema_input_formatted, ema_atlases_data)\n",
    "\n",
    "    if config[\"cache\"][\"rt_correction_data_from_cache\"] is False:\n",
    "        print(\"Setting up RT correction for compounds not yet in atlases using baseline correction method:\\n\")\n",
    "        baseline_to_experimental_qc, baseline_correction_outputs = sta.run_rt_correction(nonmatches_to_atlases, config)\n",
    "        sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"rt_correction\", \\\n",
    "                        data=(baseline_to_experimental_qc, baseline_correction_outputs))\n",
    "\n",
    "    elif config[\"cache\"][\"rt_correction_data_from_cache\"] is True:\n",
    "        baseline_to_experimental_qc, baseline_correction_outputs = sta.handle_data(mode=\"load\",config=config, file_suffix=\"rt_correction\")\n",
    "\n",
    "    nonmatches_to_atlases_rt_corrected = sta.substitute_corrected_rt_values(nonmatches_to_atlases, baseline_correction_outputs)\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"ema_atlases\", \\\n",
    "                    data=(nonmatches_to_atlases_rt_corrected, ema_atlases_data, baseline_to_experimental_qc, baseline_correction_outputs))\n",
    "\n",
    "elif config[\"cache\"][\"ema_atlas_data_from_cache\"] is True:\n",
    "    nonmatches_to_atlases_rt_corrected, ema_atlases_data, baseline_to_experimental_qc, baseline_correction_outputs = sta.handle_data(mode=\"load\", config=config, file_suffix=\"ema_atlases\")\n",
    "    print(f\"Total compounds to add to EMA atlases per chromatography: {nonmatches_to_atlases_rt_corrected['chromatography'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new EMA atlas with top selected reference standards added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['atlases']['save_new_ema_atlases'] is True:\n",
    "    ema_atlas_ids, ema_atlas_names = sta.update_and_save_ema_atlases(nonmatches_to_atlases_rt_corrected, ema_atlases_data, config, timestamp)\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"new_atlas_ids\", \\\n",
    "                    data=(ema_atlas_ids, ema_atlas_names))\n",
    "    ema_atlas_ids, ema_atlas_names = sta.handle_data(mode=\"load\", config=config, file_suffix=\"new_atlas_ids\")\n",
    "\n",
    "    if config['atlases']['direct_deposit_new_emas'] is True:\n",
    "        print(\"New EMA atlases have been saved to disk and deposited in the metatlas database:\")\n",
    "        display(pd.DataFrame.from_dict(ema_atlas_ids))\n",
    "    print(f\"\\nNew EMA atlas locations:\")\n",
    "    display(pd.DataFrame.from_dict(ema_atlas_names))\n",
    "\n",
    "elif config['atlases']['save_new_ema_atlases'] is False:\n",
    "    print(\"No new EMA atlases saved to disk, as 'save_new_ema_atlases' is set to False in the config file.\")\n",
    "    print(\"Here is the new atlas data in memory:\")\n",
    "    display(nonmatches_to_atlases_rt_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify compounds not in MSMS refs and set up new MSMS refs creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"cache\"][\"msms_refs_data_from_cache\"] is False:\n",
    "    if config[\"msms_refs\"][\"new_msms_refs_dtype\"] == \"all\":\n",
    "        rt_peaks_msms_input = all_rt_peaks_formatted\n",
    "        top_spectra_msms_input = all_selected_adducts['top_spectra']\n",
    "    elif config[\"msms_refs\"][\"new_msms_refs_dtype\"] == \"best\":\n",
    "        rt_peaks_msms_input = all_rt_peaks_formatted[all_rt_peaks_formatted['best_adduct'] == True]\n",
    "        top_spectra_msms_input = all_selected_adducts['top_spectra'][all_selected_adducts['top_spectra']['best_adduct'] == True]\n",
    "    msms_refs = sta.get_msms_refs(msms_refs_path=config[\"msms_refs\"][\"current_msms_refs_path\"])\n",
    "    rt_peaks_msms_input_formatted = sta.format_for_msms_refs(rt_peaks_msms_input, top_spectra_msms_input, msms_refs, config)\n",
    "    in_msms_refs, notin_msms_refs = sta.search_for_matches_in_msms_refs(rt_peaks_msms_input_formatted, msms_refs, check_by_flat=True)\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"msms_refs\", \\\n",
    "                    data=(msms_refs, notin_msms_refs, rt_peaks_msms_input, top_spectra_msms_input))\n",
    "\n",
    "elif config[\"cache\"][\"msms_refs_data_from_cache\"] is True:\n",
    "    msms_refs, notin_msms_refs, rt_peaks_msms_input, top_spectra_msms_input = sta.handle_data(mode=\"load\", config=config, file_suffix=\"msms_refs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new MSMS refs table from selected reference standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"msms_refs\"]['save_new_msms_refs'] is True:\n",
    "    sta.update_and_save_msms_refs(msms_refs, notin_msms_refs, config, timestamp)\n",
    "\n",
    "elif config[\"msms_refs\"]['save_new_msms_refs'] is False:\n",
    "    print(\"No new MSMS refs saved to disk, as 'save_new_msms_refs' is set to False in the config file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new MSMS refs MGF file from selected reference standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"msms_refs\"]['save_new_mgf'] is True:\n",
    "    sta.write_mgf_from_top_spectra(top_spectra_msms_input, rt_peaks_msms_input, config, timestamp)\n",
    "\n",
    "elif config[\"msms_refs\"]['save_new_mgf'] is False:\n",
    "    print(\"No new MGF refs saved to disk, as 'save_new_mgf' is set to False in the config file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Metatlas Targeted",
   "language": "python",
   "name": "metatlas-targeted"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
