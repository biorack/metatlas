{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 19:06:12 \u001b[32mINFO    \u001b[0m Running on git commit: b'f3db7e42d52ed8844421d3124358e0717f0b9a2d' from 2025-05-06 11:32:18 -0700 -- 34 minutes ago\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 19:06:13 \u001b[32mINFO    \u001b[0m NERSC=True\n"
     ]
    }
   ],
   "source": [
    "# pylint: disable=wrong-import-position,import-error,missing-class-docstring\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "kernel_def = \"\"\"{\"argv\":[\"shifter\",\"--entrypoint\",\"--image=ghcr.io/biorack/metatlas/metatlas_shifter:latest\",\"/usr/local/bin/python\",\"-m\",\n",
    "                 \"ipykernel_launcher\",\"-f\",\"{connection_file}\"],\"display_name\": \"Metatlas Targeted\",\"language\": \"python\",\n",
    "                 \"metadata\": { \"debugger\": true }}\"\"\"\n",
    "kernel_file_name = Path.home() / \".local\" / \"share\" / \"jupyter\" / \"kernels\" / \"metatlas-targeted\" / \"kernel.json\"\n",
    "try:\n",
    "    has_root_kernel = Path(\"/root/.local/share/jupyter/kernels/papermill/kernel.json\").is_file()\n",
    "except PermissionError:\n",
    "    has_root_kernel = False\n",
    "if not has_root_kernel and not kernel_file_name.is_file():\n",
    "    kernel_file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with kernel_file_name.open(mode=\"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(kernel_def)\n",
    "    print('CRITICAL: Notebook kernel has been installed. Set kernel to \"Metatlas Targeted\" and re-run notebook.')\n",
    "    raise StopExecution\n",
    "try:\n",
    "    from metatlas.tools import notebook  # noqa: E402\n",
    "except ImportError as err:\n",
    "    print('CRITICAL: Set notebook kernel to \"Metatlas Targeted\" and re-run notebook.')\n",
    "    raise StopExecution from err\n",
    "\n",
    "source_code_version_id = \"f3db7e42d52ed8844421d3124358e0717f0b9a2d\"\n",
    "notebook.setup(\"INFO\", source_code_version_id)\n",
    "\n",
    "import notebooks.standards_library.standard_annotation as sta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/global/homes/b/bkieft/metatlas/notebooks/standards_library/ref_std_annotation.yaml\"\n",
    "with open(config_path, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract EIC and Spectra information from files in the run table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n",
      "[19:07:40] ERROR: \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82268aa7c4d94f1a9e008ad9a5321521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Extracting data from lcmsruns:   0%|          | 0/120 [00:00<?, ?compound group/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to: /global/homes/b/bkieft/metatlas_junkdrawer/example_data/schellermetasci/cache/20250506190611_ref_stds_full.pkl\n"
     ]
    }
   ],
   "source": [
    "if config[\"full_data_from_cache\"] is False:\n",
    "    lcmsruns_table_with_adducts = sta.build_standard_lcmsrun_table(config)\n",
    "    eics_full, top_spectra_full, group_names_full, rt_peaks_full, atlas_full, mols_images = sta.extract_data(lcmsruns_table_with_adducts,config,method=\"find_peaks\")\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"full\", data=(eics_full, top_spectra_full, group_names_full, rt_peaks_full, atlas_full, mols_images))\n",
    "elif config[\"full_data_from_cache\"] is True:\n",
    "    eics_full, top_spectra_full, group_names_full, rt_peaks_full, atlas_full, mols_images = sta.handle_data(mode=\"load\", config=config, file_suffix=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create interactive plot to choose adduct rt peaks for each standard compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Union, Any, Optional, Set\n",
    "\n",
    "\n",
    "def create_interactive_plots(\n",
    "    processed_data: List[Dict[str, Any]],\n",
    "    runnum_to_structure_image_grid: Dict[int, str],\n",
    "    selected_good_adducts: Dict[str, List[str]],\n",
    "    ambiguous_adducts: Dict[str, str],\n",
    "    top_adducts: Dict[str, List[str]]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create interactive plots for visualizing and annotating processed data.\n",
    "\n",
    "    Args:\n",
    "        processed_data (List[Dict[str, Any]]): A list of dictionaries containing processed data for each compound group.\n",
    "            Each dictionary should include keys such as 'eics', 'rt_peaks', 'top_spectra', 'adduct_color', 'group_id',\n",
    "            'unique_id', 'group_file', and 'compound_name'.\n",
    "        runnum_to_structure_image_grid (Dict[int, str]): A dictionary mapping run numbers to base64-encoded molecular structure images.\n",
    "        selected_good_adducts (Dict[str, List[str]]): A dictionary mapping unique compound IDs to lists of selected\n",
    "            adduct-peak combinations in the format \"adduct||peak_index\".\n",
    "        ambiguous_adducts (Dict[str, str]): A dictionary mapping unique compound IDs to ambiguous annotations.\n",
    "        top_adducts (Dict[str, List[str]]): A dictionary mapping unique compound IDs to lists of top adducts.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a state object to track current values\n",
    "    class PlotState:\n",
    "        def __init__(self):\n",
    "            self.current_index = 0\n",
    "            self.current_unique_id = processed_data[0]['unique_id'] if processed_data else None\n",
    "            # Add debug counters\n",
    "            self.update_count = 0\n",
    "    \n",
    "    state = PlotState()\n",
    "    \n",
    "    # Create persistent widgets (those that don't need to be recreated)\n",
    "    image_toggle = widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description='Show Structures',\n",
    "        tooltip='Toggle to show/hide the compound structure image',\n",
    "        layout=widgets.Layout(width='150px', margin='5px 0 0 0')\n",
    "    )\n",
    "    yaxis_toggle = widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description='Shared Y-Axis',\n",
    "        tooltip='Toggle between unique and shared y-axes for non-log EIC plots',\n",
    "        layout=widgets.Layout(width='150px', margin='30px 0 0 0')\n",
    "    )\n",
    "    next_button = widgets.Button(description=\"Next Group\")\n",
    "    previous_button = widgets.Button(description=\"Previous Group\")\n",
    "    progress_label = widgets.Label(value=f\"1/{len(processed_data)} Groups Completed\")\n",
    "    navigate_textbox = widgets.Text(\n",
    "        placeholder='Index...',\n",
    "        description='Go to:',\n",
    "        layout=widgets.Layout(width='50px')\n",
    "    )\n",
    "    navigate_button = widgets.Button(\n",
    "        description=\"Go\",\n",
    "        layout=widgets.Layout(width='50px')\n",
    "    )\n",
    "    compound_image_widget = widgets.Image(\n",
    "        format='png',\n",
    "        layout=widgets.Layout(\n",
    "            width='400px',\n",
    "            height='400px',\n",
    "            margin='0 0 0 50px',\n",
    "            display='none'  # Initially hidden\n",
    "        )\n",
    "    )\n",
    "    compound_image_label = widgets.Label(\n",
    "        value=\"Compound Structures\",\n",
    "        layout=widgets.Layout(margin='0 0 10px 0')\n",
    "    )\n",
    "    completion_label = widgets.Label(value=\"\", layout=widgets.Layout(margin=\"0 0 0 0\"))\n",
    "    output_container = widgets.Output()\n",
    "    \n",
    "    # Main output area that will be refreshed\n",
    "    main_output = widgets.Output()\n",
    "    \n",
    "    # Define event handlers for persistent widgets\n",
    "    def on_image_toggle_change(change):\n",
    "        if image_toggle.value:\n",
    "            image_toggle.description = 'Hide Structures'\n",
    "            compound_image_widget.layout.display = 'block'\n",
    "        else:\n",
    "            image_toggle.description = 'Show Structures'\n",
    "            compound_image_widget.layout.display = 'none'\n",
    "    \n",
    "    def update_progress_text():\n",
    "        progress_label.value = f\"{state.current_index + 1}/{len(processed_data)} Groups Completed\"\n",
    "    \n",
    "    def on_toggle_change(change):\n",
    "        yaxis_toggle.description = 'Shared Y-Axis' if not yaxis_toggle.value else 'Unique Y-Axis'\n",
    "        update_display()\n",
    "    \n",
    "    def next_group(b):\n",
    "        if state.current_index < len(processed_data) - 1:\n",
    "            state.current_index += 1\n",
    "            state.current_unique_id = processed_data[state.current_index]['unique_id']\n",
    "            image_toggle.value = False\n",
    "            update_display()\n",
    "            completion_label.value = \"\"\n",
    "        else:\n",
    "            completion_label.value = \"Analysis completed!\"\n",
    "    \n",
    "    def previous_group(b):\n",
    "        if state.current_index > 0:\n",
    "            state.current_index -= 1\n",
    "            state.current_unique_id = processed_data[state.current_index]['unique_id']\n",
    "            image_toggle.value = False\n",
    "            update_display()\n",
    "            completion_label.value = \"\"\n",
    "        else:\n",
    "            output_container.clear_output(wait=True)\n",
    "            with output_container:\n",
    "                print(\"Already at the first group.\")\n",
    "    \n",
    "    def navigate_to_group(b):\n",
    "        try:\n",
    "            target_index = int(navigate_textbox.value) - 1\n",
    "            if 0 <= target_index < len(processed_data):\n",
    "                state.current_index = target_index\n",
    "                state.current_unique_id = processed_data[state.current_index]['unique_id']\n",
    "                update_display()\n",
    "            else:\n",
    "                output_container.clear_output(wait=True)\n",
    "                with output_container:\n",
    "                    print(f\"Invalid index. Please enter a number between 1 and {len(processed_data)}.\")\n",
    "        except ValueError:\n",
    "            output_container.clear_output(wait=True)\n",
    "            with output_container:\n",
    "                print(\"Invalid input. Please enter a valid integer.\")\n",
    "    \n",
    "    # Bind event handlers\n",
    "    image_toggle.observe(on_image_toggle_change, names='value')\n",
    "    yaxis_toggle.observe(on_toggle_change, names='value')\n",
    "    next_button.on_click(next_group)\n",
    "    previous_button.on_click(previous_group)\n",
    "    navigate_button.on_click(navigate_to_group)\n",
    "    \n",
    "    # Helper function to directly update dictionaries when checkboxes change\n",
    "    def create_checkbox_handlers(unique_id, all_adducts_checkboxes, adduct_peak_combinations, ambiguous_checkbox, top_adducts_checkboxes):\n",
    "        \"\"\"Creates handlers that explicitly use the provided unique_id\"\"\"\n",
    "        \n",
    "        def on_all_adducts_change(change):\n",
    "            \n",
    "            if ambiguous_checkbox.value:\n",
    "                # Mark as ambiguous\n",
    "                ambiguous_adducts[unique_id] = unique_id\n",
    "                # Remove from other dictionaries\n",
    "                if unique_id in selected_good_adducts:\n",
    "                    del selected_good_adducts[unique_id]\n",
    "                if unique_id in top_adducts:\n",
    "                    del top_adducts[unique_id]\n",
    "                \n",
    "            else:\n",
    "                # Get all selected adduct combinations\n",
    "                selected_combos = []\n",
    "                checkbox_dict = {c.description: c for c in all_adducts_checkboxes[:-1]}  # Exclude ambiguous checkbox\n",
    "                \n",
    "                for combo in adduct_peak_combinations:\n",
    "                    if combo['description'] in checkbox_dict and checkbox_dict[combo['description']].value:\n",
    "                        selected_combos.append(f\"{combo['adduct']}||{combo['peak_index']}\")\n",
    "                \n",
    "                # Update dictionary only if selections were made\n",
    "                if selected_combos:\n",
    "                    selected_good_adducts[unique_id] = selected_combos\n",
    "                elif unique_id in selected_good_adducts:\n",
    "                    del selected_good_adducts[unique_id]\n",
    "                \n",
    "                # Remove from ambiguous\n",
    "                if unique_id in ambiguous_adducts:\n",
    "                    del ambiguous_adducts[unique_id]\n",
    "        \n",
    "        def on_top_adducts_change(change):\n",
    "            selected = []\n",
    "            for checkbox in top_adducts_checkboxes.children:\n",
    "                if checkbox.value:\n",
    "                    selected.append(checkbox.description)\n",
    "            \n",
    "            if selected:\n",
    "                top_adducts[unique_id] = selected\n",
    "            elif unique_id in top_adducts:\n",
    "                del top_adducts[unique_id]\n",
    "        \n",
    "        return on_all_adducts_change, on_top_adducts_change\n",
    "\n",
    "    # Layout Definitions\n",
    "    def create_layout(all_adducts_checkboxes, top_adducts_checkboxes):\n",
    "        checkbox_layout = widgets.VBox(\n",
    "            children=[\n",
    "                widgets.Label(value=\"Select all good adducts:\"),\n",
    "                *all_adducts_checkboxes\n",
    "            ],\n",
    "            layout=widgets.Layout(\n",
    "                border='1px solid black',\n",
    "                padding='10px',\n",
    "                margin='10px',\n",
    "                width='300px',\n",
    "                align_items='flex-start'  # Align items to the start (left)\n",
    "            )\n",
    "        )\n",
    "        top_adducts_checkboxes_layout = widgets.VBox(\n",
    "            children=[\n",
    "                widgets.Label(value=\"Select best adduct(s) - default intensity:\"),\n",
    "                top_adducts_checkboxes\n",
    "            ],\n",
    "            layout=widgets.Layout(\n",
    "                border='1px solid black',\n",
    "                padding='10px',\n",
    "                margin='10px',\n",
    "                width='300px',\n",
    "                align_items='flex-start'\n",
    "            )\n",
    "        )\n",
    "        go_to_label = widgets.Label(value=\"Go To:\")\n",
    "        go_to_layout = widgets.HBox(\n",
    "            [go_to_label, navigate_textbox, navigate_button],\n",
    "            layout=widgets.Layout(\n",
    "                justify_content='flex-start',  # Align to the far left\n",
    "                spacing='5px',\n",
    "                margin='30px 0 0 0'  # Add space above the widget\n",
    "            )\n",
    "        )\n",
    "        navigate_textbox.description = \"\"\n",
    "        navigate_textbox.layout = widgets.Layout(width='150px')  # Decrease the size of the search box\n",
    "    \n",
    "        compound_image_widget.layout.display = 'none'\n",
    "        image_toggle.layout.margin = '0 0 0 50px'\n",
    "    \n",
    "        navigation_buttons_layout = widgets.HBox(\n",
    "            [\n",
    "                widgets.VBox([next_button, previous_button]),  # Stack Previous and Next buttons vertically\n",
    "                image_toggle  # Place the Image Toggle button to the right\n",
    "            ],\n",
    "            layout=widgets.Layout(\n",
    "                justify_content='flex-start',  # Align items to the left\n",
    "                spacing='10px',  # Add spacing between elements\n",
    "                margin='0 0 0 0'  # No margin for the navigation buttons\n",
    "            )\n",
    "        )\n",
    "        button_layout = widgets.VBox(\n",
    "            [navigation_buttons_layout, progress_label, go_to_layout, yaxis_toggle],\n",
    "            layout=widgets.Layout(\n",
    "                align_items='flex-start',\n",
    "                spacing='5px'\n",
    "            )\n",
    "        )\n",
    "        compound_image_container = widgets.VBox(\n",
    "            [compound_image_label, compound_image_widget],\n",
    "            layout=widgets.Layout(\n",
    "                align_items='center',  # Center-align the content\n",
    "                padding='10px',  # Add padding around the container\n",
    "                border='1px solid lightgray',  # Optional: Add a border for better visibility\n",
    "                width='500px'  # Ensure the container is slightly wider than the image\n",
    "            )\n",
    "        )\n",
    "        top_layout = widgets.HBox(\n",
    "            [checkbox_layout, top_adducts_checkboxes_layout, button_layout, compound_image_container],\n",
    "            layout=widgets.Layout(\n",
    "                align_items='flex-start',\n",
    "                justify_content='flex-start',\n",
    "                spacing='10px'\n",
    "            )\n",
    "        )\n",
    "        final_layout = widgets.VBox(\n",
    "            [completion_label, top_layout],\n",
    "            layout=widgets.Layout(\n",
    "                align_items='flex-start',  # Center-align the content\n",
    "                padding='0px',  # Add padding around the container\n",
    "            )\n",
    "        )\n",
    "        return final_layout\n",
    "    \n",
    "    # Main display update function that recreates the plots and widgets\n",
    "    def update_display():\n",
    "        state.update_count += 1\n",
    "        main_output.clear_output(wait=True)\n",
    "        \n",
    "        # Get current data\n",
    "        data = processed_data[state.current_index]\n",
    "        unique_id = data['unique_id']\n",
    "        state.current_unique_id = unique_id\n",
    "\n",
    "        # Get data from current group\n",
    "        eics = data['eics']\n",
    "        top_spectra = data['top_spectra']\n",
    "        rt_peaks = data['rt_peaks']\n",
    "        adduct_color = data['adduct_color']\n",
    "        group_id = data['group_id']\n",
    "        unique_id = data['unique_id']\n",
    "        group_run_number = data['group_run_number']\n",
    "\n",
    "        # Extract adduct-peak combinations from rt_peaks and top_spectra\n",
    "        adduct_peak_combinations = []\n",
    "        if isinstance(rt_peaks, pd.DataFrame) and not rt_peaks.empty:\n",
    "            # Create a mapping from adducts to peak indices and intensities\n",
    "            adduct_to_peaks = {}\n",
    "            for _, peak_row in rt_peaks.iterrows():\n",
    "                adduct = peak_row['adduct'] if 'adduct' in peak_row else None\n",
    "                if adduct:\n",
    "                    if adduct not in adduct_to_peaks:\n",
    "                        adduct_to_peaks[adduct] = []\n",
    "                    adduct_to_peaks[adduct].append({\n",
    "                        'peak_index': peak_row['peak_index'],\n",
    "                        'intensity': peak_row['intensity']\n",
    "                    })\n",
    "\n",
    "        # Create unique identifiers for each adduct-peak combination\n",
    "        for adduct, peaks in adduct_to_peaks.items():\n",
    "            max_intensity = max(peak['intensity'] for peak in peaks)\n",
    "            for peak in peaks:\n",
    "                # Check if there is an MS2 spectrum for this adduct+peak_index\n",
    "                if top_spectra.empty:\n",
    "                    has_ms2 = False\n",
    "                else:\n",
    "                    has_ms2 = not top_spectra[\n",
    "                        (top_spectra['adduct'] == adduct) & \n",
    "                        (top_spectra['peak_index'] == peak['peak_index'])\n",
    "                    ].empty\n",
    "\n",
    "                # Add a star to the description if MS2 spectrum exists\n",
    "                description = f\"{adduct} ({peak['peak_index']}){' *' if has_ms2 else ''}\"\n",
    "                adduct_peak_combinations.append({\n",
    "                    'adduct': adduct,\n",
    "                    'peak_index': peak['peak_index'],\n",
    "                    'description': description,\n",
    "                    'max_intensity': max_intensity\n",
    "                })\n",
    "\n",
    "        # Sort adduct_peak_combinations by max_intensity in descending order\n",
    "        adduct_peak_combinations.sort(key=lambda x: x['max_intensity'], reverse=True)\n",
    "\n",
    "        # Create the summary EIC plot data\n",
    "        group_run_eics = [\n",
    "            eic for pdata in processed_data if pdata['group_run_number'] == group_run_number\n",
    "            for eic in pdata['eics'].values()\n",
    "        ]\n",
    "        summary_traces = []\n",
    "        summary_xmin_list = []\n",
    "        summary_xmax_list = []\n",
    "        for eic in group_run_eics:\n",
    "            # Loop through each row in the eic DataFrame\n",
    "            for _, eic_row in eic.iterrows():\n",
    "                # Filter data where intensity is above 1e5\n",
    "                valid_indices = eic_row['i'] > 1e5\n",
    "                filtered_rt = eic_row['rt'][valid_indices]\n",
    "                filtered_i = eic_row['i'][valid_indices]\n",
    "\n",
    "                if len(filtered_rt) > 0:  # Ensure there are valid points\n",
    "                    # Sort retention times\n",
    "                    rt_sort = np.argsort(filtered_rt)\n",
    "                    adduct = sta.get_adduct(eic_row['label'])  # Extract adduct from the label\n",
    "                    color = adduct_color.get(adduct, 'gray')  # Default to gray if adduct color is missing\n",
    "                    label = eic_row['label']\n",
    "\n",
    "                    # Update x_min and x_max based on filtered data\n",
    "                    summary_xmin_list.append(filtered_rt.min())\n",
    "                    summary_xmax_list.append(filtered_rt.max())\n",
    "\n",
    "                    # Add a trace for the current adduct\n",
    "                    summary_traces.append(\n",
    "                        go.Scatter(\n",
    "                            x=filtered_rt[rt_sort],\n",
    "                            y=filtered_i[rt_sort],\n",
    "                            mode='lines',\n",
    "                            name=f\"{label}\",\n",
    "                            line=dict(color=color),\n",
    "                            showlegend=False\n",
    "                        )\n",
    "                    )\n",
    "        x_min = min(summary_xmin_list) if summary_xmin_list else None\n",
    "        x_max = max(summary_xmax_list) if summary_xmax_list else None\n",
    "\n",
    "        # Create the figure with subplots\n",
    "        num_spectra = len(top_spectra)\n",
    "        if num_spectra == 0:\n",
    "            num_spectra = 1  # Ensure at least one row for empty top_spectra\n",
    "        num_columns = 4\n",
    "        num_spectra_rows = math.ceil(num_spectra / num_columns)\n",
    "\n",
    "        # Adjust subplot titles and specifications\n",
    "        subplot_titles = [\n",
    "            \"Sample\",\n",
    "            \"Blank\",\n",
    "            \"EIC Summary\",\n",
    "            \"Sample (Log)\",\n",
    "            \"Blank (Log)\",\n",
    "            *(f\"\" if top_spectra.empty else f\"{row['adduct']} @ {round(row['rt'], 2)} mins\" for _, row in top_spectra.iterrows())\n",
    "        ]\n",
    "\n",
    "        specs = [\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"scatter\", \"rowspan\": 2, \"colspan\": 2}, None],\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, None, None],\n",
    "            *[[{\"type\": \"scatter\"} for _ in range(4)] for _ in range(num_spectra_rows)]\n",
    "        ]\n",
    "\n",
    "        # Ensure there is at least one row for empty top_spectra\n",
    "        if top_spectra.empty:\n",
    "            subplot_titles.extend([\"\"] * (num_spectra_rows * num_columns - len(subplot_titles) + 5))\n",
    "            specs.extend([[{\"type\": \"scatter\"} for _ in range(4)] for _ in range(num_spectra_rows - 1)])\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=2 + num_spectra_rows,\n",
    "            cols=4,\n",
    "            shared_xaxes=False,\n",
    "            shared_yaxes=yaxis_toggle.value,\n",
    "            vertical_spacing=0.3 / (2 + num_spectra_rows),\n",
    "            horizontal_spacing=0.1,\n",
    "            subplot_titles=subplot_titles,\n",
    "            specs=specs\n",
    "        )\n",
    "\n",
    "        # Add fallback traces if top_spectra is empty\n",
    "        if top_spectra.empty:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[],\n",
    "                    y=[],\n",
    "                    mode='lines',\n",
    "                    name=\"No Spectra Available\",\n",
    "                    line=dict(color='gray'),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=3,\n",
    "                col=1\n",
    "            )\n",
    "\n",
    "        # Add the summary traces to the spanning subplot\n",
    "        fig.update_xaxes(range=[x_min, x_max], row=1, col=3)  # Set x-axis bounds for the summary graph\n",
    "        for trace in summary_traces:\n",
    "            fig.add_trace(trace, row=1, col=3)  # Add to row 1, col 3\n",
    "\n",
    "        # Add EIC traces for each adduct/peak\n",
    "        for idx, (lcmsrun_path, eic) in enumerate(eics.items()):\n",
    "            for i, eic_row in eic.iterrows():\n",
    "                rt_sort = np.argsort(eic_row['rt'])\n",
    "                adduct = sta.get_adduct(eic_row['label'])\n",
    "                color = adduct_color[adduct]\n",
    "                \n",
    "                # Determine row and column for the current trace\n",
    "                row = 1 if idx < 2 else 2\n",
    "                col = (idx % 2) + 1\n",
    "                \n",
    "                # Dynamic facet_name determination \n",
    "                if row == 1 and col == 1:\n",
    "                    facet_name = \"Sample\"\n",
    "                elif row == 1 and col == 2:\n",
    "                    facet_name = \"Blank\"\n",
    "                elif row == 2 and col == 1:\n",
    "                    facet_name = \"Sample (Log)\"\n",
    "                elif row == 2 and col == 2:\n",
    "                    facet_name = \"Blank (Log)\"\n",
    "\n",
    "                # Add line traces for raw intensity\n",
    "                trace_index = len(fig.data)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=eic_row['rt'][rt_sort],\n",
    "                        y=eic_row['i'][rt_sort],\n",
    "                        mode='lines',\n",
    "                        name=f\"{adduct} {facet_name}\",  # Include facet_name in legend\n",
    "                        line=dict(color=color),\n",
    "                        showlegend=True\n",
    "                    ),\n",
    "                    row=row,\n",
    "                    col=col\n",
    "                )\n",
    "\n",
    "                # Recalculate facet_name for log-transformed traces\n",
    "                if row + 1 == 2 and col == 1:\n",
    "                    facet_name = \"Sample (Log)\"\n",
    "                elif row + 1 == 2 and col == 2:\n",
    "                    facet_name = \"Blank (Log)\"\n",
    "\n",
    "                # Add line traces for log-transformed intensity\n",
    "                trace_index = len(fig.data)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=eic_row['rt'][rt_sort],\n",
    "                        y=np.log10(eic_row['i'][rt_sort].astype(float)),\n",
    "                        mode='lines',\n",
    "                        name=f\"{adduct} {facet_name}\",  # Include updated facet_name in legend\n",
    "                        line=dict(color=color),\n",
    "                        showlegend=True\n",
    "                    ),\n",
    "                    row=row + 1,  # Log traces go to the next row\n",
    "                    col=col\n",
    "                )\n",
    "\n",
    "                # Add peak markers for each peak associated with this adduct\n",
    "                if not rt_peaks.empty:\n",
    "                    if facet_name == \"Sample\" or facet_name == \"Sample (Log)\":\n",
    "                        adduct_peaks = rt_peaks[rt_peaks['adduct'] == adduct]\n",
    "                        for _, peak_info in adduct_peaks.iterrows():\n",
    "                            peak_rt = peak_info['rt_peak']\n",
    "                            peak_index = peak_info['peak_index']\n",
    "                            peak_intensity = peak_info['intensity']\n",
    "\n",
    "                            # Add marker for raw intensity\n",
    "                            fig.add_trace(\n",
    "                                go.Scatter(\n",
    "                                    x=[peak_rt],\n",
    "                                    y=[peak_intensity],\n",
    "                                    mode='markers',\n",
    "                                    marker=dict(color=color, size=10),\n",
    "                                    name=f\"{adduct} RT {peak_index}\",\n",
    "                                    showlegend=False\n",
    "                                ),\n",
    "                                row=row,\n",
    "                                col=col\n",
    "                            )\n",
    "\n",
    "                            # Add marker for log-transformed intensity\n",
    "                            fig.add_trace(\n",
    "                                go.Scatter(\n",
    "                                    x=[peak_rt],\n",
    "                                    y=[np.log10(peak_intensity)],\n",
    "                                    mode='markers',\n",
    "                                    marker=dict(color=color, size=10),\n",
    "                                    name=f\"{adduct} RT {peak_index}\",\n",
    "                                    showlegend=False\n",
    "                                ),\n",
    "                                row=row + 1,  # Log traces go to the next row\n",
    "                                col=col\n",
    "                            )\n",
    "\n",
    "                # Add MS2 spectra markers\n",
    "                if not top_spectra.empty:\n",
    "                    if facet_name == \"Sample\" or facet_name == \"Sample (Log)\":\n",
    "                        adduct_spectra = top_spectra[top_spectra['adduct'] == adduct]\n",
    "                        # Remove adduct filtering to show all MS2 spectra\n",
    "                        for _, spectrum_row in adduct_spectra.iterrows():\n",
    "                            spectrum_adduct = spectrum_row['adduct']\n",
    "                            spectrum_peak_index = spectrum_row['peak_index']\n",
    "                            rounded_rt = round(spectrum_row['rt'], 2)\n",
    "                            marker_color = adduct_color.get(spectrum_adduct, 'gray')\n",
    "\n",
    "                            # Find closest point in the current EIC\n",
    "                            sorted_rt = eic_row['rt'][rt_sort]\n",
    "                            sorted_intensity = eic_row['i'][rt_sort]\n",
    "                            \n",
    "                            # Skip if no intensity data available\n",
    "                            if len(sorted_rt) == 0 or len(sorted_intensity) == 0:\n",
    "                                continue\n",
    "                                \n",
    "                            # Find the closest RT point in the EIC\n",
    "                            closest_idx = np.argmin(np.abs(sorted_rt - spectrum_row['rt']))\n",
    "                            \n",
    "                            if closest_idx >= len(sorted_rt):\n",
    "                                # If the index is out of bounds, skip this spectrum\n",
    "                                print(f\"Warning: RT {spectrum_row['rt']} is out of bounds for EIC RT range.\")\n",
    "                                continue\n",
    "                                \n",
    "                            raw_intensity = sorted_intensity[closest_idx]\n",
    "                            log_intensity = np.log10(raw_intensity)\n",
    "                            \n",
    "                            # Display marker for all spectra on the raw intensity plot\n",
    "                            fig.add_trace(\n",
    "                                go.Scatter(\n",
    "                                    x=[spectrum_row['rt']],\n",
    "                                    y=[raw_intensity],\n",
    "                                    mode='markers',\n",
    "                                    marker=dict(color=marker_color, symbol='x', size=10),\n",
    "                                    name=f\"MS2: {spectrum_adduct} ({spectrum_peak_index}) @ {rounded_rt}\",\n",
    "                                    showlegend=False\n",
    "                                ),\n",
    "                                row=row,\n",
    "                                col=col\n",
    "                            )\n",
    "                            \n",
    "                            # Display marker for all spectra on the log-transformed plot\n",
    "                            fig.add_trace(\n",
    "                                go.Scatter(\n",
    "                                    x=[spectrum_row['rt']],\n",
    "                                    y=[log_intensity],\n",
    "                                    mode='markers',\n",
    "                                    marker=dict(color=marker_color, symbol='x', size=10),\n",
    "                                    name=f\"MS2: {spectrum_adduct} ({spectrum_peak_index}) @ {rounded_rt}\",\n",
    "                                    showlegend=False\n",
    "                                ),\n",
    "                                row=row + 1,  # Log traces go to the next row\n",
    "                                col=col\n",
    "                            )\n",
    "\n",
    "        # Add traces for Spectra plots\n",
    "        if not top_spectra.empty:\n",
    "            top_spectra_sorted = top_spectra.sort_values(['adduct', 'peak_index'])\n",
    "\n",
    "            mz_list = [lst[0] for lst in top_spectra_sorted['spectrum'] if isinstance(lst, (list, np.ndarray)) and len(lst) > 0]\n",
    "            mz_list_flattened = np.concatenate([np.ravel(arr) if isinstance(arr, np.ndarray) else np.array([arr]) for arr in mz_list])\n",
    "            lowest_mz = np.min(mz_list_flattened)*0.9\n",
    "            highest_mz = np.max(mz_list_flattened)*1.1\n",
    "\n",
    "            for i, spectrum_row in enumerate(top_spectra_sorted.iterrows()):\n",
    "                mz_values = spectrum_row[1]['spectrum'][0]\n",
    "                i_values = spectrum_row[1]['spectrum'][1]\n",
    "                adduct = spectrum_row[1]['adduct']\n",
    "                color = adduct_color[adduct]\n",
    "                precursor_mz = spectrum_row[1]['precursor_mz']\n",
    "                peak_index = spectrum_row[1]['peak_index']\n",
    "                spectrum_title = f\"{adduct} ({peak_index}) @ {round(spectrum_row[1]['rt'], 2)} mins\"\n",
    "\n",
    "                # Determine the row and column for this spectrum\n",
    "                spectrum_row_idx = 3 + (i // num_columns)  # Start after EIC rows\n",
    "                spectrum_col = (i % num_columns) + 1\n",
    "\n",
    "                # Update the x-axis range for the current subplot\n",
    "                fig.update_xaxes(\n",
    "                    range=[lowest_mz, highest_mz],  # Set x-axis limits\n",
    "                    row=spectrum_row_idx,\n",
    "                    col=spectrum_col\n",
    "                )\n",
    "\n",
    "                # Add vertical lines for each point\n",
    "                for mz, intensity in zip(mz_values, i_values):\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=[mz, mz],\n",
    "                            y=[0, intensity],\n",
    "                            mode='lines',\n",
    "                            line=dict(color=color),\n",
    "                            showlegend=False\n",
    "                        ),\n",
    "                        row=spectrum_row_idx,\n",
    "                        col=spectrum_col\n",
    "                    )\n",
    "\n",
    "                # Add markers for each point\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=mz_values,\n",
    "                        y=i_values,\n",
    "                        mode='markers',\n",
    "                        marker=dict(color=color, size=6),\n",
    "                        name=f\"Spectrum {i+1}: {adduct}\",\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=spectrum_row_idx,\n",
    "                    col=spectrum_col\n",
    "                )\n",
    "\n",
    "                # Add a black circle at precursor_mz (y=0)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[precursor_mz],\n",
    "                        y=[0],\n",
    "                        mode='markers',\n",
    "                        marker=dict(color='black', symbol='circle', size=20),\n",
    "                        name=f\"Precursor MZ: {precursor_mz}\",\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=spectrum_row_idx,\n",
    "                    col=spectrum_col\n",
    "                )\n",
    "                \n",
    "                fig.layout.annotations[5 + i].text = spectrum_title\n",
    "\n",
    "        # Update layout\n",
    "        fig_title = (group_id.replace('_', '  |  '))\n",
    "        fig.update_layout(\n",
    "            hoverlabel=dict(\n",
    "                font_size=11,  # Increase font size for better readability\n",
    "                namelength=-1  # Show the full name without truncation\n",
    "            ),\n",
    "            title=dict(text=fig_title, font=dict(size=14), x=0.5, xanchor=\"center\"),\n",
    "            height=700 + 300 * num_spectra_rows,\n",
    "            width=1500,\n",
    "            plot_bgcolor=\"white\",\n",
    "            paper_bgcolor=\"white\",\n",
    "            legend=dict(\n",
    "                orientation=\"h\",\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"top\",\n",
    "                x=0.5,\n",
    "                y=-0.2\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Add black borders and keep gridlines\n",
    "        fig.update_xaxes(\n",
    "            showline=True,  # Show axis line\n",
    "            linewidth=1,  # Set line width\n",
    "            linecolor=\"black\",  # Set line color to black\n",
    "            showgrid=True,  # Keep gridlines\n",
    "            gridcolor=\"lightgray\"  # Set gridline color\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            showline=True,  # Show axis line\n",
    "            linewidth=1,  # Set line width\n",
    "            linecolor=\"black\",  # Set line color to black\n",
    "            showgrid=True,  # Keep gridlines\n",
    "            gridcolor=\"lightgray\"  # Set gridline color\n",
    "        )\n",
    "\n",
    "        # Update the compound image based on group_run_number\n",
    "        if group_run_number in runnum_to_structure_image_grid:\n",
    "            compound_image_widget.value = base64.b64decode(runnum_to_structure_image_grid[group_run_number])\n",
    "            compound_image_label.value = f\"Structures in Run{group_run_number}\"  # Update the label text\n",
    "        else:\n",
    "            compound_image_widget.value = b''  # Clear the image if not found\n",
    "            compound_image_label.value = \"No Structures Found\"  # Update the label text\n",
    "        \n",
    "        # Create new checkboxes for this unique_id\n",
    "        all_adducts_checkboxes = []\n",
    "        for combo in adduct_peak_combinations:\n",
    "            # Check if this combo is selected\n",
    "            is_selected = False\n",
    "            if unique_id in selected_good_adducts:\n",
    "                combo_id = f\"{combo['adduct']}||{combo['peak_index']}\"\n",
    "                is_selected = combo_id in selected_good_adducts[unique_id]\n",
    "            \n",
    "            checkbox = widgets.Checkbox(\n",
    "                value=is_selected,\n",
    "                description=combo['description'],\n",
    "                disabled=False,\n",
    "                layout=widgets.Layout(width='300px', margin='0 0 0 -75px')\n",
    "            )\n",
    "            all_adducts_checkboxes.append(checkbox)\n",
    "        \n",
    "        # Create ambiguous checkbox\n",
    "        ambiguous_checkbox = widgets.Checkbox(\n",
    "            value=(unique_id in ambiguous_adducts),\n",
    "            description=\"Ambiguous\",\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='300px', margin='0 0 0 -75px')\n",
    "        )\n",
    "        all_adducts_checkboxes.append(ambiguous_checkbox)\n",
    "        \n",
    "        # Create top_adducts checkboxes\n",
    "        top_adducts_options = list(dict.fromkeys(combo['adduct'] for combo in adduct_peak_combinations))\n",
    "        top_adducts_children = []\n",
    "        \n",
    "        # Pre-select first adduct if this is a new unique_id\n",
    "        default_to_first = unique_id not in top_adducts and len(top_adducts_options) > 0\n",
    "        \n",
    "        for idx, adduct in enumerate(top_adducts_options):\n",
    "            # Check if this adduct should be selected\n",
    "            is_selected = False\n",
    "            \n",
    "            if unique_id in top_adducts:\n",
    "                # Use existing selection\n",
    "                is_selected = adduct in top_adducts[unique_id]\n",
    "            elif idx == 0 and default_to_first:\n",
    "                # This is the first checkbox for a new unique_id - select it by default\n",
    "                is_selected = True\n",
    "                # Also update the dictionary\n",
    "                top_adducts[unique_id] = [adduct]\n",
    "                \n",
    "            checkbox = widgets.Checkbox(\n",
    "                value=is_selected,\n",
    "                description=adduct,\n",
    "                layout=widgets.Layout(width='275px', margin='0 0 0 -75px')\n",
    "            )\n",
    "            top_adducts_children.append(checkbox)\n",
    "        \n",
    "        top_adducts_checkboxes = widgets.VBox(children=top_adducts_children)\n",
    "        \n",
    "        # Create and attach handlers that explicitly use the current unique_id\n",
    "        on_all_adducts_change, on_top_adducts_change = create_checkbox_handlers(\n",
    "            unique_id, all_adducts_checkboxes, adduct_peak_combinations, ambiguous_checkbox, top_adducts_checkboxes\n",
    "        )\n",
    "        \n",
    "        for checkbox in all_adducts_checkboxes:\n",
    "            checkbox.observe(on_all_adducts_change, names='value')\n",
    "        \n",
    "        for checkbox in top_adducts_checkboxes.children:\n",
    "            checkbox.observe(on_top_adducts_change, names='value')\n",
    "        \n",
    "        # Create layout with current widgets\n",
    "        layout = create_layout(all_adducts_checkboxes, top_adducts_checkboxes)\n",
    "        \n",
    "        # Update image\n",
    "        group_run_number = data['group_run_number']\n",
    "        if group_run_number in runnum_to_structure_image_grid:\n",
    "            compound_image_widget.value = base64.b64decode(runnum_to_structure_image_grid[group_run_number])\n",
    "            compound_image_label.value = f\"Structures in Run{group_run_number}\"\n",
    "        else:\n",
    "            compound_image_widget.value = b''\n",
    "            compound_image_label.value = \"No Structures Found\"\n",
    "        \n",
    "        # Display everything in the main output\n",
    "        with main_output:\n",
    "            display(layout)\n",
    "            display(fig)  # Display the plotly figure\n",
    "        \n",
    "        update_progress_text()\n",
    "    \n",
    "    # Initial display\n",
    "    update_display()\n",
    "    \n",
    "    # Build the main UI\n",
    "    ui = widgets.VBox([\n",
    "        main_output,\n",
    "        output_container\n",
    "    ])\n",
    "    \n",
    "    # Show the UI\n",
    "    display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baa329cc3b34ae3bf3e4af6e73e9e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if config[\"selected_data_from_cache\"] is False:\n",
    "    processed_data = sta.process_data_for_plotting(eics_full, top_spectra_full, group_names_full, rt_peaks_full, config)\n",
    "    selected_adducts_dict = {}\n",
    "    ambiguous_adducts_dict = {}\n",
    "    top_adducts_dict = {}\n",
    "    create_interactive_plots(processed_data, mols_images, selected_adducts_dict, ambiguous_adducts_dict, top_adducts_dict)\n",
    "    # Run next cell after manual selection of adducts\n",
    "\n",
    "elif config[\"selected_data_from_cache\"] is True:\n",
    "    print(\"Not initiating GUI for adduct selection, loading selected adducts from cache below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sorgoleone;;/global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558_POS_MS2_RefStd-1_Sorgoleone_1_Rg70to1050-CE102040norm-200uM-S1_Run375.h5': ['[M+H]+||peak1',\n",
       "  '[M+NH4]+||peak1'],\n",
       " 'sorgoleone;;/global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558_POS_MS2_RefStd-1_Sorgoleone_1_Rg70to1050-CE205060norm-200uM-S1_Run376.h5': ['[M+H]+||peak1',\n",
       "  '[M+NH4]+||peak1'],\n",
       " 'sorgoleone;;/global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558_NEG_MS2_RefStd-1_Sorgoleone_1_Rg70to1050-CE102040norm-200uM-S1_Run377.h5': ['[M-H]-||peak1'],\n",
       " 'sorgoleone;;/global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558_NEG_MS2_RefStd-1_Sorgoleone_1_Rg70to1050-CE205060norm-200uM-S1_Run378.h5': ['[M-H]-||peak1'],\n",
       " 'sorgoleone;;/global/cfs/cdirs/metatlas/raw_data/jgi/20241021_JGI_HS_510060_SorghExu_final1_IQX_C18_USDAY92782/20241021_JGI_HS_510060_SorghExu_final1_IQX_C18_USDAY92782_POS_MS2_RefStd-1_Sorgoleone_1_Rg80to1200-CE102040norm-200uM-S1_Run382.h5': ['[M+Na]+||peak1',\n",
       "  '[M+H]+||peak1'],\n",
       " 'sorgoleone;;/global/cfs/cdirs/metatlas/raw_data/jgi/20241021_JGI_HS_510060_SorghExu_final1_IQX_C18_USDAY92782/20241021_JGI_HS_510060_SorghExu_final1_IQX_C18_USDAY92782_POS_MS2_RefStd-1_Sorgoleone_1_Rg80to1200-CE205060norm-200uM-S1_Run383.h5': ['[M+Na]+||peak1',\n",
       "  '[M+H]+||peak1']}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_adducts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate static summary reports for each compound after selections are made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to: /global/homes/b/bkieft/metatlas_junkdrawer/example_data/schellermetasci/cache/20250506190611_ref_stds_selected.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756ff06f705641558105b6fce2217e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Writing summary plots for selected compounds:   0%|          | 0/8 [00:00<?, ? compound group/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 21:09:41 \u001b[37m\u001b[41mCRITICAL\u001b[0m Uncaught exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_805171/141666826.py\", line 4, in <module>\n",
      "    sta.generate_static_summary_plots(processed_data, selected_adducts_dict, top_adducts_dict, config) # Save summary plots of selected compounds+adducts after completing GUI\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/metatlas.ety4nerKCN/notebooks/standards_library/standard_annotation.py\", line 3146, in generate_static_summary_plots\n",
      "    fig.write_image(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/plotly/basedatatypes.py\", line 3827, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/plotly/io/_kaleido.py\", line 266, in write_image\n",
      "    img_data = to_image(\n",
      "               ^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/plotly/io/_kaleido.py\", line 132, in to_image\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "Image export using the \"kaleido\" engine requires the kaleido package,\n",
      "which can be installed using pip:\n",
      "    $ pip install -U kaleido\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[98], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     sta\u001b[38;5;241m.\u001b[39mhandle_data(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig, timestamp\u001b[38;5;241m=\u001b[39mtimestamp, file_suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselected\u001b[39m\u001b[38;5;124m\"\u001b[39m, \\\n\u001b[1;32m      3\u001b[0m                     data\u001b[38;5;241m=\u001b[39m(selected_adducts_dict, ambiguous_adducts_dict, top_adducts_dict, processed_data))\n\u001b[0;32m----> 4\u001b[0m     \u001b[43msta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_static_summary_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_adducts_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_adducts_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Save summary plots of selected compounds+adducts after completing GUI\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselected_data_from_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/metatlas.ety4nerKCN/notebooks/standards_library/standard_annotation.py:3146\u001b[0m, in \u001b[0;36mgenerate_static_summary_plots\u001b[0;34m(processed_data, selected_good_adducts, top_adducts, config)\u001b[0m\n\u001b[1;32m   3145\u001b[0m fname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dirname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_summary_plot.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3146\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkaleido\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m   3152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/basedatatypes.py:3827\u001b[0m, in \u001b[0;36mBaseFigure.write_image\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/io/_kaleido.py:266\u001b[0m, in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Request image\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# -------------\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Do this first so we don't create a file if image conversion fails\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m img_data \u001b[38;5;241m=\u001b[39m \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# ---------\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/io/_kaleido.py:132\u001b[0m, in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03mImage export using the \"kaleido\" engine requires the kaleido package,\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mwhich can be installed using pip:\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    $ pip install -U kaleido\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m         )\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Validate figure\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# ---------------\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: \nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/metatlas.ety4nerKCN/metatlas/tools/logging.py:149\u001b[0m, in \u001b[0;36m_change_function.<locals>.showtraceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(exc_type, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m    148\u001b[0m     logger\u001b[38;5;241m.\u001b[39mcritical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m(exc_type, exc_value, exc_traceback))\n\u001b[0;32m--> 149\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# otherwise run the original hook\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     value \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mSystemExit\u001b[0m: 128"
     ]
    }
   ],
   "source": [
    "if config[\"selected_data_from_cache\"] is False:\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"selected\", \\\n",
    "                    data=(selected_adducts_dict, ambiguous_adducts_dict, top_adducts_dict, processed_data))\n",
    "    sta.generate_static_summary_plots(processed_data, selected_adducts_dict, top_adducts_dict, config) # Save summary plots of selected compounds+adducts after completing GUI\n",
    "\n",
    "elif config[\"selected_data_from_cache\"] is True:\n",
    "    selected_adducts_dict, ambiguous_adducts_dict, top_adducts_dict, processed_data = sta.handle_data(mode=\"load\", config=config, file_suffix=\"selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter RT Peak, EICs, and Top Spectra by the selected compounds+adducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique compounds selected: 1\n",
      "Total unique compound+adduct entries selected: 6\n",
      "\n",
      "Total EICs selected: 6\n",
      "Total RT peaks selected: 2\n",
      "Total MS2 spectra selected: 2\n",
      "Saving data to: /global/homes/b/bkieft/metatlas_junkdrawer/example_data/schellermetasci/cache/20250506190611_ref_stds_filtered.pkl\n"
     ]
    }
   ],
   "source": [
    "if config[\"filtered_data_from_cache\"] is False:\n",
    "    eics_filtered, rt_peaks_filtered, top_spectra_filtered = sta.filter_by_selected(eics_full, rt_peaks_full, top_spectra_full, selected_adducts_dict, top_adducts_dict) \n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"filtered\", \\\n",
    "                    data=(eics_filtered, top_spectra_filtered, rt_peaks_filtered))\n",
    "\n",
    "elif config[\"filtered_data_from_cache\"] is True:\n",
    "    eics_filtered, top_spectra_filtered, rt_peaks_filtered = sta.handle_data(mode=\"load\", config=config, file_suffix=\"filtered\")\n",
    "    print(f\"\\nTotal unique compounds selected: {eics_filtered['compound_name'].nunique()}\")\n",
    "    print(f\"Total unique compound+adduct entries selected: {eics_filtered['label'].nunique()}\\n\")\n",
    "    print(f\"Total EICs selected: {eics_filtered.shape[0]}\")\n",
    "    print(f\"Total RT peaks selected: {rt_peaks_filtered.shape[0]}\")\n",
    "    print(f\"Total MS2 spectra selected: {top_spectra_filtered.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify compounds not in the metatlas database Compounds table and store if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on dataset: top\n",
      "\tChecking for differing RTs between CEs and polarities, which are unexpected...\n",
      "\t\tGroup ('HILICZ', 'sorgoleone'): All RT values for ['102040norm'] and ['POS'] are within 0.05 mins of each other (0.0).\n",
      "\n",
      "\tGrouping by monoisotopic_mass and identify isomers in the datasets...\n",
      "\t\tNo isomers found in top data.\n",
      "\n",
      "\tSelecting best collision energy row by intensity for the top adduct(s) per compound...\n",
      "\t\tSelected 1 row and removed 0 row(s) for ('HILICZ', 'POS', 'sorgoleone', '[M+H]+').\n",
      "\t\tSelected 1 row and removed 0 row(s) for ('HILICZ', 'POS', 'sorgoleone', '[M+NH4]+').\n",
      "\n",
      "Working on dataset: all\n",
      "\tChecking for differing RTs between CEs and polarities, which are unexpected...\n",
      "\t\tGroup ('HILICZ', 'sorgoleone'): All RT values for ['102040norm'] and ['POS'] are within 0.05 mins of each other (0.0).\n",
      "\n",
      "\tGrouping by monoisotopic_mass and identify isomers in the datasets...\n",
      "\t\tNo isomers found in all data.\n",
      "\n",
      "'All' peaks dataset (for MSMS refs): 2 total compound peaks.\n",
      "'Top' peaks dataset (for EMA atlases): 2 best compound peaks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5c524f81184fc69e77a479d7b16774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Searching for matches in metatlas db:   0%|          | 0/2 [00:00<?, ? compound/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of compounds already in the metatlas database:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_label</th>\n",
       "      <th>query_matching_criterion</th>\n",
       "      <th>query_to_db</th>\n",
       "      <th>db_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sorgoleone</td>\n",
       "      <td>inchi_key</td>\n",
       "      <td>FGWRUVXUQWGLOX-AFJQJTPPSA-N</td>\n",
       "      <td>[FGWRUVXUQWGLOX-AFJQJTPPSA-N]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_label query_matching_criterion                  query_to_db  \\\n",
       "0  sorgoleone                inchi_key  FGWRUVXUQWGLOX-AFJQJTPPSA-N   \n",
       "\n",
       "                        db_match  \n",
       "0  [FGWRUVXUQWGLOX-AFJQJTPPSA-N]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All compounds are already in the metatlas database.\n",
      "\n",
      "All new entries found in the database.\n",
      "\n",
      "Saving data to: /global/homes/b/bkieft/metatlas_junkdrawer/example_data/schellermetasci/cache/20250506190611_ref_stds_metatlas_db.pkl\n"
     ]
    }
   ],
   "source": [
    "if config['metatlas_db_data_from_cache'] is False:\n",
    "    rt_peaks_filtered_all_selected, rt_peaks_filtered_top_selected = sta.format_and_select_top_adducts(rt_peaks_filtered, top_adducts_dict) # Export \"all\" for MSMS refs and \"top\" for EMA atlases\n",
    "    in_db, notin_db = sta.search_for_matches_in_metatlas_db(rt_peaks_filtered_all_selected, check_by_flat=True) # Check if selected compounds are in metatlas DB\n",
    "    if len(notin_db) > 0 and config['direct_store_to_compounds_table'] is True: # Store selected compounds+adducts in metatlas db\n",
    "        sta.store_in_metatlas_db(notin_db)\n",
    "    sta.check_db_deposit(rt_peaks_filtered_top_selected)\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"metatlas_db\", \\\n",
    "                    data=(in_db, notin_db, rt_peaks_filtered_all_selected, rt_peaks_filtered_top_selected))\n",
    "\n",
    "elif config['metatlas_db_data_from_cache'] is True:\n",
    "    in_db, notin_db, rt_peaks_filtered_all_selected, rt_peaks_filtered_top_selected = sta.handle_data(mode=\"load\", config=config, file_suffix=\"metatlas_db\")\n",
    "    print(f\"\\n'All' peaks dataset (for MSMS refs): {rt_peaks_filtered_all_selected.shape[0]} total compound peaks.\")\n",
    "    print(f\"'Top' peaks dataset (for EMA atlases): {rt_peaks_filtered_top_selected.shape[0]} best compound peaks.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify compounds+adducts not in atlases and set up new atlas creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3dcafcd1f74e3cb8e703c77b2b6a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Searching in HILICZ positive atlas:   0%|          | 0/2 [00:00<?, ? compound/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24cf55cfdf046ed9e2487ef58824836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Searching in HILICZ negative atlas: 0 compound [00:00, ? compound/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a891dadec3f48e381619bd1d3be90b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Searching in C18 positive atlas: 0 compound [00:00, ? compound/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b28072fd5844c88fc8652ff5cb94bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Searching in C18 negative atlas: 0 compound [00:00, ? compound/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None of the compounds+adducts searched were found in the atlases.\n",
      "\n",
      "There are 2 compounds+adducts are not yet in any atlases. View with 'nonmatches_to_atlases'.\n",
      "\n",
      "Setting up RT correction for compounds not yet in atlases using baseline correction method:\n",
      "\n",
      "\tGetting all QC files for project /global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558\n",
      "\n",
      "\tRetrieving baseline HILICZ QC atlas: /global/homes/b/bkieft/metatlas-data/HILIC/HILIC_QCv7_positive.tsv\n",
      "\n",
      "\tCollecting QC MS1 data for HILICZ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e44eb70771466d85462319fbf77579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Collecting MS1 data for QC compounds:   0%|          | 0/52 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPerforming RT correction...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d968425ebd046baa9555d2021f0b5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating RT correction model:   0%|          | 0/1 [00:00<?, ? chromatography/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHILICZ RT correction results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>adduct</th>\n",
       "      <th>polarity</th>\n",
       "      <th>rt_peak_baseline</th>\n",
       "      <th>rt_peak_experimental</th>\n",
       "      <th>rt_peak_corrected</th>\n",
       "      <th>rt_min_corrected</th>\n",
       "      <th>rt_max_corrected</th>\n",
       "      <th>rt_diff_experimental_vs_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sorgoleone</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801184</td>\n",
       "      <td>0.645454</td>\n",
       "      <td>0.145454</td>\n",
       "      <td>1.145454</td>\n",
       "      <td>0.15573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sorgoleone</td>\n",
       "      <td>[M+NH4]+</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801184</td>\n",
       "      <td>0.645454</td>\n",
       "      <td>0.145454</td>\n",
       "      <td>1.145454</td>\n",
       "      <td>0.15573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABMBA (unlabeled)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>1.093806</td>\n",
       "      <td>1.21834</td>\n",
       "      <td>1.096205</td>\n",
       "      <td>0.596205</td>\n",
       "      <td>1.596205</td>\n",
       "      <td>0.122135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N-acetyl-glucosamine (U - 13C)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>6.707815</td>\n",
       "      <td>6.418233</td>\n",
       "      <td>6.580829</td>\n",
       "      <td>6.080829</td>\n",
       "      <td>7.080829</td>\n",
       "      <td>-0.162596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adenine (U - 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>2.677602</td>\n",
       "      <td>2.834389</td>\n",
       "      <td>2.827321</td>\n",
       "      <td>2.327321</td>\n",
       "      <td>3.327321</td>\n",
       "      <td>0.007068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alanine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>13.405091</td>\n",
       "      <td>13.240681</td>\n",
       "      <td>13.400469</td>\n",
       "      <td>12.900469</td>\n",
       "      <td>13.900469</td>\n",
       "      <td>-0.159788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arginine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>16.939915</td>\n",
       "      <td>17.013107</td>\n",
       "      <td>16.987934</td>\n",
       "      <td>16.487934</td>\n",
       "      <td>17.487934</td>\n",
       "      <td>0.025173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>asparagine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>14.368089</td>\n",
       "      <td>14.252848</td>\n",
       "      <td>14.375830</td>\n",
       "      <td>13.875830</td>\n",
       "      <td>14.875830</td>\n",
       "      <td>-0.122982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aspartic acid (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>16.130360</td>\n",
       "      <td>16.043652</td>\n",
       "      <td>16.078480</td>\n",
       "      <td>15.578480</td>\n",
       "      <td>16.578480</td>\n",
       "      <td>-0.034828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cystine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>16.904308</td>\n",
       "      <td>16.930342</td>\n",
       "      <td>16.910628</td>\n",
       "      <td>16.410628</td>\n",
       "      <td>17.410628</td>\n",
       "      <td>0.019714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>glutamic acid (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>15.935390</td>\n",
       "      <td>15.834127</td>\n",
       "      <td>15.880790</td>\n",
       "      <td>15.380790</td>\n",
       "      <td>16.380790</td>\n",
       "      <td>-0.046663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>guanine (U - 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>6.265360</td>\n",
       "      <td>6.133224</td>\n",
       "      <td>6.286641</td>\n",
       "      <td>5.786641</td>\n",
       "      <td>6.786641</td>\n",
       "      <td>-0.153417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hypoxanthine (U - 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>3.102967</td>\n",
       "      <td>3.127001</td>\n",
       "      <td>3.138205</td>\n",
       "      <td>2.638205</td>\n",
       "      <td>3.638205</td>\n",
       "      <td>-0.011204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>inosine (U - 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>5.434236</td>\n",
       "      <td>5.173415</td>\n",
       "      <td>5.290440</td>\n",
       "      <td>4.790440</td>\n",
       "      <td>5.790440</td>\n",
       "      <td>-0.117025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lysine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>17.011310</td>\n",
       "      <td>17.090218</td>\n",
       "      <td>17.059901</td>\n",
       "      <td>16.559901</td>\n",
       "      <td>17.559901</td>\n",
       "      <td>0.030316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>methionine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>10.440955</td>\n",
       "      <td>10.258733</td>\n",
       "      <td>10.472300</td>\n",
       "      <td>9.972300</td>\n",
       "      <td>10.972300</td>\n",
       "      <td>-0.213567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>phenylalanine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>8.979306</td>\n",
       "      <td>8.996424</td>\n",
       "      <td>9.208172</td>\n",
       "      <td>8.708172</td>\n",
       "      <td>9.708172</td>\n",
       "      <td>-0.211748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>threonine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>13.489572</td>\n",
       "      <td>13.292386</td>\n",
       "      <td>13.450522</td>\n",
       "      <td>12.950522</td>\n",
       "      <td>13.950522</td>\n",
       "      <td>-0.158136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>thymine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>1.255231</td>\n",
       "      <td>1.293718</td>\n",
       "      <td>1.177483</td>\n",
       "      <td>0.677483</td>\n",
       "      <td>1.677483</td>\n",
       "      <td>0.116235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tryptophan (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>10.156649</td>\n",
       "      <td>9.98646</td>\n",
       "      <td>10.200872</td>\n",
       "      <td>9.700872</td>\n",
       "      <td>10.700872</td>\n",
       "      <td>-0.214412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tyrosine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>11.855156</td>\n",
       "      <td>11.571081</td>\n",
       "      <td>11.771035</td>\n",
       "      <td>11.271035</td>\n",
       "      <td>12.271035</td>\n",
       "      <td>-0.199954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>valine (U - 13C, 15N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QC</td>\n",
       "      <td>11.116009</td>\n",
       "      <td>10.86584</td>\n",
       "      <td>11.075074</td>\n",
       "      <td>10.575074</td>\n",
       "      <td>11.575074</td>\n",
       "      <td>-0.209234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             label    adduct  polarity  rt_peak_baseline  \\\n",
       "0                       sorgoleone    [M+H]+  positive               NaN   \n",
       "1                       sorgoleone  [M+NH4]+  positive               NaN   \n",
       "2                ABMBA (unlabeled)       NaN        QC          1.093806   \n",
       "3   N-acetyl-glucosamine (U - 13C)       NaN        QC          6.707815   \n",
       "4                adenine (U - 15N)       NaN        QC          2.677602   \n",
       "5           alanine (U - 13C, 15N)       NaN        QC         13.405091   \n",
       "6          arginine (U - 13C, 15N)       NaN        QC         16.939915   \n",
       "7        asparagine (U - 13C, 15N)       NaN        QC         14.368089   \n",
       "8     aspartic acid (U - 13C, 15N)       NaN        QC         16.130360   \n",
       "9           cystine (U - 13C, 15N)       NaN        QC         16.904308   \n",
       "10    glutamic acid (U - 13C, 15N)       NaN        QC         15.935390   \n",
       "11               guanine (U - 15N)       NaN        QC          6.265360   \n",
       "12          hypoxanthine (U - 15N)       NaN        QC          3.102967   \n",
       "13               inosine (U - 15N)       NaN        QC          5.434236   \n",
       "14           lysine (U - 13C, 15N)       NaN        QC         17.011310   \n",
       "15       methionine (U - 13C, 15N)       NaN        QC         10.440955   \n",
       "16    phenylalanine (U - 13C, 15N)       NaN        QC          8.979306   \n",
       "17        threonine (U - 13C, 15N)       NaN        QC         13.489572   \n",
       "18          thymine (U - 13C, 15N)       NaN        QC          1.255231   \n",
       "19       tryptophan (U - 13C, 15N)       NaN        QC         10.156649   \n",
       "20         tyrosine (U - 13C, 15N)       NaN        QC         11.855156   \n",
       "21           valine (U - 13C, 15N)       NaN        QC         11.116009   \n",
       "\n",
       "   rt_peak_experimental  rt_peak_corrected  rt_min_corrected  \\\n",
       "0              0.801184           0.645454          0.145454   \n",
       "1              0.801184           0.645454          0.145454   \n",
       "2               1.21834           1.096205          0.596205   \n",
       "3              6.418233           6.580829          6.080829   \n",
       "4              2.834389           2.827321          2.327321   \n",
       "5             13.240681          13.400469         12.900469   \n",
       "6             17.013107          16.987934         16.487934   \n",
       "7             14.252848          14.375830         13.875830   \n",
       "8             16.043652          16.078480         15.578480   \n",
       "9             16.930342          16.910628         16.410628   \n",
       "10            15.834127          15.880790         15.380790   \n",
       "11             6.133224           6.286641          5.786641   \n",
       "12             3.127001           3.138205          2.638205   \n",
       "13             5.173415           5.290440          4.790440   \n",
       "14            17.090218          17.059901         16.559901   \n",
       "15            10.258733          10.472300          9.972300   \n",
       "16             8.996424           9.208172          8.708172   \n",
       "17            13.292386          13.450522         12.950522   \n",
       "18             1.293718           1.177483          0.677483   \n",
       "19              9.98646          10.200872          9.700872   \n",
       "20            11.571081          11.771035         11.271035   \n",
       "21             10.86584          11.075074         10.575074   \n",
       "\n",
       "    rt_max_corrected rt_diff_experimental_vs_corrected  \n",
       "0           1.145454                           0.15573  \n",
       "1           1.145454                           0.15573  \n",
       "2           1.596205                          0.122135  \n",
       "3           7.080829                         -0.162596  \n",
       "4           3.327321                          0.007068  \n",
       "5          13.900469                         -0.159788  \n",
       "6          17.487934                          0.025173  \n",
       "7          14.875830                         -0.122982  \n",
       "8          16.578480                         -0.034828  \n",
       "9          17.410628                          0.019714  \n",
       "10         16.380790                         -0.046663  \n",
       "11          6.786641                         -0.153417  \n",
       "12          3.638205                         -0.011204  \n",
       "13          5.790440                         -0.117025  \n",
       "14         17.559901                          0.030316  \n",
       "15         10.972300                         -0.213567  \n",
       "16          9.708172                         -0.211748  \n",
       "17         13.950522                         -0.158136  \n",
       "18          1.677483                          0.116235  \n",
       "19         10.700872                         -0.214412  \n",
       "20         12.271035                         -0.199954  \n",
       "21         11.575074                         -0.209234  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to: /global/homes/b/bkieft/metatlas_junkdrawer/example_data/schellermetasci/cache/20250506190611_ref_stds_rt_correction.pkl\n",
      "Formatted 2 RT-corrected compounds for insertion into HILICZ atlases.\n",
      "Saving data to: /global/homes/b/bkieft/metatlas_junkdrawer/example_data/schellermetasci/cache/20250506190611_ref_stds_ema_atlases.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/metatlas.ety4nerKCN/notebooks/standards_library/standard_annotation.py:1976: FutureWarning:\n",
      "\n",
      "The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "\n",
      "/tmp/metatlas.ety4nerKCN/notebooks/standards_library/standard_annotation.py:1977: FutureWarning:\n",
      "\n",
      "The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "\n",
      "/tmp/metatlas.ety4nerKCN/notebooks/standards_library/standard_annotation.py:1978: FutureWarning:\n",
      "\n",
      "The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if config[\"ema_atlas_data_from_cache\"] is False:\n",
    "    ema_atlases_data = sta.get_ema_atlas_data(config[\"current_ema_atlases\"])\n",
    "    rt_peaks_filtered_top_selected_formatted = sta.convert_rt_peaks_to_atlas_format(rt_peaks_filtered_top_selected)\n",
    "    matches_to_atlases, nonmatches_to_atlases = sta.search_for_matches_in_atlases(rt_peaks_filtered_top_selected_formatted, ema_atlases_data)\n",
    "\n",
    "    if config[\"rt_correction_data_from_cache\"] is False:\n",
    "        print(\"Setting up RT correction for compounds not yet in atlases using baseline correction method:\\n\")\n",
    "        baseline_qc, experimental_qc, baseline_to_experimental_qc = sta.get_qc_experimental_atlas(nonmatches_to_atlases, config[\"current_qc_atlases\"], include_istds=True)\n",
    "        baseline_correction_inputs = sta.create_baseline_correction_input(nonmatches_to_atlases, baseline_to_experimental_qc)\n",
    "        baseline_correction_outputs = sta.rt_correction_from_baseline(baseline_correction_inputs, config)\n",
    "        sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"rt_correction\", \\\n",
    "                        data=(baseline_to_experimental_qc, baseline_correction_outputs))\n",
    "\n",
    "    elif config[\"rt_correction_data_from_cache\"] is True:\n",
    "        baseline_to_experimental_qc, baseline_correction_outputs = sta.handle_data(mode=\"load\",config=config, file_suffix=\"rt_correction\")\n",
    "\n",
    "    nonmatches_to_atlases_rt_corrected = sta.substitute_corrected_rt_values(nonmatches_to_atlases, baseline_correction_outputs)\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"ema_atlases\", \\\n",
    "                    data=(nonmatches_to_atlases_rt_corrected, ema_atlases_data, baseline_to_experimental_qc, baseline_correction_outputs))\n",
    "\n",
    "elif config[\"ema_atlas_data_from_cache\"] is True:\n",
    "    nonmatches_to_atlases_rt_corrected, ema_atlases_data, baseline_to_experimental_qc, baseline_correction_outputs = sta.handle_data(mode=\"load\", config=config, file_suffix=\"ema_atlases\")\n",
    "    print(f\"Total compounds to add to EMA atlases per chromatography: {nonmatches_to_atlases_rt_corrected['chromatography'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new EMA atlas with top selected reference standards added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_lcmsrun</th>\n",
       "      <th>chromatography</th>\n",
       "      <th>compound_name</th>\n",
       "      <th>adduct</th>\n",
       "      <th>polarity</th>\n",
       "      <th>rt_peak</th>\n",
       "      <th>mz</th>\n",
       "      <th>smiles</th>\n",
       "      <th>peak_index</th>\n",
       "      <th>inchi</th>\n",
       "      <th>inchi_key</th>\n",
       "      <th>neutralized_inchi</th>\n",
       "      <th>neutralized_inchi_key</th>\n",
       "      <th>permanent_charge</th>\n",
       "      <th>formula</th>\n",
       "      <th>mono_isotopic_molecular_weight</th>\n",
       "      <th>collision_energy</th>\n",
       "      <th>label</th>\n",
       "      <th>rt_min</th>\n",
       "      <th>rt_max</th>\n",
       "      <th>mz_tolerance</th>\n",
       "      <th>mz_tolerance_units</th>\n",
       "      <th>in_metatlas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558_POS_MS2_RefStd-1_Sorgoleone_1_Rg70to1050-CE102040norm-200uM-S1_Run375.h5</td>\n",
       "      <td>HILICZ</td>\n",
       "      <td>sorgoleone</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.645454</td>\n",
       "      <td>359.221685</td>\n",
       "      <td>COC1=CC(=O)C(=C(C1=O)CCCCCCC/C=C\\C/C=C\\CC=C)O</td>\n",
       "      <td>peak1</td>\n",
       "      <td>InChI=1S/C22H30O4/c1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-18-21(24)19(23)17-20(26-2)22(18)25/h3,5-6,8-9,17,24H,1,4,7,10-16H2,2H3/b6-5-,9-8-</td>\n",
       "      <td>FGWRUVXUQWGLOX-AFJQJTPPSA-N</td>\n",
       "      <td>InChI=1S/C22H30O4/c1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-18-21(24)19(23)17-20(26-2)22(18)25/h3,5-6,8-9,17,24H,1,4,7,10-16H2,2H3/b6-5-,9-8-</td>\n",
       "      <td>FGWRUVXUQWGLOX-AFJQJTPPSA-N</td>\n",
       "      <td>0</td>\n",
       "      <td>C22H30O4</td>\n",
       "      <td>358.214409</td>\n",
       "      <td>102040norm</td>\n",
       "      <td>sorgoleone</td>\n",
       "      <td>0.145454</td>\n",
       "      <td>1.145454</td>\n",
       "      <td>5</td>\n",
       "      <td>ppm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558_POS_MS2_RefStd-1_Sorgoleone_1_Rg70to1050-CE102040norm-200uM-S1_Run375.h5</td>\n",
       "      <td>HILICZ</td>\n",
       "      <td>sorgoleone</td>\n",
       "      <td>[M+NH4]+</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.645454</td>\n",
       "      <td>376.248232</td>\n",
       "      <td>COC1=CC(=O)C(=C(C1=O)CCCCCCC/C=C\\C/C=C\\CC=C)O</td>\n",
       "      <td>peak1</td>\n",
       "      <td>InChI=1S/C22H30O4/c1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-18-21(24)19(23)17-20(26-2)22(18)25/h3,5-6,8-9,17,24H,1,4,7,10-16H2,2H3/b6-5-,9-8-</td>\n",
       "      <td>FGWRUVXUQWGLOX-AFJQJTPPSA-N</td>\n",
       "      <td>InChI=1S/C22H30O4/c1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-18-21(24)19(23)17-20(26-2)22(18)25/h3,5-6,8-9,17,24H,1,4,7,10-16H2,2H3/b6-5-,9-8-</td>\n",
       "      <td>FGWRUVXUQWGLOX-AFJQJTPPSA-N</td>\n",
       "      <td>0</td>\n",
       "      <td>C22H30O4</td>\n",
       "      <td>358.214409</td>\n",
       "      <td>102040norm</td>\n",
       "      <td>sorgoleone</td>\n",
       "      <td>0.145454</td>\n",
       "      <td>1.145454</td>\n",
       "      <td>5</td>\n",
       "      <td>ppm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                     standard_lcmsrun  \\\n",
       "0  /global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558_POS_MS2_RefStd-1_Sorgoleone_1_Rg70to1050-CE102040norm-200uM-S1_Run375.h5   \n",
       "1  /global/cfs/cdirs/metatlas/raw_data/jgi/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558/20241002_JGI_HS_510060_SorghExu_final1_EXP120B_HILICZ_USHXG02558_POS_MS2_RefStd-1_Sorgoleone_1_Rg70to1050-CE102040norm-200uM-S1_Run375.h5   \n",
       "\n",
       "  chromatography compound_name    adduct  polarity   rt_peak          mz  \\\n",
       "0         HILICZ    sorgoleone    [M+H]+  positive  0.645454  359.221685   \n",
       "1         HILICZ    sorgoleone  [M+NH4]+  positive  0.645454  376.248232   \n",
       "\n",
       "                                          smiles peak_index  \\\n",
       "0  COC1=CC(=O)C(=C(C1=O)CCCCCCC/C=C\\C/C=C\\CC=C)O      peak1   \n",
       "1  COC1=CC(=O)C(=C(C1=O)CCCCCCC/C=C\\C/C=C\\CC=C)O      peak1   \n",
       "\n",
       "                                                                                                                                       inchi  \\\n",
       "0  InChI=1S/C22H30O4/c1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-18-21(24)19(23)17-20(26-2)22(18)25/h3,5-6,8-9,17,24H,1,4,7,10-16H2,2H3/b6-5-,9-8-   \n",
       "1  InChI=1S/C22H30O4/c1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-18-21(24)19(23)17-20(26-2)22(18)25/h3,5-6,8-9,17,24H,1,4,7,10-16H2,2H3/b6-5-,9-8-   \n",
       "\n",
       "                     inchi_key  \\\n",
       "0  FGWRUVXUQWGLOX-AFJQJTPPSA-N   \n",
       "1  FGWRUVXUQWGLOX-AFJQJTPPSA-N   \n",
       "\n",
       "                                                                                                                           neutralized_inchi  \\\n",
       "0  InChI=1S/C22H30O4/c1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-18-21(24)19(23)17-20(26-2)22(18)25/h3,5-6,8-9,17,24H,1,4,7,10-16H2,2H3/b6-5-,9-8-   \n",
       "1  InChI=1S/C22H30O4/c1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-18-21(24)19(23)17-20(26-2)22(18)25/h3,5-6,8-9,17,24H,1,4,7,10-16H2,2H3/b6-5-,9-8-   \n",
       "\n",
       "         neutralized_inchi_key permanent_charge   formula  \\\n",
       "0  FGWRUVXUQWGLOX-AFJQJTPPSA-N                0  C22H30O4   \n",
       "1  FGWRUVXUQWGLOX-AFJQJTPPSA-N                0  C22H30O4   \n",
       "\n",
       "  mono_isotopic_molecular_weight collision_energy       label    rt_min  \\\n",
       "0                     358.214409       102040norm  sorgoleone  0.145454   \n",
       "1                     358.214409       102040norm  sorgoleone  0.145454   \n",
       "\n",
       "     rt_max mz_tolerance mz_tolerance_units in_metatlas  \n",
       "0  1.145454            5                ppm        True  \n",
       "1  1.145454            5                ppm        True  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonmatches_to_atlases_rt_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:39:40 \u001b[37m\u001b[41mCRITICAL\u001b[0m Uncaught exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_805171/3518290779.py\", line 2, in <module>\n",
      "    ema_atlas_ids, ema_atlas_names = sta.update_and_save_ema_atlases(nonmatches_to_atlases_rt_corrected, {ema_atlases_data['HILICZ']}, config, timestamp)\n",
      "                                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: unhashable type: 'dict'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_new_ema_atlases\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     ema_atlas_ids, ema_atlas_names \u001b[38;5;241m=\u001b[39m sta\u001b[38;5;241m.\u001b[39mupdate_and_save_ema_atlases(nonmatches_to_atlases_rt_corrected, {ema_atlases_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHILICZ\u001b[39m\u001b[38;5;124m'\u001b[39m]}, config, timestamp)\n\u001b[1;32m      3\u001b[0m     sta\u001b[38;5;241m.\u001b[39mhandle_data(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig, timestamp\u001b[38;5;241m=\u001b[39mtimestamp, file_suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_atlas_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \\\n\u001b[1;32m      4\u001b[0m                     data\u001b[38;5;241m=\u001b[39m(ema_atlas_ids, ema_atlas_names))\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/metatlas.ety4nerKCN/metatlas/tools/logging.py:149\u001b[0m, in \u001b[0;36m_change_function.<locals>.showtraceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(exc_type, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m    148\u001b[0m     logger\u001b[38;5;241m.\u001b[39mcritical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m(exc_type, exc_value, exc_traceback))\n\u001b[0;32m--> 149\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# otherwise run the original hook\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     value \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mSystemExit\u001b[0m: 128"
     ]
    }
   ],
   "source": [
    "if config['save_new_ema_atlases'] is True:\n",
    "    ema_atlas_ids, ema_atlas_names = sta.update_and_save_ema_atlases(nonmatches_to_atlases_rt_corrected, ema_atlases_data['HILICZ'], config, timestamp)\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"new_atlas_ids\", \\\n",
    "                    data=(ema_atlas_ids, ema_atlas_names))\n",
    "    ema_atlas_ids, ema_atlas_names = sta.handle_data(mode=\"load\", config=config, file_suffix=\"new_atlas_ids\")\n",
    "\n",
    "    if config['direct_deposit_new_emas'] is True:\n",
    "        print(\"New EMA atlases have been saved to disk and deposited in the metatlas database:\")\n",
    "        display(pd.DataFrame.from_dict(ema_atlas_ids))\n",
    "    print(f\"\\nNew EMA atlas locations:\")\n",
    "    display(pd.DataFrame.from_dict(ema_atlas_names))\n",
    "\n",
    "elif config['save_new_ema_atlases'] is False:\n",
    "    print(\"No new EMA atlases saved to disk, as 'save_new_ema_atlases' is set to False in the config file.\")\n",
    "    print(\"Here is the new atlas data in memory:\")\n",
    "    display(nonmatches_to_atlases_rt_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify compounds not in MSMS refs and set up new MSMS refs creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MSMS refs with 216409 rows and 17 columns.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3716c85304774d118adff266aac1d9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Searching for matches in MSMS refs:   0%|          | 0/12 [00:00<?, ? compound/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 compounds+adducts are not yet in MSMS refs. Check notin_msms_refs to view.\n",
      "\n",
      "Saving data to: /global/homes/b/bkieft/metatlas/notebooks/standards_library/example_data/schellermetasci/cache/20250506103111_ref_stds_msms_refs.pkl\n"
     ]
    }
   ],
   "source": [
    "if config[\"msms_refs_data_from_cache\"] is False:\n",
    "    msms_refs = sta.get_msms_refs(msms_refs_path=config[\"current_msms_refs_path\"])\n",
    "    rt_peaks_filtered_all_selected_formatted = sta.format_for_msms_refs(rt_peaks_filtered_all_selected, top_spectra_filtered, msms_refs, config)\n",
    "    in_msms_refs, notin_msms_refs = sta.search_for_matches_in_msms_refs(rt_peaks_filtered_all_selected_formatted, msms_refs, check_by_flat=True)\n",
    "    sta.handle_data(mode=\"save\", config=config, timestamp=timestamp, file_suffix=\"msms_refs\", \\\n",
    "                    data=(msms_refs, notin_msms_refs, rt_peaks_filtered_all_selected_formatted))\n",
    "    \n",
    "elif config[\"msms_refs_data_from_cache\"] is True:\n",
    "    msms_refs, notin_msms_refs, rt_peaks_filtered_all_selected_formatted = sta.handle_data(mode=\"load\", config=config, file_suffix=\"msms_refs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new MSMS refs table with all selected reference standards added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing MSMS refs went from 216409 to 216421 compounds.\n",
      "\tNew MSMS refs: /global/homes/b/bkieft/metatlas/notebooks/standards_library/example_data/schellermetasci/updated_MSMS_refs/msms_refs_20250506103111.tab\n"
     ]
    }
   ],
   "source": [
    "if config['save_new_msms_refs'] is True:\n",
    "    sta.update_and_save_msms_refs(msms_refs, notin_msms_refs, config, timestamp)\n",
    "\n",
    "elif config['save_new_msms_refs'] is False:\n",
    "    print(\"No new MSMS refs saved to disk, as 'save_new_msms_refs' is set to False in the config file.\")\n",
    "    print(\"Here is the new MSMS refs data in memory:\")\n",
    "    display(notin_msms_refs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Metatlas Targeted",
   "language": "python",
   "name": "metatlas-targeted"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
